var documenterSearchIndex = {"docs":
[{"location":"manuals/sharpbits/stack-overflow-inference/#stack-overflow-inference","page":"Stack Overflow in Message Computations","title":"Stack Overflow during inference","text":"","category":"section"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"When working with large probabilistic models in RxInfer, you might encounter a StackOverflowError. This section explains why this happens and how to prevent it.","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/#The-Problem","page":"Stack Overflow in Message Computations","title":"The Problem","text":"","category":"section"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"RxInfer uses reactive streams to compute messages between nodes in the factor graph. The subscription to these streams happens recursively, which means:","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"Each node subscribes to its input messages or posteriors\nThose input messages may need to subscribe to their own inputs\nThis continues until all dependencies are resolved","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"For large models, this recursive subscription process can consume the entire stack space, resulting in a StackOverflowError.","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/#Example-Error","page":"Stack Overflow in Message Computations","title":"Example Error","text":"","category":"section"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"When this occurs, you'll see an error message that looks something like this:","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"ERROR: Stack overflow error occurred during the inference procedure. ","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/#Solution:-Limiting-Stack-Depth","page":"Stack Overflow in Message Computations","title":"Solution: Limiting Stack Depth","text":"","category":"section"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"RxInfer provides a solution through the limit_stack_depth option in the inference options. This option limits the recursion depth at the cost of some performance overhead.","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/#How-to-Use","page":"Stack Overflow in Message Computations","title":"How to Use","text":"","category":"section"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"You can enable stack depth limiting by passing it through the options parameter to the infer function:","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"using RxInfer\n\n@model function long_state_space_model(y)\n    x[1] ~ Normal(mean = 0.0, var = 1.0)\n    y[1] ~ Normal(mean = x[1], var = 1.0)\n    for i in 2:length(y)\n        x[i] ~ Normal(mean = x[i - 1], var = 1.0)\n        y[i] ~ Normal(mean = x[i], var = 1.0)\n    end\nend\n\ndata = (y = randn(10000), )\n\nresults = infer(\n    model = long_state_space_model(),\n    data = data,\n    options = (\n        limit_stack_depth = 100, # note the comma\n    )\n)","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"note: Note\nNote the comma after limit_stack_depth = 100. This is important because it tells Julia that the option is placed in the named tuple options.","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"Without limit_stack_depth enabled, the inference will fail with a StackOverflowError","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"results = infer(\n    model = long_state_space_model(),\n    data = data\n)","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"ERROR: Stack overflow error occurred during the inference procedure. ","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/#Performance-Considerations","page":"Stack Overflow in Message Computations","title":"Performance Considerations","text":"","category":"section"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"When limit_stack_depth is enabled:","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"The recursive subscription process is split into multiple steps\nThis prevents stack overflow but introduces performance overhead (you should verify this in your use case)\nFor very large models, this option might be essential for successful execution","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/#When-to-Use","page":"Stack Overflow in Message Computations","title":"When to Use","text":"","category":"section"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"Consider using limit_stack_depth when:","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"Working with large models (many nodes/variables)\nEncountering StackOverflowError\nProcessing deep hierarchical models\nDealing with long sequences or time series","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"tip: Tip\nIf you're not sure whether you need this option, try running your model without it first. Only enable limit_stack_depth if you encounter stack overflow issues.","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/#Further-Reading","page":"Stack Overflow in Message Computations","title":"Further Reading","text":"","category":"section"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"For more details about inference options and execution, see:","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"Static Inference documentation\nThe options parameter in the infer function documentation","category":"page"},{"location":"manuals/sharpbits/stack-overflow-inference/","page":"Stack Overflow in Message Computations","title":"Stack Overflow in Message Computations","text":"","category":"page"},{"location":"manuals/inference/nonconjugate/#inference-nonconjugate","page":"Non-conjugate inference","title":"Non-conjugate Inference","text":"","category":"section"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"The RxInfer package excels in scenarios where the model uses conjugate priors for hidden states. Conjugate priors allow Bayesian inference to utilize pre-computed analytical update rules, significantly speeding up the inference process. For instance, the conjugate prior for the parameter of a Bernoulli distribution is the Beta distribution. The conjugate prior for the mean parameter of a Normal distribution is another Normal distribution, and the conjugate prior for the precision parameter of a Normal distribution is the Gamma distribution.","category":"page"},{"location":"manuals/inference/nonconjugate/#Non-conjugate-Structures","page":"Non-conjugate inference","title":"Non-conjugate Structures","text":"","category":"section"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"However, models often contain non-conjugate structures, which prevent RxInfer from performing efficient inference. Non-conjugate priors occur when the prior and the likelihood do not result in a posterior that belongs to the same family as the prior. This complicates the inference process because it requires approximations or numerical methods instead of simple analytical updates.","category":"page"},{"location":"manuals/inference/nonconjugate/#Example-Scenario","page":"Non-conjugate inference","title":"Example Scenario","text":"","category":"section"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"Consider the scenario where we assign the Beta distribution as a prior for the mean parameter of a Normal distribution. Let's explore what happens in this case with an example.","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"First, we generate some synthetic data:","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"using Distributions, ExponentialFamily, Plots, StableRNGs\n\n# The model will infer the hidden parameters from data\nhidden_mean         = 0.2\nhidden_precision    = 0.8\nhidden_distribution = NormalMeanPrecision(hidden_mean, hidden_precision)\n\nnumber_of_datapoints = 1000\ndata = rand(StableRNG(42), hidden_distribution, number_of_datapoints)\n\nhistogram(data; normalize = :pdf)","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"Next, we specify the model. Suppose we believe the data follows a Normal distribution, and we are confident that the mean parameter is between 0 and 1. The Beta distribution is a logical choice for the prior of the mean parameter because it models a continuous variable in the range from 0 to 1. Similarly, we assign a Beta prior for the precision parameter, assuming it also lies between 0 and 1.","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"using RxInfer\n\n@model function non_conjugate_model(y)\n   m ~ Beta(1, 1)\n   p ~ Beta(1, 1)\n   y .~ Normal(mean = m, precision = p)\nend","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"If we attempt inference with this model, RxInfer will throw an error because the necessary computational rules for such a model are not available in closed form. This is due to the non-conjugate nature of the priors used.","category":"page"},{"location":"manuals/inference/nonconjugate/#Addressing-Non-conjugacy-with-ExponentialFamilyProjection","page":"Non-conjugate inference","title":"Addressing Non-conjugacy with ExponentialFamilyProjection","text":"","category":"section"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"To overcome this limitation, RxInfer integrates with the ExponentialFamilyProjection package. This package re-projects non-conjugate relationships back into a member of the exponential family at the cost of some accuracy.","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"note: Note\nRxInfer supports non-conjugate inference for completeness, but be aware that inference execution times may increase significantly. This is because non-conjugate models require more complex computations, often involving sampling-based approximations.","category":"page"},{"location":"manuals/inference/nonconjugate/#Specifying-Constraints","page":"Non-conjugate inference","title":"Specifying Constraints","text":"","category":"section"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"The projection constraint must be specified using the @constraints macro. For example:","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"using ExponentialFamilyProjection\n\n@constraints function non_conjugate_model_constraints()\n  # project variational posterior over `m` to `Beta`\n  q(m) :: ProjectedTo(Beta)\n  # project variational posterior over `p` to `Beta`\n  q(p) :: ProjectedTo(Beta)\n  # `m` and `p` are jointly independent\n  q(m, p) = q(m)q(p)\nend","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"These constraints specify that the posterior distribution for the hidden variable m must be re-projected to a Beta distribution to cover the region from 0 to 1. The same applies to the variable p.  ","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"note: Note\nNote that the distribution specified in the @constraints does not need to match the distribution specified as a prior. For example, we could use a Gamma distribution as a prior and a Beta distribution as a posterior. The only requirement is that the support of the posterior distribution must be the same as or smaller than that of the prior.","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"We also assume that m and p are jointly independent with the q(m, p) = q(m)q(p) specification. Dropping the assumption of joint independence would require initializing messages for m and p without guarantees of convergence. Read more about factorization constraints in the Constraints Specification guide.","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"note: Note\nThe ProjectedTo structure is defined in the ExponentialFamilyProjection package. To fully explore its capabilities and hyper-parameters, we invite you to read the detailed documentation.","category":"page"},{"location":"manuals/inference/nonconjugate/#Initialization","page":"Non-conjugate inference","title":"Initialization","text":"","category":"section"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"We also need to initialize the inference procedure due to the factorization constraints. Read more about initialization in the corresponding section.","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"initialization = @initialization begin \n  q(m) = Beta(1, 1)\n  q(p) = Beta(1, 1)\nend","category":"page"},{"location":"manuals/inference/nonconjugate/#Running-the-Inference","page":"Non-conjugate inference","title":"Running the Inference","text":"","category":"section"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"With everything set up, we can run the inference procedure:","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"result = infer(\n  model = non_conjugate_model(),\n  data  = (y = data,),\n  constraints = non_conjugate_model_constraints(),\n  initialization = initialization,\n  iterations = 25,\n  free_energy = true\n)","category":"page"},{"location":"manuals/inference/nonconjugate/#Analyzing-the-Results","page":"Non-conjugate inference","title":"Analyzing the Results","text":"","category":"section"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"Let's analyze the results using the StatsPlots package to visualize the resulting posteriors over individual VMP iterations:","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"using StatsPlots\nusing Test #hide\n\n@test isapprox(mean(result.posteriors[:m][end]), hidden_mean, atol = 1e-1) #hide\n@test isapprox(mean(result.posteriors[:p][end]), hidden_precision, atol = 1e-1) #hide\n\n@gif for (i, q) in enumerate(zip(result.posteriors[:m], result.posteriors[:p]))\n  q_m = q[1]\n  q_p = q[2]\n\n  p1 = plot(q_m, label = \"Inferred `m`\", fill = 0, fillalpha = 0.2)\n  p1 = vline!(p1, [hidden_mean], label = \"Hidden `m`\")\n\n  p2 = plot(q_p, label = \"Inferred `p`\", fill = 0, fillalpha = 0.2)\n  p2 = vline!(p2, [hidden_precision], label = \"Hidden `p`\")\n\n  plot(p1, p2; title = \"Iteration $i\")\nend fps = 15","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"As we can see, the estimated posteriors are quite close to the actual hidden parameters used to generate our dataset. We can also verify the Bethe Free Energy values to ensure our result has converged:","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"@test first(result.free_energy) > last(result.free_energy) #hide\nplot(result.free_energy, label = \"Bethe Free Energy (per iteration)\")","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"The convergence of the Bethe Free Energy indicates that the inference process has stabilized, and the model parameters have reached an optimal state.","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"note: Note\nThe projection method uses stochastic gradient computations, which may cause fluctuations in the estimates and Bethe Free Energy performance.","category":"page"},{"location":"manuals/inference/nonconjugate/","page":"Non-conjugate inference","title":"Non-conjugate inference","text":"","category":"page"},{"location":"library/exported-methods/#lib-using-methods","page":"Exported methods","title":"Using methods from RxInfer","text":"","category":"section"},{"location":"library/exported-methods/","page":"Exported methods","title":"Exported methods","text":"In the Julia programming language (in contrast to Python for example) the most common way of loading a module is:","category":"page"},{"location":"library/exported-methods/","page":"Exported methods","title":"Exported methods","text":"using RxInfer","category":"page"},{"location":"library/exported-methods/","page":"Exported methods","title":"Exported methods","text":"A nice explanation about how modules/packages work in Julia can be found in the official documentation.","category":"page"},{"location":"library/exported-methods/","page":"Exported methods","title":"Exported methods","text":"In a nutshell, Julia automatically resolves all name collisions and there is no a lot of benefit of importing specific names, e.g.:","category":"page"},{"location":"library/exported-methods/","page":"Exported methods","title":"Exported methods","text":"import RxInfer: mean","category":"page"},{"location":"library/exported-methods/","page":"Exported methods","title":"Exported methods","text":"One of the reasons for that is that Julia uses multiple-dispatch capabilities to merge names automatically and will indicate (with a warning) if something went wrong or names have unresolvable collisions on types. As a small example of this feature consider the following small import example:","category":"page"},{"location":"library/exported-methods/","page":"Exported methods","title":"Exported methods","text":"import RxInfer: mean as mean_from_rxinfer\nimport Distributions: mean as mean_from_distributions\n\nmean_from_rxinfer === mean_from_distributions","category":"page"},{"location":"library/exported-methods/","page":"Exported methods","title":"Exported methods","text":"Even though we import mean function from two different packages they actually refer to the same object. Worth noting that this is not always the case - Julia will print a warning in case it finds unresolvable conflicts and usage of such functions will be disallowed unless user import them specifically. Read more about this in the section of the Julia's documentation.","category":"page"},{"location":"library/exported-methods/","page":"Exported methods","title":"Exported methods","text":"# It is easier to let Julia resolve names automatically\n# Julia will not overwrite `mean` that is coming from both packages\nusing RxInfer, Distributions ","category":"page"},{"location":"library/exported-methods/","page":"Exported methods","title":"Exported methods","text":"mean(Normal(0.0, 1.0)) # `Normal` is an object from `Distributions.jl`","category":"page"},{"location":"library/exported-methods/","page":"Exported methods","title":"Exported methods","text":"mean(NormalMeanVariance(0.0, 1.0)) # `NormalMeanVariance` is an object from `RxInfer.jl`","category":"page"},{"location":"library/exported-methods/#lib-list-methods","page":"Exported methods","title":"List of available methods","text":"","category":"section"},{"location":"library/exported-methods/","page":"Exported methods","title":"Exported methods","text":"Below you can find a list of exported methods from RxInfer.jl. All methods (even private) can be always accessed with RxInfer. prefix, e.g RxInfer.mean.","category":"page"},{"location":"library/exported-methods/","page":"Exported methods","title":"Exported methods","text":"note: Note\nSome exported names are (for legacy reasons) intended for private usage only. As a result some of these methods do not have a proper associated documentation with them. We constantly improve RxInfer.jl library and continue to add better documentation for many exported methods, but a small portion of these methods could be removed from this list in the future.","category":"page"},{"location":"library/exported-methods/","page":"Exported methods","title":"Exported methods","text":"using RxInfer #hide\nforeach(println, names(RxInfer))","category":"page"},{"location":"library/exported-methods/","page":"Exported methods","title":"Exported methods","text":"","category":"page"},{"location":"manuals/sharpbits/overview/#Sharp-bits-of-RxInfer","page":"Overview","title":"Sharp bits of RxInfer","text":"","category":"section"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"This page serves as a collection of sharp bits - potential pitfalls and common issues you might encounter while using RxInfer. While RxInfer is designed to be user-friendly, there are certain scenarios where you might encounter unexpected behavior or errors. Understanding these can help you avoid common problems and debug your code more effectively.","category":"page"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"note: Note\nSee Session Data and Telemetry for more information on how to share sessions for better support.","category":"page"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"Rule Not Found Error\nWhat causes it\nHow to diagnose and fix it\nCommon scenarios\nStack Overflow during inference\nUnderstanding the potential cause\nPrevention strategies\nUsing = instead of := for deterministic nodes\nWhy not =?","category":"page"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"note: Note\nThis is a community document that will be updated as we identify more common issues and their solutions. If you encounter a problem that isn't covered here, please consider opening an issue/discussion or contributing to this guide.","category":"page"},{"location":"manuals/sharpbits/overview/#getting-help","page":"Overview","title":"Getting Help with Issues","text":"","category":"section"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"When you encounter issues with RxInfer, we want to help you as effectively as possible. Here's how you can help us help you:","category":"page"},{"location":"manuals/sharpbits/overview/#sharpbits-telemetry-note","page":"Overview","title":"Session Data and Telemetry","text":"","category":"section"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"RxInfer includes optional telemetry and session sharing features to help us provide better support and improve the package. When enabled, these features help us:","category":"page"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"Understand how the package is used in practice\nIdentify and debug issues more effectively \nMake informed decisions about improvements\nShare aggregate usage patterns in community meetings","category":"page"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"For details on enabling telemetry and sharing session data, see:","category":"page"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"Usage Telemetry - Learn about anonymous usage statistics\nSession Sharing - Share session data for debugging","category":"page"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"All data sharing is optional and privacy-focused. When opening issues, including your session ID helps us provide more targeted support by understanding your usage context.","category":"page"},{"location":"manuals/sharpbits/overview/#How-to-contribute","page":"Overview","title":"How to contribute","text":"","category":"section"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"If you have a sharp bit to share, please consider opening an issue/discussion or contributing to this guide. To write a new section, create a new file in the docs/src/manuals/sharpbits directory. Use @id to specify the ID of the section and @ref to reference it later.","category":"page"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"# [New section](@id new-section)\n\nThis is a new section.","category":"page"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"Then add a new entry to the pages array in the docs/make.jl file.","category":"page"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"\"Sharp bits of RxInfer\" => [\n    \"Overview\" => \"manuals/sharpbits/overview.md\",\n    \"Rule Not Found Error\" => \"manuals/sharpbits/rule-not-found.md\",\n    \"Stack Overflow in Message Computations\" => \"manuals/sharpbits/stack-overflow-inference.md\",\n    \"Using `=` instead of `:=` for deterministic nodes\" => \"manuals/sharpbits/usage-colon-equality.md\",\n    # ...\n    \"New section\" => \"manuals/sharpbits/new-section.md\",\n]","category":"page"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"In the overview.md file, add a new section with the title and the ID of the section. Use the @ref macro to reference the ID.","category":"page"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"- [New section](@ref new-section)\n    - What this section is about\n    - ...","category":"page"},{"location":"manuals/sharpbits/overview/","page":"Overview","title":"Overview","text":"","category":"page"},{"location":"manuals/constraints-specification/#user-guide-constraints-specification","page":"Constraints specification","title":"Constraints Specification","text":"","category":"section"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"RxInfer.jl uses a macro called @constraints from GraphPPL to add extra constraints during the inference process. For details on using the @constraints macro, you can check out the official documentation of GraphPPL.","category":"page"},{"location":"manuals/constraints-specification/#user-guide-constraints-specification-background","page":"Constraints specification","title":"Background and example","text":"","category":"section"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"Here we briefly cover the mathematical aspects of constraints specification. For additional information and relevant links, please refer to the Bethe Free Energy section. In essence, RxInfer performs Variational Inference (via message passing) given specific constraints mathcalQ:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"q^* = argmin_q(s) in mathcalQFq(haty) = mathbbE_q(s)leftlog fracq(s)p(s y=haty) right","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"The @model macro specifies generative model p(s, y) where s is a set of random variables and y is a set of observations. In a nutshell the goal of probabilistic programming is to find p(s|y). RxInfer approximates p(s|y) with a proxy distribution q(x) using KL divergence and Bethe Free Energy optimisation procedure. By default there are no extra factorization constraints on q(s) and the optimal solution is q(s) = p(s|y).","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"For certain problems, it may be necessary to adjust the set of constraints mathcalQ (also known as the variational family of distributions) to either improve accuracy at the expense of computational resources or reduce accuracy to conserve computational resources. Sometimes, we are compelled to impose certain constraints because otherwise, the problem becomes too challenging to solve within a reasonable timeframe.","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"For instance, consider the following model:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"using RxInfer\n\n@model function iid_normal(y)\n    μ  ~ Normal(mean = 0.0, variance = 1.0)\n    τ  ~ Gamma(shape = 1.0, rate = 1.0)\n    y .~ Normal(mean = μ, precision = τ)\nend","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"In this model, we characterize all observations in a dataset y as a Normal distribution with mean μ and precision τ. It's reasonable to assume that the latent variables μ and τ are jointly independent, thereby rendering their joint posterior distribution as:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"q(μ τ) = q(μ)q(τ)","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"If we would write the variational family of distribution for such an assumption, it would be expressed as:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"mathcalQ = left q  q(μ τ) = q(μ)q(τ) right","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"We can express this constraint with the @constraints macro:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"constraints = @constraints begin \n    q(μ, τ) = q(μ)q(τ)\nend","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"and use the created constraints object to the infer function:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"# We need to specify initial marginals, since with the constraints \n# the problem becomes inherently iterative (we could also specify initial for the `μ` instead)\ninit = @initialization begin \n    q(τ) = vague(Gamma)\nend\n\nresult = infer(\n    model       = iid_normal(),\n    # Sample data from mean `3.1415` and precision `2.7182`\n    data        = (y = rand(NormalMeanPrecision(3.1415, 2.7182), 1000), ),\n    constraints = constraints,\n    initialization = init,\n    iterations     = 25\n)","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"println(\"Estimated mean of `μ` is \", mean(result.posteriors[:μ][end]), \" with standard deviation \", std(result.posteriors[:μ][end]))\nprintln(\"Estimated mean of `τ` is \", mean(result.posteriors[:τ][end]), \" with standard deviation \", std(result.posteriors[:τ][end]))","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"We observe that the estimates tend to slightly deviate from what the real values are.  This behavior is a known characteristic of inference with the aforementioned constraints, often referred to as Mean Field constraints.","category":"page"},{"location":"manuals/constraints-specification/#General-syntax","page":"Constraints specification","title":"General syntax","text":"","category":"section"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"You can use the @constraints macro with either a regular Julia function or a single begin ... end block. Both ways are valid, as shown below:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"using RxInfer #hide\n\n# `functional` style\n@constraints function create_my_constraints()\n    q(μ, τ) = q(μ)q(τ)\nend\n\n# `block` style\nmyconstraints = @constraints begin \n    q(μ, τ) = q(μ)q(τ)\nend\n\nnothing #hide","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"The function-based syntax can also take arguments, like this:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"@constraints function make_constraints(mean_field)\n    # Specify mean-field only if the flag is `true`\n    if mean_field\n        q(μ, τ) = q(μ)q(τ)\n    end\nend\n\nmyconstraints = make_constraints(true)","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"note: Note\nRxInfer exports MeanField and other prespecified constraints as convenient aliases that can be used directly in the constraints argument of infer. See Prespecified constraints below for more details.","category":"page"},{"location":"manuals/constraints-specification/#Marginal-and-messages-form-constraints","page":"Constraints specification","title":"Marginal and messages form constraints","text":"","category":"section"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"To specify marginal or messages form constraints @constraints macro uses :: operator (in somewhat similar way as Julia uses it for multiple dispatch type specification). Read more about available functional form constraints in the Built-In Functional Forms section.","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"As an example, the following constraint:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"@constraints begin \n    q(x) :: PointMassFormConstraint()\nend","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"indicates that the resulting marginal of the variable (or array of variables) named x must be approximated with a PointMass object. Message passing based algorithms compute posterior marginals as a normalized product of two colliding messages on corresponding edges of a factor graph. In a few words q(x)::PointMassFormConstraint reads as:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"mathrmapproximate q(x) = fracoverrightarrowmu(x)overleftarrowmu(x)int overrightarrowmu(x)overleftarrowmu(x) mathrmdxmathrmasPointMass","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"Sometimes it might be useful to set a functional form constraint on messages too. For example if it is essential to keep a specific Gaussian parametrisation or if some messages are intractable and need approximation. To set messages form constraint @constraints macro uses μ(...) instead of q(...):","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"@constraints begin \n    q(x) :: PointMassFormConstraint()\n    μ(x) :: SampleListFormConstraint(1000)\n    # it is possible to assign different form constraints on the same variable \n    # both for the marginal and for the messages \nend","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"@constraints macro understands \"stacked\" form constraints. For example the following form constraint","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"@constraints begin \n    q(x) :: SampleListFormConstraint(1000) :: PointMassFormConstraint()\nend","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"indicates that the q(x) first must be approximated with a SampleList and in addition the result of this approximation should be approximated as a PointMass. ","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"note: Note\nNot all combinations of \"stacked\" form constraints are compatible between each other.","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"You can find more information about built-in functional form constraint in the Built-in Functional Forms section. In addition, the ReactiveMP library documentation explains the functional form interfaces and shows how to build a custom functional form constraint that is compatible with RxInfer.jl and ReactiveMP.jl inference engine.","category":"page"},{"location":"manuals/constraints-specification/#Factorization-constraints-on-posterior-distribution-q","page":"Constraints specification","title":"Factorization constraints on posterior distribution q","text":"","category":"section"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"As has been mentioned above, inference may be not tractable for every model without extra factorization constraints. To circumvent this, RxInfer.jl allows for extra factorization constraints, for example:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"@constraints begin \n    q(x, y) = q(x)q(y)\nend","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"specifies a so-called mean-field assumption on variables x and y in the model. Furthermore, if x is an array of variables in our model we may induce extra mean-field assumption on x in the following way.","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"@constraints begin \n    q(x) = q(x[begin])..q(x[end])\n    q(x, y) = q(x)q(y)\nend","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"These constraints specify a mean-field assumption between variables x and y (either single variable or collection of variables) and additionally specify mean-field assumption on variables x_i.","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"note: Note\n@constraints macro does not support matrix-based collections of variables. E.g. it is not possible to write q(x[begin, begin])..q(x[end, end]). Use q(x[begin])..q(x[end]) instead.","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"Read more about the @constraints macro in the official documentation of GraphPPL","category":"page"},{"location":"manuals/constraints-specification/#Constraints-in-submodels","page":"Constraints specification","title":"Constraints in submodels","text":"","category":"section"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"RxInfer allows you to define your generative model hierarchically, using previously defined @model modules as submodels in larger models. Because of this, users need to specify their constraints hierarchically as well to avoid ambiguities. Consider the following example:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"@model function inner_inner(τ, y)\n    y ~ Normal(mean = τ[1], var = τ[2])\nend\n\n@model function inner(θ, α)\n    β ~ Normal(mean = 0.0, var = 1.0)\n    α ~ Gamma(shape = β, rate = 1.0)\n    α ~ inner_inner(τ = θ)\nend\n\n@model function outer()\n    local w\n    for i = 1:5\n        w[i] ~ inner(θ = Gamma(shape = 1.0, rate = 1.0))\n    end\n    y ~ inner(θ = w[2:3])\nend","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"To access the variables in the submodels, we use the for q in __submodel__ syntax, which will allow us to specify constraints over variables in the context of an inner submodel:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"@constraints begin\n    for q in inner\n        q(α) :: PointMassFormConstraint()\n        q(α, β) = q(α)q(β)\n    end\nend","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"Similarly, we can specify constraints over variables in the context of the innermost submodel by using the for q in __submodel__ syntax twice:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"@constraints begin\n    for q in inner\n        for q in inner_inner\n            q(y, τ) = q(y)q(τ[1])q(τ[2])\n        end\n        q(α) :: PointMassFormConstraint()\n        q(α, β) = q(α)q(β)\n    end\nend","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"The for q in __submodel__ applies the constraints specified in this code block to all instances of __submodel__ in the current context. If we want to apply constraints to a specific instance of a submodel, we can use the for q in (__submodel__, __identifier__) syntax, where __identifier__ is a counter integer. For example, if we want to specify constraints on the first instance of inner in our outer model, we can do so with the following syntax:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"@constraints begin\n    for q in (inner, 1)\n        q(α) :: PointMassFormConstraint()\n        q(α, β) = q(α)q(β)\n    end\nend","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"Factorization constraints specified in a context propagate to their child submodels. This means that we can specify factorization constraints over variables where the factor node that connects the two are in a submodel, without having to specify the factorization constraint in the submodel itself. For example, if we want to specify a factorization constraint between w[2] and w[3] in our outer model, we can specify it in the context of outer, and RxInfer will recognize that these variables are connected through the Normal node in the inner_inner submodel:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"@constraints begin\n    q(w) = q(w[begin])..q(w[end])\nend","category":"page"},{"location":"manuals/constraints-specification/#Default-constraints","page":"Constraints specification","title":"Default constraints","text":"","category":"section"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"Sometimes, a submodel is used in multiple contexts, on multiple levels of hierarchy and in different submodels. In such cases, it becomes cumbersome to specify constraints for each instance of the submodel and track its usage throughout the model. To alleviate this, RxInfer allows users to specify default constraints for a submodel. These constraints will be applied to all instances of the submodel unless overridden by specific constraints. To specify default constraints for a submodel, override the GraphPPL.default_constraints function for the submodel:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"RxInfer.GraphPPL.default_constraints(::typeof(inner)) = @constraints begin\n    q(α) :: PointMassFormConstraint()\n    q(α, β) = q(α)q(β)\nend","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"More information can be found in the GraphPPL documentation.","category":"page"},{"location":"manuals/constraints-specification/#Constraints-on-the-data","page":"Constraints specification","title":"Constraints on the data","text":"","category":"section"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"By default, RxInfer assumes that, since the data comes into the model as observed, the posterior marginal distribution of the data is independent from other marginals and is a Dirac-delta distribution. However, this assumption breaks when we pass missing data into our model. When the data is missing, we might have a joint dependency between the data and latent variables, as the missing data essentially behaves as a latent variable. In such cases, we can wrap the data in a UnfactorizedData. This will notify the inference engine that the data should not be factorized out and we can specify a custom factorization constraint on these variables using the @constraints macro. ","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"UnfactorizedData","category":"page"},{"location":"manuals/constraints-specification/#RxInfer.UnfactorizedData","page":"Constraints specification","title":"RxInfer.UnfactorizedData","text":"UnfactorizedData{D}\n\nA wrapper struct to wrap data that should not be factorized out by default during inference. When performing Bayesian Inference with message passing, every factor node contains a local factorization constraint on the variational posterior distribution. For data, we usually regarding data as an independent component in the variational posterior distribution. However, in some cases, for example when we are predicting data, we do not want to factorize out the data. In such cases, we can wrap the data with UnfactorizedData struct to prevent the factorization and craft a custom node-local factorization with the @constraints macro.\n\n\n\n\n\n","category":"type"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"unfactorized_example_constraints = @constraints begin\n    q(y[1:1000], μ, τ) = q(y[1:1000])q(μ)q(τ)\n    q(y[1001:1100], μ, τ) = q(y[1001:1100], μ)q(τ)\nend\nresult = infer(\n    model       = iid_normal(),\n    data        = (y = UnfactorizedData(vcat(rand(NormalMeanPrecision(3.1415, 2.7182), 1000), [missing for _ in 1:100])),),\n    constraints = unfactorized_example_constraints, \n    initialization = init,\n    iterations = 25\n)","category":"page"},{"location":"manuals/constraints-specification/#prespecified-constraints","page":"Constraints specification","title":"Prespecified constraints","text":"","category":"section"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"GraphPPL exports some prespecified constraints that can be used in the @constraints macro, but these constraints can also be passed as top-level constraints in the infer function. For example, to specify a mean-field assumption on all variables in the model, we can use the MeanField constraint:","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"result = infer(\n    model       = iid_normal(),\n    data        = (y = rand(NormalMeanPrecision(3.1415, 2.7182), 1000), ),\n    constraints = MeanField(), # instead of using `@constraints` macro\n    initialization = init,\n    iterations  = 25\n)","category":"page"},{"location":"manuals/constraints-specification/","page":"Constraints specification","title":"Constraints specification","text":"","category":"page"},{"location":"contributing/new-release/#contributing-new-release","page":"Publishing a new release","title":"Publishing a new release","text":"","category":"section"},{"location":"contributing/new-release/","page":"Publishing a new release","title":"Publishing a new release","text":"Please read first the general Contributing section. Also, please read the FAQ section in the Julia General registry.","category":"page"},{"location":"contributing/new-release/#Start-the-release-process","page":"Publishing a new release","title":"Start the release process","text":"","category":"section"},{"location":"contributing/new-release/","page":"Publishing a new release","title":"Publishing a new release","text":"In order to start the release process a person with the associated permissions should: ","category":"page"},{"location":"contributing/new-release/","page":"Publishing a new release","title":"Publishing a new release","text":"Open a commit page on GitHub\nWrite the @JuliaRegistrator register comment for the commit:","category":"page"},{"location":"contributing/new-release/","page":"Publishing a new release","title":"Publishing a new release","text":"(Image: Release comment)","category":"page"},{"location":"contributing/new-release/","page":"Publishing a new release","title":"Publishing a new release","text":"The Julia Registrator bot should automatically register a request for the new release. Once all checks have passed on the Julia Registrator's side, the new release will be published and tagged automatically.","category":"page"},{"location":"contributing/new-release/","page":"Publishing a new release","title":"Publishing a new release","text":"","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/#usage-colon-equality","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"","category":"section"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"When specifying probabilistic models in RxInfer, you might be tempted to use the = operator for deterministic relationships between variables. While this may seem natural from a programming perspective (especially if you're coming from other frameworks - see Comparison to other packages), it doesn't align with how Bayesian inference and factor graphs work. Let's explore why RxInfer uses a different approach and how it enables powerful probabilistic modeling.","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/#The-Problem","page":"Using = instead of := for deterministic nodes","title":"The Problem","text":"","category":"section"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"Consider this seemingly reasonable model specification:","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"@model function wrong_model(θ)\n    x ~ MvNormal(mean = [ 0.0, 0.0 ], cov = [ 1.0 0.0; 0.0 1.0 ])\n    y = dot(x, θ)      # This won't work!\n    z ~ Normal(y, 1.0)\nend","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"This code will fail because:","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"During model creation, x is not an actual vector of numbers - it's a reference to a node in the factor graph\nJulia's dot function expects a vector input, not a graph node\nThe = operator performs immediate assignment and executes the dot function, which isn't what we want for building factor graphs","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/#The-Solution","page":"Using = instead of := for deterministic nodes","title":"The Solution","text":"","category":"section"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"Use the := operator for deterministic relationships:","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"@model function correct_model()\n    x ~ MvNormal(mean = [ 0.0, 0.0 ], cov = [ 1.0 0.0; 0.0 1.0 ])\n    y := dot(x, θ)     # This is correct!\n    z ~ Normal(y, 1.0)\nend","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"The := operator:","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"Creates a deterministic node in the factor graph\nProperly tracks dependencies between variables\nAllows RxInfer to handle the computation during inference","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"tip: Tip\nIf you're coming from other probabilistic programming frameworks like Turing.jl, remember that RxInfer uses := for deterministic relationships. While this might seem unusual at first, it's a deliberate design choice that enables powerful message-passing inference algorithms.","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/#Why-Not-?","page":"Using = instead of := for deterministic nodes","title":"Why Not =?","text":"","category":"section"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"RxInfer's design is based on factor graphs, which are probabilistic graphical models that represent the factorization of a joint probability distribution. In a factor graph:","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"Variables are represented as nodes (vertices) in the graph\nFactor nodes connect variables and encode their relationships\nEdges represent the dependencies between variables and factors\nBoth probabilistic (~) and deterministic (:=) relationships create specific types of factor nodes","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"When you specify a model, RxInfer constructs this graph structure where:","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"Each ~ creates a factor node representing that probability distribution\nEach := creates a deterministic factor node representing that transformation\nVariables are automatically connected to their relevant factors\nThe graph captures the complete probabilistic model structure","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"This explicit graph-based design brings several key benefits:","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"Efficient Message Passing: The graph structure enables localized belief propagation, where each node only needs to communicate with its immediate neighbors\nLazy Evaluation: Factor nodes compute messages only when needed during inference, avoiding unnecessary calculations\nFlexible Inference: The same graph structure can support different message-passing schedules and inference algorithms\nModular Updates: Changes in one part of the graph only affect the connected components","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"Using = would break this design because:","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"It executes computations immediately during model specification, before the graph is built\nIt prevents RxInfer from properly tracking the probabilistic dependencies\nIt makes message passing impossible since there's no graph structure to pass messages through","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/#Implementation-Details","page":"Using = instead of := for deterministic nodes","title":"Implementation Details","text":"","category":"section"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"When you write:","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"y := dot(x, θ)","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"RxInfer creates:","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"A deterministic factor node representing the dot function with x and θ as arguments (edges)\nCreates a node for y if it has not been created yet\nProper edges connecting x and θ to this node and this node to y\nMessage passing rules for propagating beliefs through this transformation","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"This structured approach enables efficient inference and maintains the mathematical rigor of the probabilistic model.","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"For more details about model specification, see the Model Specification guide, particularly the section on Deterministic relationships.","category":"page"},{"location":"manuals/sharpbits/usage-colon-equality/","page":"Using = instead of := for deterministic nodes","title":"Using = instead of := for deterministic nodes","text":"","category":"page"},{"location":"manuals/meta-specification/#user-guide-meta-specification","page":"Meta specification","title":"Meta Specification","text":"","category":"section"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"RxInfer.jl utilizes the GraphPPL.jl package to construct a factor graph representing a probabilistic model, and then employs the ReactiveMP.jl package to conduct variational inference through message passing on this factor graph. Some factor nodes within the ReactiveMP.jl inference engine require an additional structure, known as meta-information. This meta-information can serve various purposes such as providing extra details to nodes, customizing the inference process, or adjusting how nodes compute outgoing messages. For example, the AR node, which models Auto-Regressive processes, needs to know the order of the AR process. Similarly, the GCV node (Gaussian Controlled Variance) requires an approximation method to handle non-conjugate relationships between its variables. To address these needs, RxInfer.jl utilizes the @meta macro from the GraphPPL.jl package to specify node-specific meta-information and contextual details.","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"Here, we only touch upon the basics of the @meta macro. For further details, please consult the official documentation of the GraphPPL.jl package.","category":"page"},{"location":"manuals/meta-specification/#General-syntax","page":"Meta specification","title":"General syntax","text":"","category":"section"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"The @meta macro accepts either a regular Julia function or a single begin ... end block:","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"using RxInfer\n\nstruct MetaObject\n    arg1\n    arg2\nend\n\n@meta function create_meta(arg1, arg2)\n    Normal(y, x) -> MetaObject(arg1, arg2)\nend\n\nmy_meta = @meta begin \n    Normal(y, x) -> MetaObject(1, 2)\nend\n\nnothing #hide","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"In the first case, it returns a function that produces an object containing metadata when called. For instance, to specify meta for an AR node with an order of 5, you can do the following:","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"@meta function ARmodel_meta(num_order)\n    AR() -> ARMeta(Multivariate, num_order, ARsafe())\nend\n\nmy_meta = ARmodel_meta(5)\nnothing #hide","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"In the second case, it directly provides the meta object. The same meta for the AR node can also be defined as follows:","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"num_order = 5\n\nmy_meta = @meta begin \n    AR() -> ARMeta(Multivariate, num_order, ARsafe())\nend\nnothing #hide","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"Both syntax variations provide the same meta specification and there is no preference given to one over the other. ","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"Another example:","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"my_meta = @meta begin \n    GCV(x, k, w) -> GCVMetadata(GaussHermiteCubature(20))\nend\nnothing #hide","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"This meta specification indicates that for every GCV node in the model with x, k and w as connected variables should use the GCVMetadata(GaussHermiteCubature(20)) meta object.","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"You can have a list of as many meta specification entries as possible for different nodes:","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"my_meta = @meta begin \n    GCV(x1, k1, w1) -> GCVMetadata(GaussHermiteCubature(20))\n    AR() -> ARMeta(Multivariate, 5, ARsafe())\nend\nnothing #hide","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"The meta-information object can be used in the infer function that accepts meta keyword argument:","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"inferred_result = infer(\n    model = my_model(arguments...),\n    data  = ...,\n    meta  = my_meta,\n    ...\n)","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"Users can also specify metadata for nodes directly inside @model, without the need to use @meta. For example:","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"@model function my_model()\n    ...\n\n    y ~ AR(x, θ, γ) where { meta = ARMeta(Multivariate, 5, ARsafe()) }\n\n    ...\nend","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"If you add node-specific meta to your model this way, you do not need to use the meta keyword argument in the infer function.","category":"page"},{"location":"manuals/meta-specification/#Create-your-own-meta","page":"Meta specification","title":"Create your own meta","text":"","category":"section"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"Although some nodes in RxInfer.jl already come with their own meta structure, users have the flexibility to define different meta structures for those nodes and also for custom ones. A meta structure is created by using the struct statement in Julia. For example, the following snippet of code illustrates how you can create your own meta structures for your custom node. This section provides a concrete example of how to create and use meta in RxInfer.jl. Suppose that we have the following Gaussian model:","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"beginaligned\n x  sim mathrmNormal(25 05)\n y  sim mathrmNormal(2*x 20)\nendaligned","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"where y is observable data and x is a latent variable. In RxInfer.jl, the inference procedure for this model is well defined without the need of specifying any meta data for the Normal node.","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"using RxInfer\n\n#create data\ny_data = 4.0 \n\n#make model\n@model function gaussian_model(y)\n    x ~ NormalMeanVariance(2.5, 0.5)\n    y ~ NormalMeanVariance(2*x, 2.)\nend\n\n#do inference\ninference_result = infer(\n    model = gaussian_model(),\n    data = (y = y_data,)\n)","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"However, let's say we would like to experiment with message update rules and define a new inference procedure by introducing a meta structure to the Normal node that always yields a message equal to Normal distribution with mean m clamped between lower_limit and upper_limit for the outbound messages of the node. This is done as follows:","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"#create your new meta structure for Normal node\nstruct MetaConstrainedMeanNormal{T}\n    lower_limit :: T\n    upper_limit :: T\nend\n\n#define rules with meta for the Normal node\n@rule NormalMeanVariance(:out, Marginalisation) (q_μ::Any, q_v::Any, meta::MetaConstrainedMeanNormal) = begin\n    return NormalMeanVariance(clamp(mean(q_μ), meta.lower_limit, meta.upper_limit), mean(q_v))\nend\n\n@rule NormalMeanVariance(:μ, Marginalisation) (q_out::Any, q_v::Any, meta::MetaConstrainedMeanNormal) = begin\n    return NormalMeanVariance(clamp(mean(q_out), meta.lower_limit, meta.upper_limit), mean(q_v))\nend","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"#make model\n@model function gaussian_model_with_meta(y)\n    x ~ NormalMeanVariance(2.5, 0.5)\n    y ~ NormalMeanVariance(2*x, 2.)\nend\n\ncustom_meta = @meta begin\n    NormalMeanVariance(y) -> MetaConstrainedMeanNormal(-2, 2)\nend\n\n#do inference\ninference_result = infer(\n    model = gaussian_model(),\n    data = (y = y_data,),\n    meta = custom_meta\n)\n\nprintln(\"Estimated mean for latent state `x` is \", mean(inference_result.posteriors[:x]), \" with standard deviation \", std(inference_result.posteriors[:x]))","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"warning: Warning\nThe above example is not mathematically correct. It is only used to show how we can work with @meta as well as how to create a meta structure for a node in RxInfer.jl.","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"Read more about the @meta macro in the official documentation of GraphPPL","category":"page"},{"location":"manuals/meta-specification/#Adding-metadata-to-nodes-in-submodels","page":"Meta specification","title":"Adding metadata to nodes in submodels","text":"","category":"section"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"Similarly to the @constraints macro, the @meta macro exposes syntax to push metadata to nodes in submodels. With the for meta in submodel syntax we can apply metadata to nodes in submodels. For example, if we use the gaussian_model_with_meta mnodel in a larger model, we can write:","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"custom_meta = @meta begin\n    for meta in gaussian_model_with_meta\n        NormalMeanVariance(y) -> MetaConstrainedMeanNormal(-2, 2)\n    end\nend","category":"page"},{"location":"manuals/meta-specification/","page":"Meta specification","title":"Meta specification","text":"","category":"page"},{"location":"manuals/inference/overview/#user-guide-inference-execution","page":"Overview","title":"Inference execution","text":"","category":"section"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"The RxInfer inference API supports different types of message-passing algorithms (including hybrid algorithms combining several different types). While RxInfer implements several algorithms to cater to different computational needs and scenarios, the core message-passing algorithms that form the foundation of our inference capabilities are:","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Belief Propagation\nVariational Message Passing","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Whereas belief propagation computes exact inference for the random variables of interest, the variational message passing (VMP) is an approximation method that can be applied to a larger range of models.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"The inference engine itself isn't aware of different algorithm types and simply does message passing between nodes. However, during the model specification stage user may specify different factorisation constraints around factor nodes with the help of the @constraints macro. Different factorisation constraints lead to different message passing update rules. See more documentation about constraints specification in the corresponding section.","category":"page"},{"location":"manuals/inference/overview/#user-guide-inference-execution-automatic-specification","page":"Overview","title":"Automatic inference specification","text":"","category":"section"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"RxInfer exports the infer function to quickly run and test your model with both static and asynchronous (real-time) datasets. See more information about the infer function on the separate documentation section:","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Static Inference\nStreamlined Inference","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"infer","category":"page"},{"location":"manuals/inference/overview/#RxInfer.infer","page":"Overview","title":"RxInfer.infer","text":"infer(\n    model; \n    data = nothing,\n    datastream = nothing,\n    autoupdates = nothing,\n    initialization = nothing,\n    constraints = nothing,\n    meta = nothing,\n    options = nothing,\n    returnvars = nothing, \n    predictvars = nothing, \n    historyvars = nothing,\n    keephistory = nothing,\n    iterations = nothing,\n    free_energy = false,\n    free_energy_diagnostics = DefaultObjectiveDiagnosticChecks,\n    showprogress = false,\n    callbacks = nothing,\n    addons = nothing,\n    postprocess = DefaultPostprocess(),\n    warn = true,\n    events = nothing,\n    uselock = false,\n    autostart = true,\n    catch_exception = false,\n    session = RxInfer.default_session()\n)\n\nThis function provides a generic way to perform probabilistic inference for batch/static and streamline/online scenarios. Returns either an InferenceResult (batch setting) or RxInferenceEngine (streamline setting) based on the parameters used.\n\nnote: Note\nBefore using this function, you may want to review common issues and solutions in the Sharp bits of RxInfer section of the documentation.\n\nArguments\n\nCheck the official documentation for more information about some of the arguments. \n\nmodel: specifies a model generator, required\ndata: NamedTuple or Dict with data, required (or datastream or predictvars)\ndatastream: A stream of NamedTuple with data, required (or data)\nautoupdates = nothing: auto-updates specification, required for streamline inference, see @autoupdates\ninitialization = nothing: initialization specification object, optional, see @initialization\nconstraints = nothing: constraints specification object, or an alias such as MeanField, optional, see @constraints\nmeta  = nothing: meta specification object, optional, may be required for some models, see @meta\noptions = nothing: model creation options, optional, see ReactiveMPInferenceOptions\nreturnvars = nothing: return structure info, optional, defaults to return everything at each iteration\npredictvars = nothing: return structure info, optional (exclusive for batch inference)\nhistoryvars = nothing: history structure info, optional, defaults to no history (exclusive for streamline inference)\nkeephistory = nothing: history buffer size, defaults to empty buffer (exclusive for streamline inference)\niterations = nothing: number of iterations, optional, defaults to nothing, the inference engine does not distinguish between variational message passing or Loopy belief propagation or expectation propagation iterations\nfree_energy = false: compute the Bethe free energy, optional, defaults to false. Can be passed a floating point type, e.g. Float64, for better efficiency, but disables automatic differentiation packages, such as ForwardDiff.jl\nfree_energy_diagnostics = DefaultObjectiveDiagnosticChecks: free energy diagnostic checks, optional, by default checks for possible NaNs and Infs. nothing disables all checks.\nshowprogress = false: show progress module, optional, defaults to false (exclusive for batch inference)\ncatch_exception  specifies whether exceptions during the inference procedure should be caught, optional, defaults to false (exclusive for batch inference)\ncallbacks = nothing: inference cycle callbacks, optional\naddons = nothing: inject and send extra computation information along messages\npostprocess = DefaultPostprocess(): inference results postprocessing step, optional\nevents = nothing: inference cycle events, optional (exclusive for streamline inference)\nuselock = false: specifies either to use the lock structure for the inference or not, if set to true uses Base.Threads.SpinLock. Accepts custom AbstractLock. (exclusive for streamline inference)\nautostart = true: specifies whether to call RxInfer.start on the created engine automatically or not (exclusive for streamline inference)\nwarn = true: enables/disables warnings\nsession = RxInfer.default_session(): current logging session for the RxInfer invokes, see Session for more details, pass nothing to disable logging\n\nError hints\n\nBy default, RxInfer provides helpful error hints with documentation links, solutions, and troubleshooting guidance.\n\nUse RxInfer.disable_inference_error_hint!() to disable error hints or RxInfer.enable_inference_error_hint!() to enable them. Note that changes to error hint settings require a Julia session restart to take effect.\n\nSee also: RxInfer.disable_inference_error_hint!, RxInfer.enable_inference_error_hint!\n\n\n\n\n\n","category":"function"},{"location":"manuals/inference/overview/#Note-on-NamedTuples","page":"Overview","title":"Note on NamedTuples","text":"","category":"section"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"When passing NamedTuple as a value for some argument, make sure you use a trailing comma for NamedTuples with a single entry. The reason is that Julia treats returnvars = (x = KeepLast()) and returnvars = (x = KeepLast(), ) expressions differently. This first expression creates (or overwrites!) new local/global variable named x with contents KeepLast(). The second expression (note trailing comma) creates NamedTuple with x as a key and KeepLast() as a value assigned for this key.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"using RxInfer #hide\n(x = KeepLast()) # defines a variable `x` with the value `KeepLast()`","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"(x = KeepLast(), ) # defines a NamedTuple with `x` as one of the keys and value `KeepLast()`","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"model","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Also read the Model Specification section.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"The model argument accepts a model specification as its input. The easiest way to create the model is to use the @model macro.  For example:","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"using RxInfer #hide\n\n@model function beta_bernoulli(y, a, b)\n    x  ~ Beta(a, b)\n    y .~ Bernoulli(x)\nend\n\nresult = infer(\n    model = beta_bernoulli(a = 1, b = 1),\n    data  = (y = [ true, false, false ], )\n)\n\nresult.posteriors[:x]","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"note: Note\nThe model keyword argument does not accept a ProbabilisticModel instance as a value, as it needs to inject constraints and meta during the inference procedure.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"data","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Either data or datastream keyword argument are required.  Specifying both data and datastream is not supported and will result in an error. ","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"note: Note\nThe behavior of the data keyword argument depends on the inference setting (batch or streamline).","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"The data keyword argument must be a NamedTuple (or Dict) where keys (of Symbol type) correspond to some arguments defined in the model specification.  For example, if a model defines y in its argument list ","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"using RxInfer #hide\n@model function beta_bernoulli(y, a, b)\n    x  ~ Beta(a, b)\n    y .~ Bernoulli(x)\nend","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"and you want to condition on this argument, then the data field must have an :y key (of Symbol type) which holds the data.  The values in the data must have the exact same shape as its corresponding variable container. E.g. in the exampl above y is being used in the broadcasting  operation, thus it must be a collection of values. a and b arguments, however, could be just single numbers:","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"result = infer(\n    model = beta_bernoulli(),\n    data  = (y = [ true, false, false ], a = 1, b = 1)\n)\n\nresult.posteriors[:x]","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"datastream","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Also read the Streamlined Inference section.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"The datastream keyword argument must be an observable that supports subscribe! and unsubscribe! functions (e.g., streams from the Rocket.jl package). The elements of the observable must be of type NamedTuple where keys (of Symbol type) correspond to input arguments defined in the model specification, except for those which are listed in the @autoupdates specification.  For example, if a model defines y as its argument (which is not part of the @autoupdates specification) the named tuple from the observable must have an :y key (of Symbol type). The values in the named tuple must have the exact same shape as the corresponding variable container.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"initialization","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Also read the Initialization section.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"For specific types of inference algorithms, such as variational message passing, it might be required to initialize (some of) the marginals before running the inference procedure in order to break the dependency loop. If this is not done, the inference algorithm will not be executed due to the lack of information and message and/or marginals will not be updated. In order to specify these initial marginals and messages, you can use the initialization argument in combination with the @initialization macro, such as","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"using RxInfer #hide\ninit = @initialization begin\n    # initialize the marginal distribution of x as a vague Normal distribution\n    # if x is a vector, then it simply uses the same value for all elements\n    # However, it is also possible to provide a vector of distributions to set each element individually \n    q(x) = vague(NormalMeanPrecision)\nend","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"returnvars","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"returnvars specifies latent variables of interest and their posterior updates. Its behavior depends on the inference type: streamline or batch.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Batch inference:","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Accepts a NamedTuple or Dict of return variable specifications.\nTwo specifications available: KeepLast (saves the last update) and KeepEach (saves all updates).\nWhen iterations is set, returns every update for each iteration (equivalent to KeepEach()); if nothing, saves the last update (equivalent to KeepLast()).\nUse iterations = 1 to force KeepEach() for a single iteration or set returnvars = KeepEach() manually.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"result = infer(\n    ...,\n    returnvars = (\n        x = KeepLast(),\n        τ = KeepEach()\n    )\n)","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Shortcut for setting the same option for all variables:","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"result = infer(\n    ...,\n    returnvars = KeepLast()  # or KeepEach()\n)","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Streamline inference:","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"For each symbol in returnvars, infer creates an observable stream of posterior updates.\nAgents can subscribe to these updates using the Rocket.jl package.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"engine = infer(\n    ...,\n    autoupdates = my_autoupdates,\n    returnvars = (:x, :τ),\n    autostart  = false\n)","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"KeepLast\nKeepEach","category":"page"},{"location":"manuals/inference/overview/#RxInfer.KeepLast","page":"Overview","title":"RxInfer.KeepLast","text":"Instructs the inference engine to keep only the last marginal update and disregard intermediate updates.\n\n\n\n\n\n","category":"type"},{"location":"manuals/inference/overview/#RxInfer.KeepEach","page":"Overview","title":"RxInfer.KeepEach","text":"Instructs the inference engine to keep each marginal update for all intermediate iterations.\n\n\n\n\n\n","category":"type"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"predictvars","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"predictvars specifies the variables which should be predicted. Similar to returnvars, predictvars accepts a NamedTuple or Dict. There are two specifications:","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"KeepLast: saves the last update for a variable, ignoring any intermediate results during iterations\nKeepEach: saves all updates for a variable for all iterations","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"result = infer(\n    ...,\n    predictvars = (\n        o = KeepLast(),\n        τ = KeepEach()\n    )\n)","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"note: Note\nThe predictvars argument is exclusive for batch setting.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"historyvars","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Also read the Keeping the history of posteriors.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"historyvars specifies the variables of interests and the amount of information to keep in history about the posterior updates when performing streamline inference. The specification is similar to the returnvars when applied in batch setting. The historyvars requires keephistory to be greater than zero.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"historyvars accepts a NamedTuple or Dict or return var specification. There are two specifications:","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"KeepLast: saves the last update for a variable, ignoring any intermediate results during iterations\nKeepEach: saves all updates for a variable for all iterations","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"result = infer(\n    ...,\n    autoupdates = my_autoupdates,\n    historyvars = (\n        x = KeepLast(),\n        τ = KeepEach()\n    ),\n    keephistory = 10\n)","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"It is also possible to set either historyvars = KeepLast() or historyvars = KeepEach() that acts as an alias and sets the given option for all random variables in the model.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"result = infer(\n    ...,\n    autoupdates = my_autoupdates,\n    historyvars = KeepLast(),\n    keephistory = 10\n)","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"keep_history","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Specifies the buffer size for the updates history both for the historyvars and the free_energy buffers in streamline inference.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"note: Note\nThe historyvars and keep_history arguments are exclusive for streamlined setting.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"iterations","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Specifies the number of variational (or loopy belief propagation) iterations. By default set to nothing, which is equivalent of doing 1 iteration. However, if set explicitly to 1 the default setting for returnvars changes from KeepLast to KeepEach.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"free_energy","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Batch inference:","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Specifies if the infer function should return Bethe Free Energy (BFE) values.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Optionally accepts a floating-point type (e.g., Float64) for improved BFE computation performance, but restricts the use of automatic differentiation packages.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Streamline inference:","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Specifies if the infer function should create an observable stream of Bethe Free Energy (BFE) values, computed at each VMP iteration.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"When free_energy = true and keephistory > 0, additional fields are exposed in the engine for accessing the history of BFE updates.\nengine.free_energy_history: Averaged BFE history over VMP iterations.\nengine.free_energy_final_only_history: BFE history of values computed in the last VMP iterations for each observation.\nengine.free_energy_raw_history: Raw BFE history.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"free_energy_diagnostics","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"This settings specifies either a single or a tuple of diagnostic checks for Bethe Free Energy values stream. By default checks for NaNs and Infs.  See also RxInfer.ObjectiveDiagnosticCheckNaNs and RxInfer.ObjectiveDiagnosticCheckInfs. Pass nothing to disable any checks.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"options","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"RxInfer.ReactiveMPInferenceOptions","category":"page"},{"location":"manuals/inference/overview/#RxInfer.ReactiveMPInferenceOptions","page":"Overview","title":"RxInfer.ReactiveMPInferenceOptions","text":"ReactiveMPInferenceOptions(; kwargs...)\n\nCreates model inference options object. The list of available options is present below.\n\nOptions\n\nlimit_stack_depth: limits the stack depth for computing messages, helps with StackOverflowError for some huge models, but reduces the performance of inference backend. Accepts integer as an argument that specifies the maximum number of recursive depth. Lower is better for stack overflow error, but worse for performance.\nwarn: (optional) flag to suppress warnings. Warnings are not displayed if set to false. Defaults to true.\n\nAdvanced options\n\nscheduler: changes the scheduler of reactive streams, see Rocket.jl for more info, defaults to AsapScheduler.\nrulefallback: specifies a global message update rule fallback for cases when a specific message update rule is not available. Consult ReactiveMP documentation for the list of available callbacks.\n\nSee also: infer\n\n\n\n\n\n","category":"type"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"catch_exception","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"The catch_exception keyword argument specifies whether exceptions during the batch inference procedure should be caught in the error field of the  result. By default, if exception occurs during the inference procedure the result will be lost. Set catch_exception = true to obtain partial result  for the inference in case if an exception occurs. Use RxInfer.issuccess and RxInfer.iserror function to check if the inference completed successfully or failed. If an error occurs, the error field will store a tuple, where first element is the exception itself and the second element is the caught backtrace. Use the stacktrace function  with the backtrace as an argument to recover the stacktrace of the error. Use Base.showerror function to display the error.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"RxInfer.issuccess\nRxInfer.iserror","category":"page"},{"location":"manuals/inference/overview/#RxInfer.issuccess","page":"Overview","title":"RxInfer.issuccess","text":"Checks if the InferenceResult object does not contain an error. \n\n\n\n\n\n","category":"function"},{"location":"manuals/inference/overview/#RxInfer.iserror","page":"Overview","title":"RxInfer.iserror","text":"Checks if the InferenceResult object contains an error. \n\n\n\n\n\n","category":"function"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"callbacks","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"The inference function has its own lifecycle. The user is free to provide some (or none) of the callbacks to inject some extra logging or other procedures in the inference function, e.g.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"result = infer(\n    ...,\n    callbacks = (\n        on_marginal_update = (model, name, update) -> println(\"\\$(name) has been updated: \\$(update)\"),\n        after_inference    = (args...) -> println(\"Inference has been completed\")\n    )\n)","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"The callbacks keyword argument accepts a named-tuple of 'name = callback' pairs.  The list of all possible callbacks for different inference setting (batch or streamline) and their arguments is present below:","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"before_model_creation()\nafter_model_creation(model::ProbabilisticModel)","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Exlusive for batch inference","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"on_marginal_update(model::ProbabilisticModel, name::Symbol, update)\nbefore_inference(model::ProbabilisticModel)\nbefore_iteration(model::ProbabilisticModel, iteration::Int)::Bool\nbefore_data_update(model::ProbabilisticModel, data)\nafter_data_update(model::ProbabilisticModel, data)\nafter_iteration(model::ProbabilisticModel, iteration::Int)::Bool\nafter_inference(model::ProbabilisticModel)","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"note: Note\nbefore_iteration and after_iteration callbacks are allowed to return true/false value. true indicates that iterations must be halted and no further inference should be made.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Exlusive for streamline inference","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"before_autostart(engine::RxInferenceEngine)\nafter_autostart(engine::RxInferenceEngine)","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"addons","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"The addons field extends the default message computation rules with some extra information, e.g. computing log-scaling factors of messages or saving debug-information. Accepts a single addon or a tuple of addons.  Automatically changes the default value of the postprocess argument to NoopPostprocess.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"postprocess","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Also read the Inference results postprocessing section.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"The postprocess keyword argument controls whether the inference results must be modified in some way before exiting the inference function. By default, the inference function uses the DefaultPostprocess strategy, which by default removes the Marginal wrapper type from the results. Change this setting to NoopPostprocess if you would like to keep the Marginal wrapper type, which might be useful in the combination with the addons argument. If the addons argument has been used, automatically changes the default strategy value to NoopPostprocess.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Error hints","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"By default, RxInfer provides helpful error hints when an error occurs during inference. This, for example, includes links to relevant documentation, common solutions and troubleshooting steps, information about where to get help, and suggestions for providing good bug reports.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Use RxInfer.disable_inference_error_hint! to disable error hints or RxInfer.enable_inference_error_hint! to enable them. Note that the change requires a Julia session restart to take effect.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"RxInfer.disable_inference_error_hint!\nRxInfer.enable_inference_error_hint!","category":"page"},{"location":"manuals/inference/overview/#RxInfer.disable_inference_error_hint!","page":"Overview","title":"RxInfer.disable_inference_error_hint!","text":"disable_inference_error_hint!()\n\nDisable error hints that are shown when an error occurs during inference.\n\nThe change requires a Julia session restart to take effect. When disabled, only the raw error will be shown without additional context or suggestions.\n\nSee also: enable_inference_error_hint!, infer\n\n\n\n\n\n","category":"function"},{"location":"manuals/inference/overview/#RxInfer.enable_inference_error_hint!","page":"Overview","title":"RxInfer.enable_inference_error_hint!","text":"enable_inference_error_hint!()\n\nEnable error hints that are shown when an error occurs during inference.\n\nThe change requires a Julia session restart to take effect. When enabled, errors during the inference call will include:\n\nLinks to relevant documentation\nCommon solutions and troubleshooting steps  \nInformation about where to get help\n\nSee also: disable_inference_error_hint!, infer\n\n\n\n\n\n","category":"function"},{"location":"manuals/inference/overview/#Where-to-go-next?","page":"Overview","title":"Where to go next?","text":"","category":"section"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"Read more explanation about the other keyword arguments in the Streamlined (online) inferencesection or check out the Static Inference section or check some more advanced examples.","category":"page"},{"location":"manuals/inference/overview/","page":"Overview","title":"Overview","text":"","category":"page"},{"location":"contributing/new-documentation/#guide-docs-contributing","page":"Contributing to the documentation","title":"Contributing to the documentation","text":"","category":"section"},{"location":"contributing/new-documentation/","page":"Contributing to the documentation","title":"Contributing to the documentation","text":"Contributing to our documentation is a valuable way to enhance the RxInfer ecosystem. To get started, you can follow these steps:","category":"page"},{"location":"contributing/new-documentation/","page":"Contributing to the documentation","title":"Contributing to the documentation","text":"Familiarize Yourself: First, take some time to explore our existing documentation. Understand the structure, style, and content to align your contributions with our standards.\nIdentify Needs: Identify areas that require improvement, clarification, or expansion. These could be missing explanations, code examples, or outdated information.\nFork the Repository: Fork our documentation repository on GitHub to create your own copy. This allows you to work on your changes independently.\nMake Your Edits: Create or modify content in your forked repository. Ensure your contributions are clear, concise, and well-structured.\nSubmit a Pull Request: When you're satisfied with your changes, submit a pull request (PR) to our main repository. Describe your changes in detail in the PR description.\nReview and Feedback: Our documentation maintainers will review your PR. They may provide feedback or request adjustments. Be responsive to this feedback to facilitate the merging process.\nMerging: Once your changes align with our documentation standards, they will be merged into the main documentation. Congratulations, you've successfully contributed to the RxInfer ecosystem!","category":"page"},{"location":"contributing/new-documentation/","page":"Contributing to the documentation","title":"Contributing to the documentation","text":"By following these steps, you can play an essential role in improving and expanding our documentation, making it more accessible and valuable to the RxInfer community.","category":"page"},{"location":"contributing/new-documentation/#Use-[LiveServer.jl](https://github.com/tlienart/LiveServer.jl)","page":"Contributing to the documentation","title":"Use LiveServer.jl","text":"","category":"section"},{"location":"contributing/new-documentation/","page":"Contributing to the documentation","title":"Contributing to the documentation","text":"LiveServer.jl is a simple and lightweight web server developed in Julia. It features live-reload capabilities, making it a valuable tool for automatically refreshing the documentation of a package while you work on its content.","category":"page"},{"location":"contributing/new-documentation/","page":"Contributing to the documentation","title":"Contributing to the documentation","text":"To use LiveServer.jl, simply follow these steps[1]","category":"page"},{"location":"contributing/new-documentation/","page":"Contributing to the documentation","title":"Contributing to the documentation","text":"[1]: Make sure to install the LiveServer and Documenter in your current working environment.","category":"page"},{"location":"contributing/new-documentation/","page":"Contributing to the documentation","title":"Contributing to the documentation","text":"Make sure to import the required packages ","category":"page"},{"location":"contributing/new-documentation/","page":"Contributing to the documentation","title":"Contributing to the documentation","text":"julia> using LiveServer, Documenter","category":"page"},{"location":"contributing/new-documentation/","page":"Contributing to the documentation","title":"Contributing to the documentation","text":"After importing the required packages, you can start the live server with the following command:","category":"page"},{"location":"contributing/new-documentation/","page":"Contributing to the documentation","title":"Contributing to the documentation","text":"julia> servedocs()","category":"page"},{"location":"contributing/new-documentation/","page":"Contributing to the documentation","title":"Contributing to the documentation","text":"","category":"page"},{"location":"examples/overview/#examples-overview","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/overview/","page":"Examples","title":"Examples","text":"All examples for the RxInfer package are available at https://examples.rxinfer.ml/.","category":"page"},{"location":"examples/overview/","page":"Examples","title":"Examples","text":"We welcome community contributions! If you have an interesting example or application of RxInfer, please consider sharing it with the community by submitting it to our examples repository. Visit our contribution guidelines to learn how to contribute.","category":"page"},{"location":"examples/overview/","page":"Examples","title":"Examples","text":"","category":"page"},{"location":"manuals/model-specification/#user-guide-model-specification","page":"Model specification","title":"Model Specification","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"RxInfer largely depends on GraphPPL for model specification. Read extensive documentation regarding the model specification in the corresponding section of GraphPPL documentation. Here we outline only a small portion of model specification capabilities for beginners.","category":"page"},{"location":"manuals/model-specification/#@model-macro","page":"Model specification","title":"@model macro","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"The RxInfer.jl package exports the @model macro for model specification. This @model macro accepts the model specification itself in a form of regular Julia function. ","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"For example: ","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"@model function model_name(model_arguments...)\n    # model specification here\nend","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"where model_arguments... may include both hypeparameters and data. ","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"note: Note\nmodel_arguments are converted to keyword arguments. Positional arguments in the model specification are not supported.  Thus it is not possible to use Julia's multiple dispatch for the model arguments.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"The @model macro returns a regular Julia function (in this example model_name()) which can be executed as usual. The only difference here is that all arguments of the model function are treated as keyword arguments. Upon calling, the model function returns a so-called model generator object, e.g:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"using RxInfer #hide\n@model function my_model(observation, hyperparameter)\n    observations ~ Normal(mean = 0.0, var = hyperparameter)\nend","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"model = my_model(hyperparameter = 3)\nnothing #hide","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"The model generator is not a real model (yet). For example, in the code above, we haven't specified anything for the observation.  The generator object allows us to iteratively add extra properties to the model, condition on data, and/or assign extra metadata information without actually materializing the entire graph structure. Read extra information about model generator here.","category":"page"},{"location":"manuals/model-specification/#A-state-space-model-example","page":"Model specification","title":"A state space model example","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"Here we give an example of a probabilistic model before presenting the details of the model specification syntax. The model below is a simple state space model with latent random variables x and noisy observations y.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"using RxInfer #hide\n\n@model function state_space_model(y, trend, variance)\n    x[1] ~ Normal(mean = 0.0, variance = 100.0)\n    y[1] ~ Normal(mean = x[1], variance = variance)\n    for i in 2:length(y)\n       x[i] ~ Normal(mean = x[i - 1] + trend, variance = 1.0)\n       y[i] ~ Normal(mean = x[i], variance = variance)\n    end\nend","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"In this model we assign a prior distribution over latent state x[1]. All subsequent states x[i] depend on x[i - 1] and trend and are modelled  as a simple Gaussian random walk. Observations y are modelled with the Gaussian distribution as well with a  prespecified variance hyperparameter.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"note: Note\nlength(y) can be called only if y has an associated data with it. This is not always the case, for example it is possible to instantiate the  model lazily before the data becomes available. In such situations, length(y) will throw an error.","category":"page"},{"location":"manuals/model-specification/#user-guide-model-specification-hyperparameters","page":"Model specification","title":"Hyperparameters","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"Any constant passed to a model as a model argument will be automatically converted to a corresponding constant node in the model's graph.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"model = state_space_model(trend = 3.0, variance = 1.0)\nnothing #hide","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"In this example we instantiate a model generator with trend and variance parameters clamped to 3.0 and 1.0 respectively. That means  that no inference will be performed for those parameters and some of the expressions within the model structure might be simplified and compiled-out.","category":"page"},{"location":"manuals/model-specification/#user-guide-model-specification-conditioning","page":"Model specification","title":"Conditioning on data","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"To fully complete model specification we need to specify y. In this example, y is playing a role of observations. RxInfer provides a convenient mechanism to pass data values to the model with the | operator.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"conditioned = model | (y = [ 0.0, 1.0, 2.0 ], )","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"note: Note\nThe conditioning on data is a feature of RxInfer, not GraphPPL.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"In the example above we conditioned on data in a form of the NamedTuple, but it is also possible to  condition on a dictionary where keys represent names of the corresponding model arguments:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"data        = Dict(:y => [ 0.0, 1.0, 2.0 ])\nconditioned = model | data","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"Sometimes it might be useful to indicate that some arguments are data (thus condition on them) before the actual data becomes available. This situation may occur during reactive inference, when data becomes available after model creation. RxInfer provides a special structure called RxInfer.DeferredDataHandler, which can be used instead of the real data.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"For the example above, however, we cannot simply do the following:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"model | (y = RxInfer.DeferredDataHandler(), )","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"because we use length(y) in the model and this is only possible if y has an associated data.  We could adjust the model specification a bit, by adding the extra n parameter to the list of arguments:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"@model function state_space_model_with_n(y, n, trend, variance)\n    x[1] ~ Normal(mean = 0.0, variance = 100.0)\n    y[1] ~ Normal(mean = x[1], variance = variance)\n    for i in 2:n\n       x[i] ~ Normal(mean = x[i - 1] + trend, variance = 1.0)\n       y[i] ~ Normal(mean = x[i], variance = variance)\n    end\nend","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"For such model, we can safely condition on y without providing actual data for it, but using the RxInfer.DeferredDataHandler instead:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"state_space_model_with_n(trend = 3.0, variance = 1.0, n = 10) | (\n    y = RxInfer.DeferredDataHandler(), \n)","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"Read more information about condition on data in this section of the documentation.","category":"page"},{"location":"manuals/model-specification/#user-guide-model-specification-random-variables","page":"Model specification","title":"Latent variables","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"Latent variables are being created with the ~ operator and can be read as is distributed as.  For example, to create a latent variable y which is modeled by a Normal distribution,  where its mean and variance are controlled by the random variables m and v respectively, we define","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"y ~ Normal(mean = m, variance = v)","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"In the example above","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"x[1] ~ Normal(mean = 0.0, variance = 100.0)","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"indicates that x₁ is distributed as Normal distribution. ","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"note: Note\nThe RxInfer.jl package uses the ~ operator for modelling both stochastic and deterministic relationships between random variables. However, GraphPPL.jl also allows to use := operator for deterministic relationships.","category":"page"},{"location":"manuals/model-specification/#user-guide-model-specification-node-creation","page":"Model specification","title":"Relationships between variables","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"In probabilistic models based on graphs, factor nodes are used to define a relationship between random variables and/or constants and data variables. A factor node defines a probability distribution over selected latent or data variables. The ~ operator not only creates a latent variable but also  defines a functional relatinship of it with other variables and creates a factor node as a result.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"In the example above","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"x[1] ~ Normal(mean = 0.0, variance = 100.0)","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"not only creates a latent variable x₁ but also a factor node Normal.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"note: Note\nGenerally it is not necessary to label all the arguments with their names, as mean = ... or variance = ... and many factor nodes  do not require it explicitly. However, for nodes, which have many different useful parametrizations (e.g. Normal) labeling the arguments  is a requirement that helps to avoid any possible confusion. Read more about Distributions compatibility here.","category":"page"},{"location":"manuals/model-specification/#user-guide-model-specification-node-creation-deterministic","page":"Model specification","title":"Deterministic relationships","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"In contrast to other probabilistic programming languages in Julia, RxInfer does not allow use of = operator for creating deterministic relationships between (latent)variables.  Instead, we can use := operator for this purpose. For example:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"t ~ Normal(mean = 0.0, variance = 1.0)\nx := exp(t) # x is linked deterministically to t\ny ~ Normal(mean = x, variance = 1.0)","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"Using x = exp(t) directly would be incorrect and most likely would result in an MethodError because t does not have a definitive value at the model creation time  (remember that our models create a factor graph under the hood and latent states do not have a value until the inference is performed).","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"See Using = instead of := for deterministic nodes for a detailed explanation of this design choice.","category":"page"},{"location":"manuals/model-specification/#user-guide-model-specification-node-creation-control-flow","page":"Model specification","title":"Control flow statements","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"In general, it is possible to use any Julia code within model specification function, including control flow statements, such as for, while and if statements. However, it is not possible to use any latent states within such statements. This is due to the fact that it is necessary to know exactly the structure of the graph before the inference. Thus it is not possible to write statements like:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"c ~ Categorical([ 1/2, 1/2 ])\n# This is NOT possible in `RxInfer`'s model specification language\nif c > 1\n# ...\nend","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"since c must be statically known upon graph creation.","category":"page"},{"location":"manuals/model-specification/#user-guide-model-specification-node-creation-anonymous","page":"Model specification","title":"Anonymous factor nodes and latent variables","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"The @model macro automatically resolves any inner function calls into anonymous factor nodes and latent variables.  For example the following:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"y ~ Normal(\n    mean = Normal(mean = 0.0, variance = 1.0), \n    precision = Gamma(shape = 1.0, rate = 1.0)\n)","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"is equivalent to","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"tmp1 ~ Normal(mean = 0.0, variance = 1.0)\ntmp2 ~ Gamma(shape = 1.0, rate = 1.0)\ny    ~ Normal(mean = tmp1, precision = tmp2)","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"The inference backend still performs inference for anonymous latent variables, however, there it does not provide an easy way to obtain posteriors for them. Note that the inference backend will try to optimize deterministic function calls in the case where all arguments are known in advance. For example:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"y ~ Normal(mean = 0.0, variance = inv(2.0))","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"should not create an extra factor node for the inv, since inv is a deterministic function and all arguments are known in advance. The same situation applies in case of complex initializations involving different types, as in:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"y ~ MvNormal(mean = zeros(3), covariance = Matrix(Diagonal(ones(3))))","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"In this case, the expression Matrix(Diagonal(ones(3))) can (and will) be precomputed upon model creation and does not require to perform probabilistic inference.","category":"page"},{"location":"manuals/model-specification/#user-guide-model-specification-node-creation-indexing","page":"Model specification","title":"Indexing operations","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"The ref expressions, such as x[i], are handled in a special way. Technically, in Julia, the x[i] call is translated to a function call getindex(x, i). Thus the @model macro should create a factor node for the getindex function, but this won't happen in practice because this case is treated separately. This means that the model parser will not create unnecessary nodes when only simple indexing is involved. That also means that all expressions inside x[...] list are left untouched during model parsing. ","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"warning: Warning\nIt is not allowed to use latent variables within square brackets in the model specification or for control flow statements such as if, for or while.","category":"page"},{"location":"manuals/model-specification/#user-guide-model-specification-node-creation-broadcasting","page":"Model specification","title":"Broadcasting syntax","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"GraphPPL support broadcasting for ~ operator in the exact same way as Julia itself.  A user is free to write an expression of the following form:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"m  ~ Normal(mean = 0.0, precision = 0.0001)\nt  ~ Gamma(shape = 1.0, rate = 1.0)\ny .~ Normal(mean = m, precision = t)","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"More complex expressions are also allowed:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"w         ~ Wishart(3, diageye(2))\nx[1]      ~ MvNormal(mean = zeros(2), precision = diageye(2))\nx[2:end] .~ A .* x[1:end-1] # <- State-space model with transition matrix A\ny        .~ MvNormal(mean = x, precision = w) # <- Observations with unknown precision matrix","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"Note, however, that shapes of all variables that take part in the broadcasting operation must be defined in advance. That means that it is not possible to  use broadcasting with deffered data. Read more about how broadcasting machinery works in Julia in the official documentation.","category":"page"},{"location":"manuals/model-specification/#user-guide-model-specification-distributions","page":"Model specification","title":"Distributions.jl compatibility","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"For some factor nodes we rely on the syntax from Distributions.jl to make it easy to adopt RxInfer.jl for these users. These nodes include for example the Beta and Wishart distributions. These nodes can be created using the ~ syntax with the arguments as specified in Distributions.jl. Unfortunately, we RxInfer.jl is not yet compatible with all possible distributions to be used as factor nodes. If you feel that you would like to see another node implemented, please file an issue.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"note: Note\nTo quickly check the list of all available factor nodes that can be used in the model specification language call ?ReactiveMP.is_predefined_node or Base.doc(ReactiveMP.is_predefined_node).","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"Specifically for the Gaussian/Normal case we have custom implementations that yield a higher computational efficiency and improved stability in comparison to Distributions.jl as these are optimized for sampling operations. Our aliases for these distributions therefore do not correspond to the implementations from Distributions.jl. However, our model specification language is compatible with syntax from Distributions.jl for normal distributions, which will be automatically converted. RxInfer has its own implementation because of the following 3 reasons:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"Distributions.jl constructs normal distributions by saving the corresponding covariance matrices in a PDMat object from PDMats.jl. This construction always computes the Cholesky decompositions of the covariance matrices, which is very convenient for sampling-based procedures. However, in RxInfer.jl we mostly base our computations on analytical expressions which do not always need to compute the Cholesky decomposition. In order to reduce the overhead that Distributions.jl introduces, we therefore have custom implementations.\nDepending on the update rules, we might favor different parameterizations of the normal distributions. ReactiveMP.jl has quite a variety in parameterizations that allow us to efficient computations where we convert between parameterizations as little as possible.\nIn certain situations we value stability a lot, especially when inverting matrices. PDMats.jl, and hence Distributions.jl, is not capable to fulfill all needs that we have here. Therefore we use PositiveFactorizations.jl to cope with the corner-cases.","category":"page"},{"location":"manuals/model-specification/#user-guide-model-specification-visualization","page":"Model specification","title":"Model structure visualisation","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"Models specified using GraphPPL.jl in RxInfer.jl can be visualized in several ways to help understand their structure and relationships between variables. Let's create a simple model and visualize it.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"using RxInfer\n\n@model function coin_toss(y)\n    t ~ Beta(1, 1)\n    for i in eachindex(y)\n        y[i] ~ Bernoulli(t)\n    end\nend\n\nmodel_generator = coin_toss() | (y = [ true, false, true ], )\nmodel_to_plot   = RxInfer.getmodel(RxInfer.create_model(model_generator))\nnothing #hide","category":"page"},{"location":"manuals/model-specification/#user-guide-model-specification-visualization-graphviz","page":"Model specification","title":"GraphViz.jl","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"It is possible to visualize the model structure after conditioning on data with the GraphViz.jl package. Note that this package is not included in the RxInfer package and must be installed separately.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"using GraphViz\n\n# Call `load` function from `GraphViz` to visualise the structure of the graph\nGraphViz.load(model_to_plot, strategy = :simple)","category":"page"},{"location":"manuals/model-specification/#user-guide-model-specification-visualization-cairo","page":"Model specification","title":"Cairo","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"There is an alternative way to visuzalise the model structure with Cairo and GraphPlot Note, that those packages are also not included in the RxInfer package and must be installed separately.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"using Cairo, GraphPlot\n\n# Call `gplot` function from `GraphPlot` to visualise the structure of the graph\nGraphPlot.gplot(model_to_plot)","category":"page"},{"location":"manuals/model-specification/#Node-Contraction","page":"Model specification","title":"Node Contraction","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"RxInfer's model specification extension for GraphPPL supports a feature called node contraction. This feature allows you to contract (or replace) a submodel with a corresponding factor node. Node contraction can be useful in several scenarios:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"When running inference in a submodel is computationally expensive\nWhen a submodel contains many variables whose inference results are not of primary importance\nWhen specialized message passing update rules can be derived for variables in the Markov blanket of the submodel","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"Let's illustrate this concept with a simple example. We'll first create a basic submodel and then allow the inference backend to replace it with a corresponding node that has well-defined message update rules.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"using RxInfer, Plots\n\n@model function ShiftedNormal(data, mean, precision, shift)\n    shifted_mean := mean + shift\n    data ~ Normal(mean = shifted_mean, precision = precision)\nend\n\n@model function Model(data, precision, shift)\n    mean ~ Normal(mean = 15.0, var = 1.0)\n    data ~ ShiftedNormal(mean = mean, precision = precision, shift = shift)\nend\n\nresult = infer(\n    model = Model(precision = 1.0, shift = 1.0),\n    data  = (data = 10.0, )\n)\n\nplot(title = \"Inference results over `mean`\")\nplot!(0:0.1:20.0, (x) -> pdf(NormalMeanVariance(15.0, 1.0), x), label = \"prior\", fill = 0, fillalpha = 0.2)\nplot!(0:0.1:20.0, (x) -> pdf(result.posteriors[:mean], x), label = \"posterior\", fill = 0, fillalpha = 0.2)\nvline!([ 10.0 ], label = \"data point\")","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"As we can see, we can run inference on this model. We can also visualize the model's structure, as shown in the Model structure visualisation section.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"using Cairo, GraphPlot\n\nGraphPlot.gplot(getmodel(result.model))","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"Now, let's create an optimized version of the ShiftedNormal submodel as a standalone node with its own message passing update rules.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"note: Note\nCreating correct message passing update rules is beyond the scope of this section. For more information about custom message passing update rules, refer to the Custom Node section.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"@node typeof(ShiftedNormal) Stochastic [ data, mean, precision, shift ]\n\n@rule typeof(ShiftedNormal)(:mean, Marginalisation) (q_data::PointMass, q_precision::PointMass, q_shift::PointMass, ) = begin \n    return @call_rule NormalMeanPrecision(:μ, Marginalisation) (q_out = PointMass(mean(q_data) - mean(q_shift)), q_τ = q_precision)\nend\n\nresult_with_contraction = infer(\n    model = Model(precision = 1.0, shift = 1.0),\n    data  = (data = 10.0, ),\n    allow_node_contraction = true\n)\nusing Test #hide\n@test result.posteriors[:mean] ≈ result_with_contraction.posteriors[:mean] #hide\n\nplot(title = \"Inference results over `mean` with node contraction\")\nplot!(0:0.1:20.0, (x) -> pdf(NormalMeanVariance(15.0, 1.0), x), label = \"prior\", fill = 0, fillalpha = 0.2)\nplot!(0:0.1:20.0, (x) -> pdf(result_with_contraction.posteriors[:mean], x), label = \"posterior\", fill = 0, fillalpha = 0.2)\nvline!([ 10.0 ], label = \"data point\")","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"As you can see, the inference result is identical to the previous case. However, the structure of the model is different:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"GraphPlot.gplot(getmodel(result_with_contraction.model))","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"With node contraction, we no longer have access to the variables defined inside the ShiftedNormal submodel, as it has been contracted to a single factor node. It's worth noting that this feature heavily relies on existing message passing update rules for the submodel. However, it can also be combined with another useful inference technique where no explicit message passing update rules are required.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"We can also verify that node contraction indeed improves the performance of the inference:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"using BenchmarkTools\n\nbenchmark_session = nothing #hide\n\nbenchmark_without_contraction = @benchmark infer(\n    model = Model(precision = 1.0, shift = 1.0),\n    data  = (data = 10.0, ),\n    session = benchmark_session #hide\n)\n\nbenchmark_with_contraction = @benchmark infer(\n    model = Model(precision = 1.0, shift = 1.0),\n    data  = (data = 10.0, ),\n    allow_node_contraction = true,\n    session = benchmark_session #hide\n)\n\nusing Test #hide\n@test benchmark_with_contraction.allocs < benchmark_without_contraction.allocs #hide\n@test mean(benchmark_with_contraction.times) < mean(benchmark_without_contraction.times) #hide\n@test median(benchmark_with_contraction.times) < median(benchmark_without_contraction.times) #hide\n@test minimum(benchmark_with_contraction.times) < minimum(benchmark_without_contraction.times) #hide\nnothing #hide","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"Let's examine the benchmark results:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"benchmark_without_contraction","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"benchmark_with_contraction","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"As we can see, the inference with node contraction runs faster due to the simplified model structure and optimized message update rules.  This performance improvement is reflected in reduced execution time and fewer memory allocations.","category":"page"},{"location":"manuals/model-specification/#user-guide-model-specification-node-creation-options","page":"Model specification","title":"Node creation options","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"GraphPPL allows to pass optional arguments to the node creation constructor with the where { options...  } options specification syntax.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"Example:","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"y ~ Normal(mean = y_mean, var = y_var) where { meta = ... }","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"A list of the available options specific to the ReactiveMP inference engine is presented below.","category":"page"},{"location":"manuals/model-specification/#Metadata-option","page":"Model specification","title":"Metadata option","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"Is is possible to pass any extra metadata to a factor node with the meta option. Metadata can be later accessed in message computation rules.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"z ~ f(x, y) where { meta = Linearization() }\nd ~ g(a, b) where { meta = Unscented() }","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"This option might be useful to change message passing rules around a specific factor node. Read more about this feature in Meta Specification section.","category":"page"},{"location":"manuals/model-specification/#Dependencies-option","page":"Model specification","title":"Dependencies option","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"A user can modify default computational pipeline of a node with the dependencies options.  Read more about different options in the ReactiveMP.jl documentation.","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"y[k - 1] ~ Probit(x[k]) where {\n    # This specification indicates that in order to compute an outbound message from the `in` interface\n    # We need an inbound message from the same edge initialized to `NormalMeanPrecision(0.0, 1.0)`\n    dependencies = RequireMessageFunctionalDependencies(in = NormalMeanPrecision(0.0, 1.0))\n}","category":"page"},{"location":"manuals/model-specification/#Read-also","page":"Model specification","title":"Read also","text":"","category":"section"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"Constraints specification\nMeta specification\nInference execution\nDebugging inference","category":"page"},{"location":"manuals/model-specification/","page":"Model specification","title":"Model specification","text":"","category":"page"},{"location":"manuals/customization/custom-node/#create-node","page":"Defining a custom node and rules","title":"Creating your own custom nodes","text":"","category":"section"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Welcome to the RxInfer documentation on creating custom factor graph nodes. In RxInfer, factor nodes represent functional relationships between variables, also known as factors. Together, these factors define your probabilistic model. Quite often these factors represent distributions, denoting how a certain parameter affects another. However, other factors are also possible, such as ones specifying linear or non-linear relationships. RxInfer already supports a lot of factor nodes, however, depending on the problem that you are trying to solve, you may need to create a custom node that better fits the specific requirements of your model. This tutorial will guide you through the process of defining a custom node in RxInfer, step by step. By the end of this tutorial, you will be able to create your own custom node and integrate it into your model.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"In addition, read another section on a different way of running inference with custom stochastic nodes without explicit rule specification here.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"To create a custom node in RxInfer, 4 steps are required:","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Create your custom node in RxInfer using the @node macro.\nDefine the corresponding message passing update rules with the @rule macro. These rules specify how the node processes information in the form of messages, and how it communicates the results to adjacent parts of the model.\nSpecify computations for marginal distributions of the relevant variables with the @marginalrule macro.\nImplement the computation of the Free Energy in a node with the @average_energy macro.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Throughout this tutorial, we will create a node for the Bernoulli distribution. The Bernoulli distribution is a commonly used distribution in statistical modeling that is often used to model a binary outcome, such as a coin flip. By recreating this node, we will be able to demonstrate the process of creating a custom node, from notifying RxInfer of the nodes existence to implementing the required methods. While this tutorial focuses on the Bernoulli distribution, the principles can be applied to creating custom nodes for other distributions as well. So let's get started!","category":"page"},{"location":"manuals/customization/custom-node/#Problem-statement","page":"Defining a custom node and rules","title":"Problem statement","text":"","category":"section"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Jane wants to determine whether a coin is a fair coin, meaning that is equally likely to land on heads or tails. In order to determine this, she will throw the coin K=20 times and write down how often it lands on heads and tails. The result of this experiment is a realization of the underlying stochastic process. Jane models the outcome of the experiment x_kin01 using the Bernoulli distribution as","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"p(x_k mid pi) = mathrmBer(x_k mid pi) = pi^x_k (1-pi)^1-x_k","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"where pi in01 denotes the probability that she throws heads, also known as the success probability. Jane also has a prior belief (initial guess) about the value of pi which she models using the Beta distribution as","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"p(pi) = mathrmBeta(pi mid 4 8)","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"With this prior belief, the total probabilistic model that she has for this experiment is given by","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"p(x_1K pi) = p(pi) prod_k=1^K p(x_k mid pi)","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Jane is interested in determining the fairness of the coin. Therefore she aims to infer (calculate) the posterior belief of pi, p(pi mid x_1K), denoting how pi is distributed after we have seen the data.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"","category":"page"},{"location":"manuals/customization/custom-node/#Step-1:-Creating-the-custom-node","page":"Defining a custom node and rules","title":"Step 1: Creating the custom node","text":"","category":"section"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"note: Note\nIn this example we will assume that the Bernoulli node and distribution do not yet exist. The RxInfer already defines the node for the Bernoulli distribution from the Distributions.jl package.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"First things first, let's import RxInfer:","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"using RxInfer","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"In order to define a custom node using the @node macro from ReactiveMP, we need the following three arguments:","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"The name of the node.\nWhether the node is Deterministic or Stochastic.\nThe interfaces of the node and any potential aliases.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"For the name of the node we wish to use MyBernoulli in this tutorial (Bernoulli already exists). However, the corresponding distribution does not yet exist. Therefore we need to specify it first as","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"# struct for Bernoulli distribution with success probability π\nstruct MyBernoulli{T <: Real} <: ContinuousUnivariateDistribution\n    π :: T\nend\n\n# for simplicity, let's also specify the mean of the distribution\nDistributions.mean(d::MyBernoulli) = d.π\n\nnothing # hide","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"note: Note\nYou can use regular functions, e.g + as a node type. Their Julia type, however, is written with the typeof(_) specification, e.g. typeof(+)","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"For our node we are dealing with a stochastic node, because the node forms a probabilistic relationship. This means that for a given value of pi, we do know the corresponding value of the output, but we do have some belief about this. Deterministic nodes include for example linear and non-linear transformation, such as + or *.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"The interfaces specify what variables are connected to the node. The first argument is its output by convention. The ordering is important for both the model specification as the rule definition. As an example consider the NormalMeanVariance factor node. This factor node has interfaces [out, μ, v] and can be called in the model specification language as x ~ NormalMeanVariance(μ, v). It is also possible to use aliases for the interfaces, which can be specified in a tuple as you will see below.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Concluding, we can create the MyBernoulli factor node as","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"@node MyBernoulli Stochastic [out, (π, aliases = [p])]","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Cool! Step 1 is done, we have created a custom node.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"","category":"page"},{"location":"manuals/customization/custom-node/#Step-2:-Defining-rules-for-our-node","page":"Defining a custom node and rules","title":"Step 2: Defining rules for our node","text":"","category":"section"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"In order for RxInfer to perform probabilistic inference and compute posterior distributions, such as p(pimid x_1K), we need to tell it how to perform inference locally around our node. This localization is what makes RxInfer achieve high performance. In our message passing-based paradigm, we need to describe how the node processes incoming information in the form of messages (or marginals). Here we will highlight two different message passing strategies: sum-product message passing and variational message passing.","category":"page"},{"location":"manuals/customization/custom-node/#Sum-product-message-passing-update-rules","page":"Defining a custom node and rules","title":"Sum-product message passing update rules","text":"","category":"section"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"In sum-product message passing we compute outgoing messages to our node as","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"vecmu(x) propto int mathrmBer(xmid pi) vecmu(pi) mathrmdx","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"overleftarrowmu(pi) propto sum_x in 01 mathrmBer(xmid pi) overleftarrowmu(x)","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"This integral does not always have nice tractable solutions. However, for some forms of the incoming messages, it does yield a tractable solution.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"For the case of a Beta message coming into our node, the outgoing message will be the predictive posterior of the Bernoulli distribution with a Beta prior. Here we obtain pi = fracalphaalpha + beta, which coincides with the mean of the Beta distribution. Hence, we can write down the first update rule using the @rule macro as","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"@rule MyBernoulli(:out, Marginalisation) (m_π :: Beta,) = MyBernoulli(mean(m_π))","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Here, :out refers to the interface of the outgoing message. The second argument denotes the incoming messages (which can be typed) as a tuple. Therefore make sure that it has a trailing , when there is a single message coming in. m_π is shorthand for the incoming message on interface π. As we will see later, the structured approximation update rule for incoming message from π will have q_π as parameter.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"The second rule is also straightforward; if π is a PointMass and therefore fixed, the outgoing message will be MyBernoulli(π):","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"@rule MyBernoulli(:out, Marginalisation) (m_π :: PointMass,) = MyBernoulli(mean(m_π))","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Continuing with the sum-product update rules, we now have to define the update rules towards the π interface. We can only do exact inference if the incoming message is known, which in the case of the Bernoulli distribution, means that the out message is a PointMass distribution that is either 0 or 1. The updated Beta distribution for π will be:","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"overleftarrowmu(π) propto mathrmBeta(1 + x 2 - x)","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Which gives us the following update rule:","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"@rule MyBernoulli(:π, Marginalisation) (m_out :: PointMass,) = begin\n    p = mean(m_out)\n    return Beta(one(p) + p, 2one(p) - p)\nend","category":"page"},{"location":"manuals/customization/custom-node/#Variational-message-passing-update-rules","page":"Defining a custom node and rules","title":"Variational message passing update rules","text":"","category":"section"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"We will now cover our second set of update rules. The sum-product messages are not always tractable and therefore we may need to resort to approximations. Here we highlight the variational approximation. In variational message passing we compute outgoing messages to our node as","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"vecnu(x) propto exp int q(pi) ln mathrmBer(xmid pi) mathrmdx","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"overleftarrownu(pi) propto exp sum_x in 01 q(x) ln mathrmBer(xmid pi)","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"These messages depend on the marginals on the adjacent edges and not on the incoming messages as was the case with sum-product message passing. Update rules that operate on the marginals instead of the incoming messages are specified with the q_{interface} argument names. With these update rules, we can often support a wider family of distributions. Below we directly give the variational update rules. Deriving them yourself will be a nice challenge.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"#rules towards out\n@rule MyBernoulli(:out, Marginalisation) (q_π :: PointMass,) = MyBernoulli(mean(q_π))\n\n@rule Bernoulli(:out, Marginalisation) (q_π::Any,) = begin\n    rho_1 = mean(log, q_π)          # E[ln(x)]\n    rho_2 = mean(mirrorlog, q_π)    # E[log(1-x)]\n    m = max(rho_1, rho_2)\n    tmp = exp(rho_1 - m)\n    p = clamp(tmp / (tmp + exp(rho_2 - m)), tiny, one(m))\n    return Bernoulli(p)\nend\n\n#rules towards π\n@rule MyBernoulli(:π, Marginalisation) (q_out :: Any,) = begin\n    p = mean(q_out)\n    return Beta(one(p) + p, 2one(p) - p)\nend","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"note: Note\nTypically, the type of the variational distributions q_ does not matter in the real computations, but only their statistics, e.g mean or var. Thus, in this case, we may safely use ::Any.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"In the example that we will show later on, we solely use sum-product message passing. Variational message passing requires us to set the local constraints in our model, something which is out of scope of this tutorial.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"","category":"page"},{"location":"manuals/customization/custom-node/#Step-3:-Defining-joint-marginals-for-our-node","page":"Defining a custom node and rules","title":"Step 3: Defining joint marginals for our node","text":"","category":"section"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"The entire probabilistic model can be scored using the Bethe free energy, which bounds the log-evidence for acyclic graphs. This Bethe free energy consists out of the sum of node-local entropies, negative node-local average energies and edge specific entropies. Formally we can denote this by","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Fqf = - sum_ainmathcalV mathrmHq_a(s_a) - sum_ainmathcalVmathrmE_q_a(s_a)ln f_a(s_a) + sum_iinmathcalEmathrmHq_i(s_i)","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Here we call q_a(s_a) the joint marginals around a node and -mathrmE_q_a(s_a)ln f_a(s_a) we term the average energy.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"In order to be able to compute the Bethe free energy, we need to first describe how to compute q_a(s_a), defined in our case as ","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"q(x_k pi) = vecmu(pi) overleftarrowmu(x_k) mathrmBer(x_k mid pi)","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"To calculate the updated posterior marginal for our custom distribution, we need to return joint posterior marginals for the interfaces of our node. In our case, the posterior marginal for the observation is still the same PointMass distribution. However, to calculate the posterior marginal over π, we use RxInfer's built-in prod functionality to multiply the Beta prior with the Beta likelihood. This gives us the updated posterior distribution, which is also a Beta distribution. We use PreserveTypeProd(Distribution) parameter to ensure that we multiply the two distributions analytically. This is done as follows:","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"@marginalrule MyBernoulli(:out_π) (m_out::PointMass, m_π::Beta) = begin\n    r = mean(m_out)\n    p = prod(PreserveTypeProd(Distribution), Beta(one(r) + r, 2one(r) - r), m_π)\n    return (out = m_out, p = p)\nend","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"In this code :out_π describes the arguments of the joint marginal distribution. The second argument contains the incoming messages. Here we know from the model specification that we observe out and therefore this has to be a PointMass. Because it is a PointMass, the joint marginal automatically factorizes as q(x_k pi) = q(x_k)q(pi). These are the distributions that we return in a form of the NamedTuple. NamedTuple is used only in cases where we know that the joint marginal factorizes further, but typically it should be a full distribution. For computing q(pi) we need to compute the product vecmu(pi)overleftarrowmu(pi). We already know how overleftarrowmu(pi) looks like from the previous step, so we can just use the prod function.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"","category":"page"},{"location":"manuals/customization/custom-node/#Step-4:-Defining-the-average-energy-for-our-node","page":"Defining a custom node and rules","title":"Step 4: Defining the average energy for our node","text":"","category":"section"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"To complete the computation of the Bethe free energy, we also need to compute the average energy term. The average energy in our MyBernoulli example can be computed as -mathrmE_q(x_k pi)ln p(x_k mid pi), however, because we know that we observe x_k and therefore q(x_k pi) factorizes, we can instead compute beginaligned -mathrmE_q(x_k)q(pi)ln p(x_k mid pi) = -mathrmE_q(x_k)q(pi) ln (pi^x_k (1-pi)^1 - x_k) \n= -mathrmE_q(x_k)q(pi) x_k ln(pi) + (1-x_k) ln(1-pi) \n= -mathrmE_q(x_k)x_k mathrmE_q(pi) ln(pi) - (1-mathrmE_q(x_k)x_k) mathrmE_q(pi)ln(1-pi) endaligned","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Which is what we implemented below. Note that mean(mirrorlog, q(x)) is equal to mathrmE_q(x)1-logx.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"@average_energy Bernoulli (q_out::Any, q_π::Any) = -mean(q_out) * mean(log, q_π) - (1.0 - mean(q_out)) * mean(mirrorlog, q_π)","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"In the case that the interfaces do not factorize, we would get something like @average_energy MyBernoulli (q_out_π::Any,) = begin ... end.","category":"page"},{"location":"manuals/customization/custom-node/#Using-our-node-in-a-model","page":"Defining a custom node and rules","title":"Using our node in a model","text":"","category":"section"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"With all the necessary functions defined, we can proceed to test our custom node in an experiment. For this experiment, we will generate a dataset from a Bernoulli distribution with a fixed success probability of 0.75. Next, we will define a probabilistic model that has a Beta prior and a MyBernoulli likelihood. The Beta prior will be used to model our prior belief about the probability of success. The MyBernoulli likelihood will be used to model the generative process of the observed data. We start by generating the dataset:","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"using Random\n\nrng = MersenneTwister(42)\nn = 500\nπ_real = 0.75\ndistribution = Bernoulli(π_real)\n\ndataset = float.(rand(rng, distribution, n))\n\nnothing # hide","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Next, we define our model. Note that we use the MyBernoulli node in the model. The model consists of a single latent variable π, which has a Beta prior and is the parameter of the MyBernoulli likelihood. The MyBernoulli node takes the value of π as its parameter and returns a binary observation. We set the hyperparameters of the Beta prior to be 4 and 8, respectively, which correspond to a distribution slightly biased towards higher values of π. The model is defined as follows:","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"@model function coin_model_mybernoulli(y)\n    # We endow θ parameter of our model with some prior\n    π ~ Beta(4.0, 8.0)\n    # We assume that outcome of each coin flip is governed by the MyBernoulli distribution\n    for i in eachindex(y)\n        y[i] ~ MyBernoulli(π)\n    end\nend","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Finally, we can run inference with this model and the generated dataset:","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"result_mybernoulli = infer(\n    model = coin_model_mybernoulli(), \n    data  = (y = dataset, ),\n)","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"We have now completed our experiment and obtained the posterior marginal distribution for p through inference. To evaluate the performance of our inference, we can compare the estimated posterior to the true value. In our experiment, the true value for p is 0.75, and we can see that the estimated posterior has a mean close to this value, which shows that our custom node was able to successfully pass messages towards the π variable in order to learn the true value of the parameter.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"using Plots\n\nrθ = range(0, 1, length = 1000)\n\np = plot(title = \"Inference results\")\n\nplot!(rθ, (x) -> pdf(result_mybernoulli.posteriors[:π], x), fillalpha=0.3, fillrange = 0, label=\"p(π|x)\", c=3)\nvline!([π_real], label=\"Real π\")","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"As a sanity check, we can create the same model with the RxInfer built-in node Bernoulli and compare the resulting posterior distribution with the one obtained using our custom MyBernoulli node. This will give us confidence that our custom node is working correctly. We use the Bernoulli node with the same Beta prior and the observed data, and then run inference. We can compare the two posterior distributions and observe that they are exactly the same, which indicates that our custom node is performing as expected.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"@model function coin_model(y)\n    p ~ Beta(4.0, 8.0)\n    for i in eachindex(y)\n        y[i] ~ Bernoulli(p)\n    end\nend\n\nresult_bernoulli = infer(\n    model = coin_model(), \n    data  = (y = dataset, ),\n)\n\nif !(result_bernoulli.posteriors[:p] == result_mybernoulli.posteriors[:π])\n    error(\"Results are not identical\")\nelse \n    println(\"Results are identical 🎉🎉🎉\")\nend\n\nnothing # hide","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Congratulations! You have successfully implemented your own custom node in RxInfer. We went through the definition of a node to the implementation of the update rules and marginal posterior calculations. Finally we tested our custom node in a model and checked if we implemented everything correctly.","category":"page"},{"location":"manuals/customization/custom-node/#custom-node-experimental","page":"Defining a custom node and rules","title":"Custom node experimental functionality","text":"","category":"section"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"warning: Experimental features\nThe functionality described below is experimental and subject to change in future releases. Use it with caution in production code.","category":"page"},{"location":"manuals/customization/custom-node/#inference-ruleswithnode","page":"Defining a custom node and rules","title":"Rules that require a reference to a node object","text":"","category":"section"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"In some advanced scenarios, you might need access to the node object itself within a message passing rule. This can be useful when:","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"You need to inspect the current state of other variables in the model\nYou want to implement complex message passing schemes that depend on the global model state\nYou're experimenting with custom inference algorithms that require access to the factor graph structure","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Here's how to implement a rule with node access. First we define a custom node and a simple model that uses this node:","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"using RxInfer\n\nstruct MyExperimentalNode end\n\n@node MyExperimentalNode Stochastic [ out, θ ]\n\n@model function my_experimental_model(y)\n    θ ~ Normal(mean = 0.0, variance = 1.0)\n    y ~ MyExperimentalNode(θ)\nend","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Second, we enable instruction to the inference backend to pass node reference to the rule.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"# Enable node reference passing for this node type\nReactiveMP.call_rule_is_node_required(::Type{<:MyExperimentalNode}) = ReactiveMP.CallRuleNodeRequired()","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"note: Performance Impact\nEnabling node reference passing can negatively impact performance as it requires additional bookkeeping during inference.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"danger: Global State\nSetting call_rule_is_node_required for existing nodes (like NormalMeanVariance) affects all models globally and will affect code that depends on your package. Only safe to use this for your custom nodes.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"The call_rule_is_node_required function is used to instruct the inference backend to pass the node object to the rule. After this is set, we can use the getnode() function to access the node object within the rule.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"@rule MyExperimentalNode(:θ, Marginalisation) (q_out::Any, ) = begin \n    node = getnode()\n    # Access interface index\n    ii = ReactiveMP.interfaceindex(node, :θ)\n    # Get interface object\n    θi = ReactiveMP.getinterfaces(node)[ii]\n    # Get variable object\n    θv = ReactiveMP.getvariable(θi)\n    \n    # By default, `germarginal` ignores marginals set in the @initialization block\n    # `IncludeAll` overrides this behavior and includes all marginals\n    qθ = Rocket.getrecent(ReactiveMP.getmarginal(θv, IncludeAll()))\n\n    # This is a simple rule that returns a NormalMeanVariance distribution\n    # It could be replaced with any other rule that returns a distribution\n    return NormalMeanVariance(mean(qθ) + mean(q_out), var(qθ))\nend","category":"page"},{"location":"manuals/customization/custom-node/#Running-inference-with-the-custom-node-and-rule","page":"Defining a custom node and rules","title":"Running inference with the custom node and rule","text":"","category":"section"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"Here's a full example showing how to use this functionality:","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"initialization = @initialization begin\n    q(θ) = NormalMeanVariance(3.14, 2.71)\nend\n\nresult = infer(\n    model = my_experimental_model(),\n    data = (y = 1.0, ),\n    initialization = initialization\n)\nnothing #hide","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"As we can see, the print statement in the rule is executed, which means that the node reference passing is working as expected. This feature opens up possibilities for advanced inference scenarios, but should be used judiciously. Consider whether your use case truly requires access to the node object, as simpler solutions using standard message passing rules are often sufficient and more maintainable.","category":"page"},{"location":"manuals/customization/custom-node/","page":"Defining a custom node and rules","title":"Defining a custom node and rules","text":"","category":"page"},{"location":"manuals/inference/static/#manual-static-inference","page":"Static inference","title":"Static Inference","text":"","category":"section"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"This guide explains how to use the infer function for static datasets. We'll show how RxInfer can estimate posterior beliefs given a set of observations. We'll use a simple Beta-Bernoulli model as an example, which has been covered in the Getting Started section, but keep in mind that these techniques can apply to any model.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Also read about Streaming Inference or checkout more complex examples.","category":"page"},{"location":"manuals/inference/static/#manual-static-inference-model-spec","page":"Static inference","title":"Model specification","text":"","category":"section"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Also read the Model Specification section.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"In static inference, we want to update our prior beliefs about certain hidden states given some dataset. To achieve this, we include data as an argument in our model specification:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"using RxInfer\nusing Test #hide\n\n@model function beta_bernoulli(y, a, b)\n    θ ~ Beta(a, b)  \n    for i in 1:length(y)\n        y[i] ~ Bernoulli(θ)\n    end\nend","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"In this model, we assume that y is a collection of data points, and a and b are just numbers. To run inference in this model, we have to call the infer function with the data argument provided.","category":"page"},{"location":"manuals/inference/static/#manual-static-inference-dataset","page":"Static inference","title":"Dataset of observations","text":"","category":"section"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"For demonstration purposes, we will use hand crafted dataset:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"using Distributions, StableRNGs\n\nhidden_θ       = 1 / 3.1415\ndistribution   = Bernoulli(hidden_θ)\nrng            = StableRNG(43)\nn_observations = 1_000\ndataset        = rand(rng, distribution, n_observations)\nnothing #hide","category":"page"},{"location":"manuals/inference/static/#manual-static-inference-infer","page":"Static inference","title":"Calling the inference procedure","text":"","category":"section"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Everything is ready to run inference in our simple model. In order to run inference with static dataset using the infer function, we need to use the data argument. The data argument  expects a NamedTuple where keys correspond to the names of the model arguments. In our case the model arguments were a, b and y. We treat a and b as hyperparameters and pass them directly to the model constructor and we treat y as our observations, thus we pass it to the data argument as follows:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"results = infer(\n    model = beta_bernoulli(a = 1.0, b = 1.0),\n    data  = (y = dataset, )\n)\n@test results isa InferenceResult #hide\nresults #hide","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"note: Note\ny inside the @model specification is not the same data collection as provided in the data argument. Inside the @model, y is a collection of nodes in the corresponding factor graph, but it will have exactly the same shape as the collection provided in the data argument, hence we can use some basic Julia function, e.g. length. ","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Note, that we could also pass a and b as data:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"results = infer(\n    model = beta_bernoulli(),\n    data  = (y = dataset, a = 1.0, b = 1.0)\n)\n@test results isa InferenceResult #hide\nresults #hide","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"The infer function, however, requires at least one data argument to be present in the supplied data. The difference between hyperparameters and observations is purely semantic and should not have real influence on the result of the inference procedure. ","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"note: Note\nThe inference procedure uses reactive message passing protocol and may decide to optimize and precompute certain messages that use fixed hyperparameters, hence changing the order of computed messages. The order of computations may change the convergence properties for some complex models.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"In case of inference with static datasets, the infer function will return the InferenceResult structure. This structure has the .posteriors field, which is a Dict like structure that maps names of latent states to their corresponding posteriors. For example:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"@test results.posteriors[:θ] isa Beta #hide\nresults.posteriors[:θ]","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"InferenceResult","category":"page"},{"location":"manuals/inference/static/#RxInfer.InferenceResult","page":"Static inference","title":"RxInfer.InferenceResult","text":"InferenceResult\n\nThis structure is used as a return value from the infer function for static datasets. \n\nPublic Fields\n\nposteriors: Dict or NamedTuple of 'random variable' - 'posterior' pairs. See the returnvars argument for infer.\npredictions: (optional) Dict or NamedTuple of 'data variable' - 'prediction' pairs. See the predictvars argument for infer.\nfree_energy: (optional) An array of Bethe Free Energy values per VMP iteration. See the free_energy argument for infer.\nmodel: FactorGraphModel object reference.\nerror: (optional) A reference to an exception, that might have occurred during the inference. See the catch_exception argument for infer.\n\nSee also: infer\n\n\n\n\n\n","category":"type"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"We can also visualize our posterior results with the Plots.jl package. We  used Beta(a = 1.0, b = 1.0) as a prior, lets compare our prior and posterior beliefs:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"using Plots\n\nrθ = range(0, 1, length = 1000)\n\np = plot()\np = plot!(p, rθ, (x) -> pdf(Beta(1.0, 1.0), x), title=\"Prior\", fillalpha=0.3, fillrange = 0, label=\"P(θ)\", c=1,)\np = plot!(p, rθ, (x) -> pdf(results.posteriors[:θ], x), title=\"Posterior\", fillalpha=0.3, fillrange = 0, label=\"P(θ|y)\", c=3)\np = vline!(p, [ hidden_θ ], label = \"Real (hidden) θ\")","category":"page"},{"location":"manuals/inference/static/#Missing-data-points-and-predictions","page":"Static inference","title":"Missing data points and predictions","text":"","category":"section"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"result = infer(\n    model = beta_bernoulli(a = 1.0, b = 1.0),\n    data  = (y = [ true, false, missing, true, false ], )\n)","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"In principle, the entire dataset may consist of missing entries:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"result = infer(\n    model = beta_bernoulli(a = 1.0, b = 1.0),\n    data  = (y = [ missing, missing, missing, missing, missing ], )\n)","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"In this case, the resulting posterior is simply equal to the prior (as expected, since no extra information can be extracted from the observations):","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"@test result.posteriors[:θ] == Beta(1.0, 1.0) #hide\nresult.posteriors[:θ]","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"In addition, in the presence of missing data points RxInfer will also attempt to compute predictive distributions:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"@test all(v -> v == Bernoulli(0.5), result.predictions[:y]) #hide\nresult.predictions[:y]","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"# Sample y₃\nrand(result.predictions[:y][3])","category":"page"},{"location":"manuals/inference/static/#manual-static-inference-variational-inference","page":"Static inference","title":"Variational Inference with static datasets","text":"","category":"section"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"The example above is quite simple and performs exact Bayesian inference. However, for more complex model, we may need to specify variational constraints and perform variational inference. To demonstrate this, we will use a slightly more complex model, where we need to estimate mean and the precision of IID samples drawn from the Normal distribution:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"@model function iid_estimation(y)\n    μ  ~ Normal(mean = 0.0, precision = 0.1)\n    τ  ~ Gamma(shape = 1.0, rate = 1.0)\n    y .~ Normal(mean = μ, precision = τ)\nend","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"In this model, we have two latent variables μ and τ and a set of observations y. Note  that we used the broadcasting syntax, which is roughly equivalent to the manual for loop shown in the previous example. Let's try to run the inference in this model, but first, we need to create our observations:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"# `ExponentialFamily` package expors different parametrizations \n# for the Normal distribution\nusing ExponentialFamily\n\nhidden_μ       = 3.1415\nhidden_τ       = 2.7182\ndistribution   = NormalMeanPrecision(hidden_μ, hidden_τ)\nrng            = StableRNG(42)\nn_observations = 1_000\ndataset        = rand(rng, distribution, n_observations)\nnothing #hide","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"And finally we run the inference procedure:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"results = infer(\n    model = iid_estimation(),\n    data  = (y = dataset, )\n)","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"ERROR: Variables [ μ, τ ] have not been updated after an update event. \nTherefore, make sure to initialize all required marginals and messages. See `initialization` keyword argument for the inference function. \nSee the official documentation for detailed information regarding the initialization.\n\nStacktrace:\n [1] error(s::String)\n   @ Base ./error.jl:35","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"# This is just a test to ensure that the example above does\n# indeed fail with the exact same error\nusing RxInfer, Test \n@model function iid_estimation(y)\n    μ  ~ Normal(mean = 0.0, precision = 0.1)\n    τ  ~ Gamma(shape = 1.0, rate = 1.0)\n    y .~ Normal(mean = μ, precision = τ)\nend\n@test_throws \"Variables [ μ, τ ] have not been updated after an update event.\" infer(\n    model = iid_estimation(),\n    data  = (y = rand(10), )\n)\nnothing","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Huh? We get an error saying that the inference could not update the latent variables. This is happened because our model contain loops in its structure, therefore it requires the initialization. Read more about the initialization in the corresponding section in the documentation.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"We have two options here, either we initialize the messages and perform Loopy Belief Propagation in this model or we break the loops with variational constraints and perform variational inference. In this tutorial, we will choose the second option. For this we need to specify factorization constraints with the @constraints macro.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"# Specify mean-field constraint over the joint variational posterior\nconstraints = @constraints begin \n    q(μ, τ) = q(μ)q(τ)\nend\n# Specify initial posteriors for variational iterations\ninitialization = @initialization begin \n    q(μ) = vague(NormalMeanPrecision)\n    q(τ) = vague(GammaShapeRate)\nend\nnothing #hide","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"With this, we can use the constraints and initialization keyword arguments in the infer function. We also specify the number of variational iterations with the iterations keyword argument:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"results = infer(\n    model          = iid_estimation(),\n    data           = (y = dataset, ),\n    constraints    = constraints,\n    iterations     = 100,\n    initialization = initialization\n)","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Nice! Now, we have some result. Let's for example inspect the posterior results for μ.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"results.posteriors[:μ]","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"In constrast to the previous example, now we have an array of posteriors for μ, not just a single value. Each posterior in the collection corresponds to the intermediate variational update for each variational iteration. Let's visualize how our posterior over μ has been changing during the variational optimization:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"@gif for (i, intermediate_posterior) in enumerate(results.posteriors[:μ])\n    rμ = range(0, 5, length = 1000)\n    plot(rμ, (x) -> pdf(intermediate_posterior, x), title=\"Posterior on iteration $(i)\", fillalpha=0.3, fillrange = 0, label=\"P(μ|y)\", c=3)\n    vline!([hidden_μ], label = \"Real (hidden) μ\")\nend","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"It seems that the posterior has converged to a stable distribution pretty fast.  We are going to verify the converge in the next section. If, for example, we are not interested in intermediate updates, but just in the final posterior, we could use the returnvars option in the infer function and use the KeepLast option for μ:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"results_keep_last = infer(\n    model          = iid_estimation(),\n    data           = (y = dataset, ),\n    constraints    = constraints,\n    iterations     = 100,\n    returnvars     = (μ = KeepLast(), ),\n    initialization = initialization\n)","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"We can also verify that the got exactly the same result:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"@test results_keep_last.posteriors[:μ] == last(results.posteriors[:μ]) #hide\nresults_keep_last.posteriors[:μ] == last(results.posteriors[:μ])","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Let's also verify that the posteriors are consistent with the real hidden values used in the dataset generation:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"println(\"Real (hidden) μ was \", hidden_μ)\nprintln(\"Inferred mean for μ is \", mean(last(results.posteriors[:μ])), \" with standard deviation \", std(last(results.posteriors[:μ])))\n\nprintln(\"Real (hidden) τ was \", hidden_τ)\nprintln(\"Inferred mean for τ is \", mean(last(results.posteriors[:τ])), \" with standard deviation \", std(last(results.posteriors[:τ])))\n\n@test abs(mean(last(results.posteriors[:μ])) - hidden_μ) < 3std(last(results.posteriors[:μ])) #hide\n@test abs(mean(last(results.posteriors[:τ])) - hidden_τ) < 3std(last(results.posteriors[:τ])) #hide\nnothing #hide","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"rμ = range(2, 4, length = 1000)\npμ = plot(rμ, (x) -> pdf(last(results.posteriors[:μ]), x), title=\"Posterior for μ\", fillalpha=0.3, fillrange = 0, label=\"P(μ|y)\", c=3)\npμ = vline!(pμ, [ hidden_μ ], label = \"Real (hidden) μ\")\n\nrτ = range(2, 4, length = 1000)\npτ = plot(rτ, (x) -> pdf(last(results.posteriors[:τ]), x), title=\"Posterior for τ\", fillalpha=0.3, fillrange = 0, label=\"P(τ|y)\", c=3)\npτ = vline!(pτ, [ hidden_τ ], label = \"Real (hidden) τ\")\n\nplot(pμ, pτ)","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Nice result! Our posteriors are pretty close to the actual values of the parameters used for dataset generation.","category":"page"},{"location":"manuals/inference/static/#manual-static-inference-bfe","page":"Static inference","title":"Convergence and Bethe Free Energy","text":"","category":"section"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Read also the Bethe Free Energy section.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"In contrast to Loopy Belief Propagation, the variational inference is set to converge to a stable point during variational inference. In order to verify the convergence for this particular model, we can check the convergence of the Bethe Free Enegrgy values. By default, infer function does not compute the Bethe Free Energy values. In order to compute those, we must set the free_energy flag explicitly to true:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"results = infer(\n    model          = iid_estimation(),\n    data           = (y = dataset, ),\n    constraints    = constraints,\n    iterations     = 100,\n    initialization = initialization,\n    free_energy    = true\n)","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Now, we can access the free_energy field of the results and verify if the inference procedure has converged or not:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"plot(results.free_energy, label = \"Bethe Free Energy\")","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Well, it seems that 100 iterations was too much for this simple problem and we could do much less iterations in order to converge to a stable point. The animation above also suggested that the posterior for μ has converged pretty fast to a stable point.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"# Let's try to use only 5 iterations\nresults = infer(\n    model          = iid_estimation(),\n    data           = (y = dataset, ),\n    constraints    = constraints,\n    iterations     = 5,\n    initialization = initialization,\n    free_energy    = true\n)","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"plot(results.free_energy, label = \"Bethe Free Energy\")","category":"page"},{"location":"manuals/inference/static/#manual-static-inference-callbacks","page":"Static inference","title":"Callbacks","text":"","category":"section"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"The infer function has its own lifecycle, consisting of multiple steps. A user is free to inject some extra logic during the inference procedure, e.g. for debugging purposes or performance analysis. By supplying callbacks, users can inject custom logic on specific moments during the inference procedure. Here are available callbacks that can be used together with the static datasets:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"using RxInfer, Test, Markdown\n# Update the documentation below if this test does not pass\n@test RxInfer.available_callbacks(RxInfer.batch_inference) === Val((\n    :on_marginal_update,\n    :before_model_creation,\n    :after_model_creation,\n    :before_inference,\n    :before_iteration,\n    :before_data_update,\n    :after_data_update,\n    :after_iteration,\n    :after_inference\n)) \nnothing","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"before_model_creation()","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Calls before the model is going to be created, does not accept any arguments.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"after_model_creation(model::ProbabilisticModel)","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Calls right after the model has been created, accepts a single argument, the model.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"before_inference(model::ProbabilisticModel)","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Calls before the inference procedure starts, accepts a single argument, the model.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"after_inference(model::ProbabilisticModel)","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Calls after the inference procedure ends, accepts a single argument, the model.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"before_iteration(model::ProbabilisticModel, iteration::Int)","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Calls before each iteration, accepts two arguments: the model and the current iteration number.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"after_iteration(model::ProbabilisticModel, iteration::Int)","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Calls after each iteration, accepts two arguments: the model and the current iteration number.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"before_data_update(model::ProbabilisticModel, data)","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Calls before each data update, accepts two arguments: the model and the updated data.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"after_data_update(model::ProbabilisticModel, data)","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Calls after each data update, accepts two arguments: the model and the updated data.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"on_marginal_update(model::ProbabilisticModel, name, update)","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Calls after each marginal update, accepts three arguments: the model, the name of the updated marginal, and the updated marginal itself.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"Here is an example usage of the outlined callbacks:","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"before_model_creation_called = Ref(false) #hide\nafter_model_creation_called = Ref(false) #hide\nbefore_inference_called = Ref(false) #hide\nafter_inference_called = Ref(false) #hide\nbefore_iteration_called = Ref(false) #hide\nafter_iteration_called = Ref(false) #hide\nbefore_data_update_called = Ref(false) #hide\nafter_data_update_called = Ref(false) #hide\non_marginal_update_called = Ref(false) #hide\n\nfunction before_model_creation()\n    before_model_creation_called[] = true #hide\n    println(\"The model is about to be created\")\nend\n\nfunction after_model_creation(model::ProbabilisticModel)\n    after_model_creation_called[] = true #hide\n    println(\"The model has been created\")\n    println(\"  The number of factor nodes is: \", length(RxInfer.getfactornodes(model)))\n    println(\"  The number of latent states is: \", length(RxInfer.getrandomvars(model)))\n    println(\"  The number of data points is: \", length(RxInfer.getdatavars(model)))\n    println(\"  The number of constants is: \", length(RxInfer.getconstantvars(model)))\nend\n\nfunction before_inference(model::ProbabilisticModel)\n    before_inference_called[] = true #hide\n    println(\"The inference procedure is about to start\")\nend\n\nfunction after_inference(model::ProbabilisticModel)\n    after_inference_called[] = true #hide\n    println(\"The inference procedure has ended\")\nend\n\nfunction before_iteration(model::ProbabilisticModel, iteration::Int)\n    before_iteration_called[] = true #hide\n    println(\"The iteration \", iteration, \" is about to start\")\nend\n\nfunction after_iteration(model::ProbabilisticModel, iteration::Int)\n    after_iteration_called[] = true #hide\n    println(\"The iteration \", iteration, \" has ended\")\nend\n\nfunction before_data_update(model::ProbabilisticModel, data)\n    before_data_update_called[] = true #hide\n    println(\"The data is about to be processed\")\nend\n\nfunction after_data_update(model::ProbabilisticModel, data)\n    after_data_update_called[] = true #hide\n    println(\"The data has been processed\")\nend\n\nfunction on_marginal_update(model::ProbabilisticModel, name, update)\n    on_marginal_update_called[] = true #hide\n    println(\"New marginal update for \", name, \" \", update)\nend","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"results = infer(\n    model          = iid_estimation(),\n    data           = (y = dataset, ),\n    constraints    = constraints,\n    iterations     = 5,\n    initialization = initialization,\n    free_energy    = true,\n    callbacks      = (\n        before_model_creation = before_model_creation,\n        after_model_creation = after_model_creation,\n        before_inference = before_inference,\n        after_inference = after_inference,\n        before_iteration = before_iteration,\n        after_iteration = after_iteration,\n        before_data_update = before_data_update,\n        after_data_update = after_data_update,\n        on_marginal_update = on_marginal_update\n    )\n)\n\n@test before_model_creation_called[] #hide\n@test after_model_creation_called[] #hide\n@test before_inference_called[] #hide\n@test after_inference_called[] #hide\n@test before_iteration_called[] #hide\n@test after_iteration_called[] #hide\n@test before_data_update_called[] #hide\n@test after_data_update_called[] #hide\n@test on_marginal_update_called[] #hide\n\nnothing #hide","category":"page"},{"location":"manuals/inference/static/#manual-static-inference-where-to-go","page":"Static inference","title":"Where to go next?","text":"","category":"section"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"This guide covered some fundamental usages of the infer function in the context of inference with static datasets,  but did not cover all the available keyword arguments of the function. Read more explanation about the other keyword arguments  in the Overview section or check out the Streaming Inference section. Also check out more complex examples.","category":"page"},{"location":"manuals/inference/static/","page":"Static inference","title":"Static inference","text":"","category":"page"},{"location":"manuals/inference/undefinedrules/#inference-undefinedrules","page":"Undefined message update rules","title":"Inference without explicit message update rules","text":"","category":"section"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"RxInfer utilizes the ReactiveMP.jl package as its inference backend. Typically, running inference with ReactiveMP.jl requires users to define a factor node using the @node macro and specify corresponding message update rules with the @rule macro. Detailed instructions on this can be found in this section of the documentation. However, in this tutorial, we will explore an alternative approach that allows inference with default message update rule for custom factor nodes by defining only BayesBase.logpdf and BayesBase.insupport for a factor node, without needing explicit @rule specifications.","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"note: Note\nIn the context of message-passing based Bayesian inference, custom message update rules enhance precision and efficiency. These rules leverage the specific mathematical properties of the model's distributions and relationships, leading to more accurate updates and faster convergence. By incorporating domain-specific knowledge, custom rules improve the robustness and reliability of the inference process, particularly in complex models where default rules may be inadequate or inefficient.","category":"page"},{"location":"manuals/inference/undefinedrules/#A-simple-prior-likelihood-model","page":"Undefined message update rules","title":"A simple prior-likelihood model","text":"","category":"section"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"We start a simple model with a hidden variable p and observations y. Later in the tutorial we explore more advanced use-cases. In this particular case we assume that p follows a prior distribution and y are drawn from a likelihood distribution. The model can be defined as follows:","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"using RxInfer\n\n@model function simple_model(y, prior, likelihood)\n    p ~ prior\n    y .~ likelihood(p)\nend","category":"page"},{"location":"manuals/inference/undefinedrules/#Node-specifications","page":"Undefined message update rules","title":"Node specifications","text":"","category":"section"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"Next, we define structures for both the prior and the likelihood. Let's start with the prior. Assume that the p parameter is best described by a Beta distribution. We can define it as follows:","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"note: Note\nThe Distributions.jl package already provides a fully-featured implementation of Beta and Bernoulli distributions, including functions like logpdf and support checks. The example below redefines the Beta distribution structure and related functions solely for illustrative purposes. In practice, you often won't need to define these distributions yourself, as many of them has already been included in Distributions.jl.","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"using Distributions, BayesBase\n\nstruct BetaDistribution{A, B} <: ContinuousUnivariateDistribution\n    a::A\n    b::B\nend\n\n# Reuse `logpdf` from `Distributions.jl` for illustrative purposes\nBayesBase.logpdf(d::BetaDistribution, x) = logpdf(Beta(d.a, d.b), x)\nBayesBase.insupport(d::BetaDistribution, x::Real) = 0 <= x <= 1","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"Next, we assume that y is a discrete dataset of true and false values. The logical choice for the likelihood distribution is the Bernoulli distribution.","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"struct BernoulliDistribution{P} <: DiscreteUnivariateDistribution\n    p::P\nend\n\n# Reuse `logpdf` from `Distributions.jl` for illustrative purposes\nBayesBase.logpdf(d::BernoulliDistribution, x) = logpdf(Bernoulli(d.p), x)\nBayesBase.insupport(d::BernoulliDistribution, x) = x === true || x === false","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"The next step is to register these structures as valid factor nodes:","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"@node BetaDistribution Stochastic [out, a, b]\n@node BernoulliDistribution Stochastic [out, p]","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"When specifying a node for our custom distributions, we must follow a specific edge ordering. The first edge is always out, which represents a sample in the logpdf function. All remaining edges must match the parameters of the distribution in the exact same order. For example, for the BetaDistribution, the node function is defined as (out, a, b) -> logpdf(BetaDistribution(a, b), out). This ensures that the node specification and the logpdf function correctly maps the distribution parameters to the sample output.","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"note: Note\nAlthough Beta is a conjugate prior for the parameter of the Bernoulli distribution, ReactiveMP and RxInfer are unaware of this and cannot exploit this information. To utilize conjugacy, refer to the custom node creation section of the documentation.","category":"page"},{"location":"manuals/inference/undefinedrules/#Generating-a-synthetic-dataset","page":"Undefined message update rules","title":"Generating a synthetic dataset","text":"","category":"section"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"Previously, we assumed that our dataset consists of discrete values: true and false. We can generate a synthetic dataset with these values as follows:","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"using StableRNGs, Plots\n\nhidden_p    = 1 / 3.1415 # a value between `0` and `1`\nndatapoints = 1_000      # number of observarions\ndataset     = rand(StableRNG(42), Bernoulli(hidden_p), ndatapoints)\n\nbar([\"true\", \"false\"], [ count(==(true), dataset), count(==(false), dataset) ], label = \"dataset\")","category":"page"},{"location":"manuals/inference/undefinedrules/#Inference-with-a-rule-fallback","page":"Undefined message update rules","title":"Inference with a rule fallback","text":"","category":"section"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"Now, we can run inference with RxInfer. Since explicit rules for our nodes have not defined, we can instruct the ReactiveMP backend to use fallback message update rules. Refer to the ReactiveMP documentation for available fallbacks. In this example, we will use the NodeFunctionRuleFallback structure, which uses the logpdf of the stochastic node to approximate messages.","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"note: Note\nNodeFunctionRuleFallback employs a simple approximation for outbound messages, which may significantly degrade inference accuracy. Whenever possible, it is recommended to define proper message update rules.","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"To complete the inference setup, we must define an approximation method for posteriors using the @constraints macro. We will utilize the ExponentialFamilyProjection library to project an arbitrary function onto a member of the exponential family. More information on ExponentialFamilyProjection can be found in the Non-conjugate Inference section and in its official documentation.","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"using ExponentialFamilyProjection\n\n@constraints function projection_constraints()\n    # Use `Beta` from `Distributions.jl` as it is compatible with the `ExponentialFamilyProjection` library\n    q(p) :: ProjectedTo(Beta) \nend","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"With all components ready, we can proceed with the inference procedure:","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"result = infer(\n    model = simple_model(prior = BetaDistribution(1, 1), likelihood = BernoulliDistribution),\n    data = (y = dataset, ),\n    constraints = projection_constraints(),\n    options = (\n        rulefallback = NodeFunctionRuleFallback(),\n    )\n)","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"note: Note\nFor rulefallback = NodeFunctionRuleFallback() to function correctly, the node must be defined as Stochastic and the underlying object must be a subtype of Distribution from Distributions.jl.","category":"page"},{"location":"manuals/inference/undefinedrules/#Result-analysis","page":"Undefined message update rules","title":"Result analysis","text":"","category":"section"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"We can perform a simple analysis and compare the inferred value with the hidden value used to generate the actual dataset:","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"using Plots, StatsPlots\nusing Test #hide\n@test isapprox(hidden_p, mean(result.posteriors[:p]), atol=1e-2) #hide\nplot(result.posteriors[:p], label = \"posterior of p\", fill = 0, fillalpha = 0.2)\nvline!([ hidden_p ], label = \"hidden p\")","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"As shown, the estimated posterior is quite close to the actual hidden value of p used during the inference procedure.","category":"page"},{"location":"manuals/inference/undefinedrules/#inference-undefinedrules-fusedelta","page":"Undefined message update rules","title":"Fusing deterministic transformations with stochastic nodes","text":"","category":"section"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"One of the limitations of the NodeFunctionRuleFallback implementation is that it does not support Deterministic or Delta nodes. However, it is possible to combine a deterministic transformation with a stochastic node, such as Gaussian. For instance, consider a dataset drawn from the Normal distribution, where the mean parameter has been transformed by a known function, and the true hidden variable is h.","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"using ExponentialFamily, Distributions, Plots, StableRNGs\n\nhidden_h = 2.3\nhidden_t = 0.5\n\nknown_transformation(h) = exp(h)\n\nhidden_mean = known_transformation(hidden_h)\nndatapoints = 50\ndataset = rand(StableRNG(42), NormalMeanPrecision(hidden_mean, hidden_t), ndatapoints)\n\nhistogram(dataset; normalize = :pdf)","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"The model can be defined as follows:","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"using RxInfer \n\n@model function mymodel(y, prior_h, prior_t)\n    h ~ prior_h\n    t ~ prior_t\n    y .~ Normal(mean = known_transformation(h), precision = t)\nend","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"Inference in this model is challenging because the known_transformation function is explicitly used as a factor node, requiring special approximation rules. These rules are covered in a separate section. Here, we demonstrate a different approach that modifies the model structure to run inference without needing to approximate messages around a deterministic node.","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"First, we define our custom transformed Normal distribution:","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"using BayesBase\n\nstruct TransformedNormalDistribution{H, T} <: ContinuousUnivariateDistribution\n    h::H\n    t::T\nend\n\n# We integrate the `known_transformation` within the `logpdf` function\n# This way, it won't be an explicit factor node but hidden within the `logpdf` of another node\nBayesBase.logpdf(dist::TransformedNormalDistribution, x) = logpdf(NormalMeanPrecision(known_transformation(dist.h), dist.t), x)\nBayesBase.insupport(dist::TransformedNormalDistribution, x) = true\n\n@node TransformedNormalDistribution Stochastic [out, h, t]","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"Next, we tweak the model structure:","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"@model function mymodel(y, prior_h, prior_t)\n    h ~ prior_h\n    t ~ prior_t\n    y .~ TransformedNormalDistribution(h, t)\nend","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"We use the following priors, constraints, and initialization:","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"using ExponentialFamilyProjection\n\nprior_h = LogNormal(0, 1)\nprior_t = Gamma(1, 1)\n\nconstraints = @constraints begin\n    q(h, t) = q(h)q(t)\n    q(h) :: ProjectedTo(LogNormal)\n    q(t) :: ProjectedTo(Gamma)\nend\n\ninitialization = @initialization begin\n    q(t) = Gamma(1, 1)\nend","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"note: Note\nThe ProjectedTo macro has a parameters field that allows for different hyperparameters, which may improve accuracy or convergence speed. Refer to the ExponentialFamilyProjection documentation for more information.","category":"page"},{"location":"manuals/inference/undefinedrules/#Inference-with-a-rule-fallback-2","page":"Undefined message update rules","title":"Inference with a rule fallback","text":"","category":"section"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"Now we are ready to run the inference procedure:","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"result = infer(\n    model = mymodel(prior_h = prior_h, prior_t = prior_t),\n    data = (y = dataset,),\n    constraints = constraints,\n    initialization = initialization,\n    iterations = 50,\n    options = (\n        rulefallback = NodeFunctionRuleFallback(),\n    )\n)","category":"page"},{"location":"manuals/inference/undefinedrules/#Result-analysis-2","page":"Undefined message update rules","title":"Result analysis","text":"","category":"section"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"Finally, let's plot the resulting posteriors for each VMP iteration:","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"using Test #hide\n@test isapprox(mean(result.posteriors[:h][end]), hidden_h, atol=0.1) #hide\n\n@gif for (i, q) in enumerate(zip(result.posteriors[:h], result.posteriors[:t]))\n    p1 = plot(1:0.01:3, q[1], label = \"q(h) iteration $i\", fill = 0, fillalpha = 0.2)\n    p1 = vline!([hidden_h], label = \"hidden h\")\n    \n    p2 = plot(0:0.01:1, q[2], label = \"q(t) iteration $i\", fill = 0, fillalpha = 0.2)\n    p2 = vline!([hidden_t], label = \"hidden t\")\n    \n    plot(p1, p2)\nend fps = 15","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"We can see that the inference results are able to recover the actual value of hidden h that has been used to generate the synthetic dataset. In conclusion, this example demonstrates that by integrating deterministic transformations within the logpdf function of a stochastic node, we can bypass the limitations of NodeFunctionRuleFallback in handling deterministic nodes.","category":"page"},{"location":"manuals/inference/undefinedrules/","page":"Undefined message update rules","title":"Undefined message update rules","text":"","category":"page"},{"location":"contributing/guidelines/#contributing-guidelines","page":"Contribution guidelines","title":"Contribution Guidelines","text":"","category":"section"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"Welcome to the contribution guidelines for RxInfer.jl. Here you'll find detailed instructions on how to contribute effectively to the project.","category":"page"},{"location":"contributing/guidelines/#Reporting-bugs","page":"Contribution guidelines","title":"Reporting bugs","text":"","category":"section"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"If you encounter any bugs while using the software, please report them via GitHub issues. To ensure efficient bug resolution, please provide comprehensive and reproducible bug reports. Include details such as the versions of Julia and RxInfer you're using, along with a concise description of the issue. Additionally, attach relevant code snippets, test cases, screenshots, or any other pertinent information that could aid in replicating and addressing the problem.","category":"page"},{"location":"contributing/guidelines/#Nightly-Julia-status","page":"Contribution guidelines","title":"Nightly Julia status","text":"","category":"section"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"Check the badge below to see if RxInfer can be installed on a Julia nightly version. A failing badge may indicate issues with RxInfer or its dependencies. Click on the badge to access the latest evaluation report.","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"(Image: PkgEval)","category":"page"},{"location":"contributing/guidelines/#Suggesting-features","page":"Contribution guidelines","title":"Suggesting features","text":"","category":"section"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"We encourage proposals for new features. Before submitting a feature request, consider the following:","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"Determine if the feature necessitates changes to the core RxInfer code. If not, such as adding a factor node for a specific application, consider local extensions in your script/notebook or creating a separate repository for your extensions.\nFor feature implementations requiring significant changes to the core RxInfer code, open a GitHub issue to discuss your proposal before proceeding with implementation. This allows for thorough deliberation and avoids investing time in features that may be challenging to integrate later on.","category":"page"},{"location":"contributing/guidelines/#Contributing-code","page":"Contribution guidelines","title":"Contributing code","text":"","category":"section"},{"location":"contributing/guidelines/#Installing-RxInfer","page":"Contribution guidelines","title":"Installing RxInfer","text":"","category":"section"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"For development purposes, it's recommended to use the dev command from the Julia package manager to install RxInfer. Use your fork's URL in the dev command to work on your forked version. For example:","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"] dev git@github.com:your_username/RxInfer.jl.git","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"The dev command clones RxInfer to ~/.julia/dev/RxInfer. All local changes to RxInfer code will be reflected in imported code.","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"note: Note\nIt is also might be useful to install Revise.jl package as it allows you to modify code and use the changes without restarting Julia.","category":"page"},{"location":"contributing/guidelines/#Core-dependencies","page":"Contribution guidelines","title":"Core dependencies","text":"","category":"section"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"RxInfer.jl depends heavily on the core packages ReactiveMP.jl, GraphPPL.jl, and Rocket.jl. Ensure RxInfer.jl is updated whenever any of these packages undergo major updates or API changes. While making changes to RxInfer.jl, developers are advised to use the dev command for these packages as well. Note that standard Julia testing utilities ignore the local development environment and test the package with the latest released versions of core dependencies. Refer to the Makefile section below to learn how to test RxInfer.jl with locally installed core dependencies.","category":"page"},{"location":"contributing/guidelines/#Committing-code","page":"Contribution guidelines","title":"Committing code","text":"","category":"section"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"We use the standard GitHub Flow workflow where all contributions are added through pull requests. To contribute:","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"Fork the repository\nCommit your contributions to your fork\nCreate a pull request on the main branch of the RxInfer repository.","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"Before opening a pull request, ensure all tests pass without errors.","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"note: Note\nUse make test and make docs commands to verify that all tests and documentation build correctly. See the Makefile section below for detailed command descriptions.","category":"page"},{"location":"contributing/guidelines/#Style-conventions","page":"Contribution guidelines","title":"Style conventions","text":"","category":"section"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"We use the default Julia style guide. There are a couple of important points modifications to the Julia style guide to take into account:","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"Use 4 spaces for indentation\nType names use UpperCamelCase. For example: AbstractFactorNode, RandomVariable, etc..\nFunction names are lowercase with underscores, when necessary. For example: activate!, randomvar, as_variable, etc..\nVariable names and function arguments use snake_case\nThe name of a method that modifies its argument(s) must end in !","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"note: Note\nThe RxInfer repository contains scripts to automatically format code according to our guidelines. Use make format command to fix code style. This command overwrites files. Use make lint to run a linting procedure without overwriting the actual source files.","category":"page"},{"location":"contributing/guidelines/#Unit-tests","page":"Contribution guidelines","title":"Unit tests","text":"","category":"section"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"We use the test-driven development (TDD) methodology for RxInfer development. Aim for comprehensive test coverage, ensuring tests cover each piece of added code.","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"All unit tests are located in the /test/ directory. The /test/ directory follows the structure of the /src/ directory. Each test file should have the following filename format: *_tests.jl. Some tests are also present in jldoctest docs annotations directly in the source code. See Julia's documentation about doctests.","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"The tests can be evaluated by running following command in the Julia REPL:","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"] test RxInfer","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"In addition tests can be evaluated by running following command in the RxInfer root directory:","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"make test","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"note: Note\nUse make devtest to use local dev-ed versions of the core packages.","category":"page"},{"location":"contributing/guidelines/#Makefile","page":"Contribution guidelines","title":"Makefile","text":"","category":"section"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"RxInfer.jl uses Makefile for most common operations:","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"make help: Shows help snippet\nmake test: Run tests, supports extra arguments\nmake test test_args=\"distributions:normal_mean_variance\" would run tests only from distributions/test_normal_mean_variance.jl\nmake test test_args=\"distributions:normal_mean_variance models:lgssm\" would run tests both from distributions/test_normal_mean_variance.jl and models/test_lgssm.jl\nmake test dev=true would run tests while using dev-ed versions of core packages\nmake devtest: Alias for the make test dev=true ...\nmake docs: Compile documentation\nmake devdocs: Same as make docs, but uses dev-ed versions of core packages\nmake lint: Check codestyle\nmake format: Check and fix codestyle ","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"note: Note\nCore packages include ReactiveMP.jl, GraphPPL.jl and Rocket.jl. When using any of the dev commands from the Makefile those packages must be present in the Pkg.devdir() directory.","category":"page"},{"location":"contributing/guidelines/","page":"Contribution guidelines","title":"Contribution guidelines","text":"","category":"page"},{"location":"contributing/new-example/#contributing-new-example","page":"Contributing to the examples","title":"Contributing to the examples","text":"","category":"section"},{"location":"contributing/new-example/","page":"Contributing to the examples","title":"Contributing to the examples","text":"The examples have been moved to a dedicated repository at RxInferExamples.jl.","category":"page"},{"location":"contributing/new-example/","page":"Contributing to the examples","title":"Contributing to the examples","text":"To contribute new examples, please visit the examples repository and follow the contribution guidelines there. We welcome all contributions that help demonstrate the capabilities of RxInfer.jl!","category":"page"},{"location":"contributing/new-example/","page":"Contributing to the examples","title":"Contributing to the examples","text":"","category":"page"},{"location":"contributing/examples/#examples","page":"Contribute with examples","title":"Contribute with examples","text":"","category":"section"},{"location":"contributing/examples/","page":"Contribute with examples","title":"Contribute with examples","text":"The examples for RxInfer.jl are now maintained in a dedicated repository at RxInferExamples.jl. Please visit the examples repository to:","category":"page"},{"location":"contributing/examples/","page":"Contribute with examples","title":"Contribute with examples","text":"Browse existing examples\nLearn how to contribute your own examples\nGet started with RxInfer.jl","category":"page"},{"location":"contributing/examples/#Featured-Examples","page":"Contribute with examples","title":"Featured Examples","text":"","category":"section"},{"location":"contributing/examples/","page":"Contribute with examples","title":"Contribute with examples","text":"Active Inference with RxInfer.jl - Dive into the realm of Active Inference guided by Kobus Esterhuysen at Learnable Loop.\nTutorial Series on RxInfer.jl - Explore a series of engaging tutorial videos on RxInfer.jl's functionalities, presented by @doggotodjl.","category":"page"},{"location":"contributing/examples/","page":"Contribute with examples","title":"Contribute with examples","text":"note: Note\nIf you're interested in contributing an example, please visit the RxInferExamples.jl repository. We welcome all contributions that help demonstrate the capabilities of RxInfer.jl!","category":"page"},{"location":"contributing/examples/","page":"Contribute with examples","title":"Contribute with examples","text":"","category":"page"},{"location":"manuals/getting-started/#user-guide-getting-started","page":"Getting started","title":"Getting started","text":"","category":"section"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"RxInfer.jl is a Julia package for Bayesian Inference on Factor Graphs by Message Passing.  It supports both exact and variational inference algorithms and forms an ecosystem around three main packages: ","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"ReactiveMP.jl - the underlying message passing-based inference engine\nGraphPPL.jl - model and constraints specification package\nRocket.jl - reactive extensions package for Julia ","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"This page provides the necessary information you need to get started with Rxinfer. We will show the general approach to solving inference problems with RxInfer by means of a running example: inferring the bias of a coin using a simple Beta-Bernoulli model.","category":"page"},{"location":"manuals/getting-started/#Installation","page":"Getting started","title":"Installation","text":"","category":"section"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"RxInfer is an officially registered Julia package. Install RxInfer through the Julia package manager by using the following command from the package manager mode:","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"] add RxInfer","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"Alternatively:","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"julia> import Pkg\n\njulia> Pkg.add(\"RxInfer\")","category":"page"},{"location":"manuals/getting-started/#Importing-RxInfer","page":"Getting started","title":"Importing RxInfer","text":"","category":"section"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"To add RxInfer package (and all associated packages) into a running Julia session simply run:","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"using RxInfer","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"Read more about about using in the Using methods from RxInfer section of the documentation.","category":"page"},{"location":"manuals/getting-started/#Example:-Inferring-the-bias-of-a-coin","page":"Getting started","title":"Example: Inferring the bias of a coin","text":"","category":"section"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"The RxInfer approach to solving inference problems consists of three phases:","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"Model specification: RxInfer uses GraphPPL package for model specification part. It offers a domain-specific language to specify your probabilistic model.\nInference specification: RxInfer inference API uses ReactiveMP inference engine under the hood and has been designed to be as flexible as possible. It is compatible both with asynchronous infinite data streams and with static datasets. For most of the use cases it consists of the same simple building blocks. In this example we will show one of the many possible ways to infer your quantities of interest.\nInference execution: Given model specification and inference procedure it is pretty straightforward to use package's API to pass data to the inference backend and to run actual inference.","category":"page"},{"location":"manuals/getting-started/#user-guide-getting-started-coin-flip-simulation","page":"Getting started","title":"Coin flip simulation","text":"","category":"section"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"Let's start by creating some dataset. One approach could be flipping a coin N times and recording each outcome. For simplicity in this example we will use static pre-generated dataset. Each sample can be thought of as the outcome of single flip which is either heads or tails (1 or 0). We will assume that our virtual coin is biased, and lands heads up on 75% of the trials (on average).","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"First let's setup our environment by importing all needed packages:","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"using Test #hide\nusing RxInfer, Distributions, Random","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"Next, let's define our dataset:","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"# Random number generator for reproducibility\nrng            = MersenneTwister(42)\n# Number of coin flips (observations)\nn_observations = 10\n# The bias of a coin used in the demonstration\ncoin_bias      = 0.75\n# We assume that the outcome of each coin flip is \n# distributed as the `Bernoulli` distrinution\ndistribution   = Bernoulli(coin_bias)\n# Simulated coin flips\ndataset        = rand(rng, distribution, n_observations)","category":"page"},{"location":"manuals/getting-started/#getting-started-model-specification","page":"Getting started","title":"Model specification","text":"","category":"section"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"In a Bayesian setting, the next step is to specify our probabilistic model. This amounts to specifying the joint probability of the random variables of the system.","category":"page"},{"location":"manuals/getting-started/#Likelihood","page":"Getting started","title":"Likelihood","text":"","category":"section"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"We've made an assumption that the outcome of each coin flip is governed by the Bernoulli distribution, i.e.","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"y_i sim mathrmBernoulli(theta)","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"where y_i = 1 represents \"heads\", y_i = 0 represents \"tails\". The underlying probability of the coin landing heads up for a single coin flip is theta in 01.","category":"page"},{"location":"manuals/getting-started/#Prior","page":"Getting started","title":"Prior","text":"","category":"section"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"We will choose the conjugate prior of the Bernoulli likelihood function defined above, namely the Beta distribution, i.e.","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"theta sim Beta(a b)","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"where a and b are the hyperparameters that encode our prior beliefs about the possible values of theta. We will assign values to the hyperparameters in a later step.   ","category":"page"},{"location":"manuals/getting-started/#Joint-probability","page":"Getting started","title":"Joint probability","text":"","category":"section"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"The joint probability is given by the multiplication of the likelihood and the prior, i.e.","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"P(y_1N θ) = P(θ) prod_i=1^N P(y_i  θ)","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"Now let's see how to specify this model using GraphPPL's package syntax.","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"# GraphPPL.jl export `@model` macro for model specification\n# It accepts a regular Julia function and builds an FFG under the hood\n@model function coin_model(y, a, b)\n    # We endow θ parameter of our model with some prior\n    θ ~ Beta(a, b)\n    # or, in this particular case, the `Uniform(0.0, 1.0)` prior also works:\n    # θ ~ Uniform(0.0, 1.0)\n\n    # We assume that outcome of each coin flip is governed by the Bernoulli distribution\n    for i in eachindex(y)\n        y[i] ~ Bernoulli(θ)\n    end\nend","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"As you can see, RxInfer offers a model specification syntax that resembles closely to the mathematical equations defined above. Alternatively, we could use a broadcasting syntax:","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"@model function coin_model(y, a, b) \n    θ  ~ Beta(a, b)\n    y .~ Bernoulli(θ) \nend","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"note: Note\nTo quickly check the list of all available factor nodes that can be used in the model specification language call ?ReactiveMP.is_predefined_node or Base.doc(ReactiveMP.is_predefined_node).","category":"page"},{"location":"manuals/getting-started/#getting-started-conditioning","page":"Getting started","title":"Conditioning on data and inspecting the model structure","text":"","category":"section"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"Given the model specification we can construct an actual model graph and visualize it. In order to do that we can use the | operator to condition on data and the RxInfer.create_model function to create the graph. Read more about condition in the corresponding section of the documentation.","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"conditioned = coin_model(a = 2.0, b = 7.0) | (y = [ true, false, true ], )","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"We can use GraphPPL.jl visualisation capabilities to show the structure of the resulting graph. For that we need two extra packages installed: Cairo and GraphPlot. Note, that those packages are not included in the RxInfer package and must be installed separately.","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"using Cairo, GraphPlot\n\n# `Create` the actual graph of the model conditioned on the data\nmodel = RxInfer.create_model(conditioned)\n\n# Call `gplot` function from `GraphPlot` to visualise the structure of the graph\nGraphPlot.gplot(RxInfer.getmodel(model))","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"In addition, we can also programatically query the structure of the graph:","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"RxInfer.getrandomvars(model)","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"RxInfer.getdatavars(model)","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"RxInfer.getconstantvars(model)","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"RxInfer.getfactornodes(model)","category":"page"},{"location":"manuals/getting-started/#Conditioning-on-data-that-is-not-available-at-model-creation-time","page":"Getting started","title":"Conditioning on data that is not available at model creation time","text":"","category":"section"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"Sometimes the data is not known at model creation time, for example, during reactive inference. For that purpose RxInfer uses RxInfer.DeferredDataHandler structure.","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"# The only difference here is that we do not specify `a` and `b` as hyperparameters \n# But rather indicate that the data for them will be available later during the inference\nconditioned_with_deffered_data = coin_model() | (\n    y = [ true, false, true ], \n    a = RxInfer.DeferredDataHandler(), \n    b = RxInfer.DeferredDataHandler()\n)\n\n# The graph creation API does not change\nmodel_with_deffered_data = RxInfer.create_model(conditioned_with_deffered_data)\n\n# We can visualise the graph with missing data handles as well\nGraphPlot.gplot(RxInfer.getmodel(model_with_deffered_data))","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"From the model structure visualisation we can see now that both a and b are no longer indicated as constants. Read more about the structure of the graph in GraphPPL documentation.","category":"page"},{"location":"manuals/getting-started/#getting-started-inference-specification","page":"Getting started","title":"Inference specification","text":"","category":"section"},{"location":"manuals/getting-started/#Automatic-inference-specification","page":"Getting started","title":"Automatic inference specification","text":"","category":"section"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"Once we have defined our model, the next step is to use RxInfer API to infer quantities of interests. To do this we can use a generic infer function that supports static datasets. Read more information about the infer function in the Inference Execution documentation section.","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"result = infer(\n    model = coin_model(a = 2.0, b = 7.0),\n    data  = (y = dataset, )\n)","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"As you can see we don't need to condition on the data manually, the infer function will do it automatically. After the inference is complete we can fetch the results from the .posterior field with the name of the latent state:","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"θestimated = result.posteriors[:θ]","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"We can also compute some statistical properties of the result:","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"println(\"Real bias is \", coin_bias)\nprintln(\"Estimated bias is \", mean(θestimated))\nprintln(\"Standard deviation \", std(θestimated))\nnothing #hide","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"Let's also visualize the resulting posteriors:","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"using Plots\n\nrθ = range(0, 1, length = 1000)\n\np1 = plot(rθ, (x) -> pdf(Beta(2.0, 7.0), x), title=\"Prior\", fillalpha=0.3, fillrange = 0, label=\"P(θ)\", c=1,)\np2 = plot(rθ, (x) -> pdf(θestimated, x), title=\"Posterior\", fillalpha=0.3, fillrange = 0, label=\"P(θ|y)\", c=3)\n\nplot(p1, p2, layout = @layout([ a; b ]))","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"In our dataset we used 10 coin flips and skewed prior to estimate the bias of a coin.  It resulted in a vague posterior distribution, however RxInfer scales very well for large models and factor graphs.  We may use more coin flips in our dataset for better posterior distribution estimates:","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"dataset_100   = rand(rng, Bernoulli(coin_bias), 100)\ndataset_1000  = rand(rng, Bernoulli(coin_bias), 1000)\ndataset_10000 = rand(rng, Bernoulli(coin_bias), 10000)\nnothing # hide","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"θestimated_100   = infer(model = coin_model(a = 2.0, b = 7.0), data  = (y = dataset_100, ))\nθestimated_1000  = infer(model = coin_model(a = 2.0, b = 7.0), data  = (y = dataset_1000, ))\nθestimated_10000 = infer(model = coin_model(a = 2.0, b = 7.0), data  = (y = dataset_10000, ))\nnothing #hide","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"Let's investigate how the number of observation affects the estimated posterior:","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"p3 = plot(title = \"Posterior\", legend = :topleft)\np3 = plot!(p3, rθ, (x) -> pdf(θestimated_100.posteriors[:θ], x), fillalpha = 0.3, fillrange = 0, label = \"P(θ|y_100)\", c = 4)\np3 = plot!(p3, rθ, (x) -> pdf(θestimated_1000.posteriors[:θ], x), fillalpha = 0.3, fillrange = 0, label = \"P(θ|y_1000)\", c = 5)\np3 = plot!(p3, rθ, (x) -> pdf(θestimated_10000.posteriors[:θ], x), fillalpha = 0.3, fillrange = 0, label = \"P(θ|y_10000)\", c = 6)\n\nplot(p1, p3, layout = @layout([ a; b ]))","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"We can see that with larger dataset our posterior marginal estimate becomes more and more accurate and represents real value of the bias of a coin.","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"println(\"Real bias is \", coin_bias)\nprintln(\"Estimated bias is \", mean(θestimated_10000.posteriors[:θ]))\nprintln(\"Standard deviation \", std(θestimated_10000.posteriors[:θ]))\nnothing #hide","category":"page"},{"location":"manuals/getting-started/#Missing-data-points","page":"Getting started","title":"Missing data points","text":"","category":"section"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"RxInfer inference engine understands missing data points in the dataset, for example:","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"result = infer(\n    model = coin_model(a = 2.0, b = 7.0),\n    data  = (y = [ true, false, missing, true, false ], )\n)\nresult.posteriors[:θ]","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"In principle, the entire dataset may consist of missing entries:","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"result = infer(\n    model = coin_model(a = 2.0, b = 7.0),\n    data  = (y = [ missing, missing, missing, missing, missing ], )\n)","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"In this case, the resulting posterior is simply equal to the prior (as expected, since no extra information can be extracted from the observations):","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"@test result.posteriors[:θ] == Beta(2.0, 7.0) #hide\nresult.posteriors[:θ]","category":"page"},{"location":"manuals/getting-started/#Where-to-go-next?","page":"Getting started","title":"Where to go next?","text":"","category":"section"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"There are a set of examples available in RxInfer repository that demonstrate the more advanced features of the package for various problems. Alternatively, you can head to the Model specification which provides more detailed information of how to use RxInfer to specify probabilistic models. Inference execution section provides a documentation about RxInfer API for running reactive Bayesian inference. Also read the Comparison to compare RxInfer with other probabilistic programming libraries. For advances use cases refer to the Non-conjugate inference tutorial and inference without defining the message update rules explicitly.","category":"page"},{"location":"manuals/getting-started/","page":"Getting started","title":"Getting started","text":"","category":"page"},{"location":"manuals/telemetry/#manual-usage-telemetry","page":"Sharing sessions & telemetry","title":"RxInfer Usage Telemetry","text":"","category":"section"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"RxInfer has two separate telemetry features:","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"A minimal package usage counter (enabled by default)\nOptional session sharing for better support and development insights","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"note: Note\nThe telemetry implementation in RxInfer has been designed with careful consideration of the community discussion about telemetry in Julia packages, particularly the discourse thread \"Pkg.jl telemetry should be opt-in\". We've aimed to strike a balance between gathering useful information for package development while respecting user privacy and control.","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"The following table compares the key properties of RxInfer's two telemetry features.","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"Property Package Usage Counter Session Sharing\nEntirely Anonymous Yes Yes\nShared Across Julia Sessions No No\nEnabled by default Yes (opt-out) No (opt-in)\nDeletion Request Support No (UUIDs not persistent, we cannot backtrace the session to a specific user) Yes* (only if users save their session ID and share it with us anonymously with the form below, otherwise we cannot backtrace the session to a specific user)\nCan Be Disabled for a Specific Julia Session Yes Yes (disabled by default)\nCan Be Disabled for All Julia Sessions Yes Yes (disabled by default)\nCan Be Disabled with Environment Variable Yes Yes (disabled by default)\nCustomizable Behavior Yes (with Preferences.jl, see Package Usage Counter manual) Yes (with Preferences.jl, see Session Sharing manual)\nCan Be Enabled for a Specific Julia Session Yes Yes\nCan Be Enabled for All Julia Sessions Yes Yes\nWhat Is Being Recorded Only timestamp and random UUID Session metadata & errors, no actual data\nReal-Time Sharing of Recorded Data Yes (on package load) Optional (manual/automatic)\nLocal Access to Recorded Data N/A (No data is collected) Yes (via session inspection, see Session Summary manual)\nEnables Extra Support from Core Developers No Yes* (if users are willing to share their session ID when opening a GitHub issue or a discussion on the GitHub repository, otherwise we cannot backtrace the session to a specific user)\nPerformance Impact Negligible (only on package load) Minimal (async sharing)\nCI Environment Behavior Automatically disabled Automatically disabled","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"Users are welcome to join our regular online meetings where we analyze the collected data and discuss how it helps shape RxInfer's development.","category":"page"},{"location":"manuals/telemetry/#manual-package-usage-counter","page":"Sharing sessions & telemetry","title":"Package Usage Counter","text":"","category":"section"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"By default, RxInfer counts how many times the package is loaded via using RxInfer. This counter:","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"Only records a timestamp and a random UUID for deduplication\nUUIDs are not persistent and are re-generated for each session\nDoes not collect any code, data, or environment information\nIs completely anonymous\nHelps us understand how widely RxInfer is used","category":"page"},{"location":"manuals/telemetry/#[Disabling-Package-Usage-Counter","page":"Sharing sessions & telemetry","title":"[Disabling Package Usage Counter","text":"","category":"section"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"You can disable the counter in several ways:","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"Using Julia functions:\nusing RxInfer\nRxInfer.disable_rxinfer_using_telemetry!() # Requires Julia restart\nUsing environment variables:\nexport LOG_USING_RXINFER=false","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"The counter is also automatically disabled in:","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"CI environments (detected via CI=true environment variable)\nWhen telemetry is disabled via disable_rxinfer_using_telemetry!()\nWhen the telemetry endpoint is set to nothing","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"RxInfer.log_using_rxinfer\nRxInfer.disable_rxinfer_using_telemetry!\nRxInfer.enable_rxinfer_using_telemetry!\nRxInfer.set_telemetry_endpoint!","category":"page"},{"location":"manuals/telemetry/#RxInfer.log_using_rxinfer","page":"Sharing sessions & telemetry","title":"RxInfer.log_using_rxinfer","text":"log_using_rxinfer()\n\nSend an anonymous usage statistics event to the telemetry endpoint on using RxInfer. This function makes an asynchronous HTTP POST request to the configured endpoint. See RxInfer.set_telemetry_endpoint! to configure the endpoint. If the telemetry endpoint is set to nothing, this function does nothing. The call sends only timestamp and a random UUID.  The request is made asynchronously to avoid blocking the user's workflow. See RxInfer.disable_rxinfer_using_telemetry! to disable telemetry on using RxInfer. Alternatively, set the environment variable LOG_USING_RXINFER to false to disable logging.\n\n\n\n\n\n","category":"function"},{"location":"manuals/telemetry/#RxInfer.disable_rxinfer_using_telemetry!","page":"Sharing sessions & telemetry","title":"RxInfer.disable_rxinfer_using_telemetry!","text":"disable_rxinfer_using_telemetry!()\n\nDisable telemetry collection on using RxInfer at compile time. The change requires a Julia session restart to take effect.\n\nSee also: set_telemetry_endpoint!, enable_rxinfer_using_telemetry!\n\n\n\n\n\n","category":"function"},{"location":"manuals/telemetry/#RxInfer.enable_rxinfer_using_telemetry!","page":"Sharing sessions & telemetry","title":"RxInfer.enable_rxinfer_using_telemetry!","text":"enable_rxinfer_using_telemetry!()\n\nEnable telemetry collection on using RxInfer at compile time. The change requires a Julia session restart to take effect.\n\nSee also: set_telemetry_endpoint!, disable_rxinfer_using_telemetry!\n\n\n\n\n\n","category":"function"},{"location":"manuals/telemetry/#RxInfer.set_telemetry_endpoint!","page":"Sharing sessions & telemetry","title":"RxInfer.set_telemetry_endpoint!","text":"set_telemetry_endpoint!(endpoint)\n\nSet the telemetry endpoint URL for RxInfer.jl at compile time. This endpoint is used for collecting anonymous usage statistics to help improve the package.\n\nThe change requires a Julia session restart to take effect.\n\nArguments\n\nendpoint: The URL of the telemetry endpoint as a String or nothing`\n\n\n\n\n\n","category":"function"},{"location":"manuals/telemetry/#manual-session-sharing","page":"Sharing sessions & telemetry","title":"Session Sharing","text":"","category":"section"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"RxInfer includes a built-in session tracking feature (detailed in Session Summary) that helps you monitor and debug your inference tasks. You can choose to share these sessions with core developers to:","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"Get better support when encountering issues\nHelp improve RxInfer through real-world usage insights\nContribute to community-driven development","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"Read more about what data is present in the session history in the Session Summary manual.","category":"page"},{"location":"manuals/telemetry/#How-to-Share-Sessions","page":"Sharing sessions & telemetry","title":"How to Share Sessions","text":"","category":"section"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"You can share your session data either manually or automatically.","category":"page"},{"location":"manuals/telemetry/#Manual-Sharing","page":"Sharing sessions & telemetry","title":"Manual Sharing","text":"","category":"section"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"Use the share_session_data function to manually share your session:","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"RxInfer.share_session_data","category":"page"},{"location":"manuals/telemetry/#RxInfer.share_session_data","page":"Sharing sessions & telemetry","title":"RxInfer.share_session_data","text":"share_session_data(session = RxInfer.default_session(); show_progress::Bool = true)\n\nShare your session data to help improve RxInfer.jl and its community. This data helps us:\n\nUnderstand how the package is used in practice\nIdentify areas for improvement\nMake informed decisions about future development\nShare aggregate usage patterns in our community meetings\n\nThe data is organized in a structured way:\n\nBasic session info (Julia version, OS, etc.)\nAnonymous statistics about different types of package usage\nInformation about individual labeled runs\n\nAll data is anonymous and only used to improve the package. We discuss aggregate statistics  in our public community meetings to make the development process transparent and collaborative.\n\nArguments\n\nsession::Session: The session object containing data to share\nshow_progress::Bool = true: Whether to display progress bars during sharing\n\nProgress Display\n\nWhen show_progress is true (default), the function displays:\n\nA blue progress bar for sharing session statistics\nA green progress bar for sharing labeled runs\n\n\n\n\n\n","category":"function"},{"location":"manuals/telemetry/#Automatic-Sharing","page":"Sharing sessions & telemetry","title":"Automatic Sharing","text":"","category":"section"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"You can enable automatic session sharing after each session update:","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"RxInfer.enable_automatic_session_sharing!\nRxInfer.disable_automatic_session_sharing!","category":"page"},{"location":"manuals/telemetry/#RxInfer.enable_automatic_session_sharing!","page":"Sharing sessions & telemetry","title":"RxInfer.enable_automatic_session_sharing!","text":"enable_automatic_session_sharing!()\n\nEnable automatic session sharing after each inference call. The change requires a Julia session restart to take effect. When enabled, session data will be automatically shared after each successful inference call. This helps improve RxInfer by providing usage patterns and helps with debugging issues.\n\nSee also: disable_automatic_session_sharing!, share_session_data\n\n\n\n\n\n","category":"function"},{"location":"manuals/telemetry/#RxInfer.disable_automatic_session_sharing!","page":"Sharing sessions & telemetry","title":"RxInfer.disable_automatic_session_sharing!","text":"disable_automatic_session_sharing!()\n\nDisable automatic session sharing after inference calls. The change requires a Julia session restart to take effect.\n\nSee also: enable_automatic_session_sharing!, share_session_data\n\n\n\n\n\n","category":"function"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"When automatic sharing is enabled:","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"Session data is shared after each session update\nSharing is done asynchronously (won't block your code)\nNo progress bars or messages are shown\nFailed sharing attempts are silently ignored","category":"page"},{"location":"manuals/telemetry/#Using-Session-IDs-in-Issues","page":"Sharing sessions & telemetry","title":"Using Session IDs in Issues","text":"","category":"section"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"When you share a session and then open a GitHub issue, include your session ID. This helps us:","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"Link your issue to the shared session data\nUnderstand your usage context\nProvide more accurate and helpful support","category":"page"},{"location":"manuals/telemetry/#Deleting-Shared-Data","page":"Sharing sessions & telemetry","title":"Deleting Shared Data","text":"","category":"section"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"If you wish to delete previously shared session data, you can contact the core developers through GitHub issues at RxInfer.jl or anonymously with the following form.","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"When requesting deletion, you must provide the session UUID. Without this identifier, we cannot trace specific sessions back to individual users. See the Session Summary manual for details on how to obtain your session ID.","category":"page"},{"location":"manuals/telemetry/#Privacy-and-Control","page":"Sharing sessions & telemetry","title":"Privacy and Control","text":"","category":"section"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"Remember:","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"Session sharing is completely optional\nAll statistics are anonymous, UUIDs are not persistent and are re-generated for each session\nNo actual data is shared, only meta information (e.g., type of data, number of observations)\nYou can inspect the sharing code in src/telemetry.jl\nWe only use this data to help improve RxInfer and provide better support","category":"page"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"We appreciate your help in making RxInfer better! Whether you choose to enable telemetry or share sessions, your contribution helps us improve the package for everyone.","category":"page"},{"location":"manuals/telemetry/#Developers-Reference","page":"Sharing sessions & telemetry","title":"Developers Reference","text":"","category":"section"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"RxInfer.to_firestore_invoke\nRxInfer.to_firestore_value\nRxInfer.to_firestore_session\nRxInfer.to_firestore_document\nRxInfer.to_firestore_session_stats","category":"page"},{"location":"manuals/telemetry/#RxInfer.to_firestore_invoke","page":"Sharing sessions & telemetry","title":"RxInfer.to_firestore_invoke","text":"to_firestore_invoke(invoke::SessionInvoke, stats_id::UUID)\n\nConvert a SessionInvoke object to a Firestore-compatible document format. Includes a reference to the parent session stats.\n\n\n\n\n\n","category":"function"},{"location":"manuals/telemetry/#RxInfer.to_firestore_value","page":"Sharing sessions & telemetry","title":"RxInfer.to_firestore_value","text":"to_firestore_value(value)\n\nConvert a Julia value to a Firestore-compatible value format. Returns a NamedTuple with the appropriate Firestore field type.\n\n\n\n\n\n","category":"function"},{"location":"manuals/telemetry/#RxInfer.to_firestore_session","page":"Sharing sessions & telemetry","title":"RxInfer.to_firestore_session","text":"to_firestore_session(session::Session)\n\nConvert a Session object to a Firestore-compatible document format.\n\n\n\n\n\n","category":"function"},{"location":"manuals/telemetry/#RxInfer.to_firestore_document","page":"Sharing sessions & telemetry","title":"RxInfer.to_firestore_document","text":"to_firestore_document(data::NamedTuple)\n\nConvert a Julia NamedTuple to a Firestore document format. Returns a NamedTuple with fields in Firestore format.\n\n\n\n\n\n","category":"function"},{"location":"manuals/telemetry/#RxInfer.to_firestore_session_stats","page":"Sharing sessions & telemetry","title":"RxInfer.to_firestore_session_stats","text":"to_firestore_session_stats(stats::SessionStats, session_id::UUID)\n\nConvert a SessionStats object to a Firestore-compatible document format. Includes a reference to the parent session.\n\n\n\n\n\n","category":"function"},{"location":"manuals/telemetry/","page":"Sharing sessions & telemetry","title":"Sharing sessions & telemetry","text":"","category":"page"},{"location":"manuals/debugging/#user-guide-debugging","page":"Debugging","title":"Debugging","text":"","category":"section"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"Debugging inference in RxInfer can be quite challenging, mostly due to the reactive nature of the inference, undefined order of computations, the use of observables, and generally hard-to-read stack traces in Julia. Below we discuss ways to help you find problems in your model that prevents you from getting the results you want. ","category":"page"},{"location":"manuals/debugging/#Getting-Help-from-the-Community","page":"Debugging","title":"Getting Help from the Community","text":"","category":"section"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"When you encounter issues that are difficult to debug, the RxInfer community is here to help. To get the most effective support:","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"Share Session Data: For complex issues, you can share your session data to help us understand exactly what's happening in your model. See Session Sharing to learn how.\nJoin Community Meetings: We discuss common issues and solutions in our regular community meetings. See Getting Help with Issues for more information.","category":"page"},{"location":"manuals/debugging/#Requesting-a-trace-of-messages","page":"Debugging","title":"Requesting a trace of messages","text":"","category":"section"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"RxInfer provides a way that allows to save the history of the computations leading up to the computed messages and marginals in the inference procedure. This history is added on top of messages and marginals and is referred to as a Memory Addon. Below is an example explaining how you can extract this history and use it to fix a bug.","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"note: Note\nAddons is a feature of ReactiveMP. Read more about implementing custom addons in the corresponding section of ReactiveMP package.","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"We show the application of the Memory Addon on the coin toss example from earlier in the documentation. We model the binary outcome x (heads or tails) using a Bernoulli distribution, with a parameter theta that represents the probability of landing on heads. We have a Beta prior distribution for the theta parameter, with a known shape alpha and rate beta parameter.","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"theta sim mathrmBeta(a b)","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"x_i sim mathrmBernoulli(theta)","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"where x_i in 0 1 are the binary observations (heads = 1, tails = 0). This is the corresponding RxInfer model:","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"using RxInfer, Random, Plots\n\nn = 4\nθ_real = 0.3\ndataset = float.(rand(Bernoulli(θ_real), n))\n\n@model function coin_model(x)\n    θ  ~ Beta(4, huge)\n    x .~ Bernoulli(θ)\nend\n\nresult = infer(\n    model = coin_model(), \n    data  = (x = dataset, ),\n)","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"The model will run without errors. But when we plot the posterior distribution for theta, something's wrong. The posterior seems to be a flat distribution:","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"\nrθ = range(0, 1, length = 1000)\n\nplot(rθ, (rvar) -> pdf(result.posteriors[:θ], rvar), label=\"Infered posterior\")\nvline!([θ_real], label=\"Real θ\", title = \"Inference results\")","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"We can figure out what's wrong by tracing the computation of the posterior with the Memory Addon.  To obtain the trace, we have to add addons = (AddonMemory(),) as an argument to the inference function.  Note, that the argument to the addons keyword argument must be a tuple, because multiple addons can be activated  at the same time. Here, we create a tuple with a single element however.","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"result = infer(\n    model = coin_model(), \n    data  = (x = dataset, ),\n    addons = (AddonMemory(),)\n)","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"Now we have access to the messages that led to the marginal posterior:","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"RxInfer.ReactiveMP.getaddons(result.posteriors[:θ])","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"(Image: Addons_messages)","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"The messages in the factor graph are marked in color. If you're interested in the mathematics behind these results, consider verifying them manually using the general equation for sum-product messages:","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"underbraceoverrightarrowmu_θ(θ)_substack textoutgoing textmessage = sum_x_1ldotsx_n underbraceoverrightarrowmu_X_1(x_1)cdots overrightarrowmu_X_n(x_n)_substacktextincoming  textmessages cdot underbracef(θx_1ldotsx_n)_substacktextnode textfunction","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"(Image: Graph)","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"Note that the posterior (yellow) has a rate parameter on the order of 1e12. Our plot failed because a Beta distribution with such a rate parameter cannot be accurately depicted using the range of theta we used in the code block above. So why does the posterior have this rate parameter?","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"All the observations (purple, green, pink, blue) have much smaller rate parameters. It seems the prior distribution (red) has an unusual rate parameter, namely 1e12. If we look back at the model, the parameter was set to huge (which is a reserved keyword meaning 1e12). Reducing the prior rate parameter will ensure the posterior has a reasonable rate parameter as well.","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"@model function coin_model(x)\n    θ  ~ Beta(4, 100)\n    x .~ Bernoulli(θ)\nend\n\nresult = infer(\n    model = coin_model(), \n    data  = (x = dataset, ),\n)","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"rθ = range(0, 1, length = 1000)\n\nplot(rθ, (rvar) -> pdf(result.posteriors[:θ], rvar), fillalpha = 0.4, fill = 0, label=\"Infered posterior\")\nvline!([θ_real], label=\"Real θ\", title = \"Inference results\")","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"Now the posterior has much more sensible shape thus confirming that we have identified the original issue correctly.  We can run the model with more observations, to get an even better posterior:","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"result = infer(\n    model = coin_model(), \n    data  = (x = float.(rand(Bernoulli(θ_real), 1000)), ),\n)\n\nrθ = range(0, 1, length = 1000)\nplot(rθ, (rvar) -> pdf(result.posteriors[:θ], rvar), fillalpha = 0.4, fill = 0, label=\"Infered posterior (1000 observations)\")\nvline!([θ_real], label=\"Real θ\", title = \"Inference results\")","category":"page"},{"location":"manuals/debugging/#user-guide-debugging-callbacks","page":"Debugging","title":"Using callbacks in the infer function","text":"","category":"section"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"Another way to inspect the inference procedure is to use the callbacks or events from the infer function. Read more about callbacks in the documentation to the infer function. Here, we show a simple application of callbacks to a simple IID inference problem. We start with model specification:","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"using RxInfer\n\n@model function iid_normal(y)\n    μ  ~ Normal(mean = 0.0, variance = 100.0)\n    γ  ~ Gamma(shape = 1.0, rate = 1.0)\n    y .~ Normal(mean = μ, precision = γ)\nend","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"Next, let us define a syntehtic dataset:","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"dataset = rand(NormalMeanPrecision(3.1415, 30.0), 100)\nnothing #hide","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"Now, we can use the callbacks argument of the infer function to track the order of posteriors computation and their intermediate values for each variational iteration:","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"# A callback that will be called every time before a variational iteration starts\nfunction before_iteration_callback(model, iteration)\n    println(\"Starting iteration \", iteration)\nend\n\n# A callback that will be called every time after a variational iteration finishes\nfunction after_iteration_callback(model, iteration)\n    println(\"Iteration \", iteration, \" has been finished\")\nend\n\n# A callback that will be called every time a posterior is updated\nfunction on_marginal_update_callback(model, variable_name, posterior)\n    println(\"Latent variable \", variable_name, \" has been updated. Estimated mean is \", mean(posterior), \" with standard deviation \", std(posterior))\nend","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"After we have defined all callbacks of interest, we can call the infer function passing them in the callback argument as a named tuple:","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"init = @initialization begin \n    q(μ) = vague(NormalMeanVariance)\nend\n\nresult = infer(\n    model = iid_normal(),\n    data  = (y = dataset, ),\n    constraints = MeanField(),\n    iterations = 5,\n    initialization = init,\n    returnvars = KeepLast(),\n    callbacks = (\n        on_marginal_update = on_marginal_update_callback,\n        before_iteration   = before_iteration_callback,\n        after_iteration    = after_iteration_callback\n    )\n)\nnothing #hide","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"We can see that the callback has been correctly executed for each intermediate variational iteration.","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"println(\"Estimated mean: \", mean(result.posteriors[:μ]))\nprintln(\"Estimated precision: \", mean(result.posteriors[:γ]))\nnothing #hide","category":"page"},{"location":"manuals/debugging/#Using-LoggerPipelineStage","page":"Debugging","title":"Using LoggerPipelineStage","text":"","category":"section"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"ReactiveMP inference engine allows attaching extra computations to the default computational pipeline of message passing.  Read more about pipelines in the corresponding section of ReactiveMP. Here we show how to use LoggerPipelineStage to trace the order of message passing updates for debugging purposes. We start with model specification:","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"using RxInfer\n\n@model function iid_normal_with_pipeline(y)\n    μ  ~ Normal(mean = 0.0, variance = 100.0)\n    γ  ~ Gamma(shape = 1.0, rate = 1.0)\n    y .~ Normal(mean = μ, precision = γ) where { pipeline = LoggerPipelineStage() }\nend","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"Next, let us define a syntehtic dataset:","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"# We use less data points in the dataset to reduce the amount of text printed\n# during the inference\ndataset = rand(NormalMeanPrecision(3.1415, 30.0), 5)\nnothing #hide","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"Now, we can call the infer function. We combine the pipeline logger stage with the callbacks, which were introduced in the previous section:","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"result = infer(\n    model = iid_normal_with_pipeline(),\n    data  = (y = dataset, ),\n    constraints = MeanField(),\n    iterations = 5,\n    initialization = init,\n    returnvars = KeepLast(),\n    callbacks = (\n        on_marginal_update = on_marginal_update_callback,\n        before_iteration   = before_iteration_callback,\n        after_iteration    = after_iteration_callback\n    )\n)\nnothing #hide","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"We can see the order of message update events. Note that ReactiveMP may decide to compute messages lazily, in which case the actual computation of the value of a message will be deffered until later moment. In this case, LoggerPipelineStage will report DefferedMessage.","category":"page"},{"location":"manuals/debugging/#user-guide-debugging-benchmark-callbacks","page":"Debugging","title":"Using RxInferBenchmarkCallbacks for Performance Analysis","text":"","category":"section"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"RxInfer provides a built-in benchmarking callback structure called RxInferBenchmarkCallbacks that helps collect timing information during the inference procedure. This structure aggregates timing information across multiple runs, allowing you to track performance statistics (min/max/average/etc.) of your model's creation and inference procedure.","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"Here's how to use it:","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"using RxInfer\n\ninfer(model = iid_normal(), data = (y = dataset, ), constraints = MeanField(), iterations = 5, initialization = init, callbacks = RxInferBenchmarkCallbacks()) #hide\n\n# Create a benchmark callbacks instance to track performance\nbenchmark_callbacks = RxInferBenchmarkCallbacks()\n\n# Run inference multiple times to gather statistics\nfor i in 1:3  # Usually you'd want more runs for better statistics\n    infer(\n        model = iid_normal(),\n        data = (y = dataset, ),\n        constraints = MeanField(),\n        iterations = 5,\n        initialization = init,\n        callbacks = benchmark_callbacks\n    )\nend","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"# Display the benchmark statistics\nbenchmark_callbacks","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"The RxInferBenchmarkCallbacks structure collects timestamps at various stages of the inference process:","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"Before and after model creation\nBefore and after inference starts/ends\nBefore and after each iteration\nBefore and after autostart (for streaming inference)","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"RxInferBenchmarkCallbacks\nRxInfer.get_benchmark_stats\nRxInfer.DEFAULT_BENCHMARK_CALLBACKS_BUFFER_CAPACITY","category":"page"},{"location":"manuals/debugging/#RxInfer.RxInferBenchmarkCallbacks","page":"Debugging","title":"RxInfer.RxInferBenchmarkCallbacks","text":"RxInferBenchmarkCallbacks(; capacity = RxInfer.DEFAULT_BENCHMARK_CALLBACKS_BUFFER_CAPACITY)\n\nA callback structure for collecting timing information during the inference procedure. This structure collects timestamps for various stages of the inference process and aggregates them across multiple runs, allowing you to track performance statistics (min/max/average/etc.) of your model's creation and inference procedure. The structure supports pretty printing by default, displaying timing statistics in a human-readable format.\n\nThe structure uses circular buffers with a default capacity of 1000 entries to store timestamps, which helps to limit memory usage in long-running applications. Use RxInferBenchmarkCallbacks(; capacity = N) to change the buffer capacity. See also RxInfer.get_benchmark_stats(callbacks).\n\nFields\n\nbefore_model_creation_ts: CircularBuffer of timestamps before model creation\nafter_model_creation_ts: CircularBuffer of timestamps after model creation\nbefore_inference_ts: CircularBuffer of timestamps before inference starts\nafter_inference_ts: CircularBuffer of timestamps after inference ends\nbefore_iteration_ts: CircularBuffer of vectors of timestamps before each iteration\nafter_iteration_ts: CircularBuffer of vectors of timestamps after each iteration\nbefore_autostart_ts: CircularBuffer of timestamps before autostart\nafter_autostart_ts: CircularBuffer of timestamps after autostart\n\nExample\n\n# Create a callbacks instance to track performance\ncallbacks = RxInferBenchmarkCallbacks()\n\n# Run inference multiple times to gather statistics\nfor _ in 1:10\n    infer(\n        model = my_model(),\n        data = my_data,\n        callbacks = callbacks\n    )\nend\n\n# Display the timing statistics (uses pretty printing by default)\ncallbacks\n\n\n\n\n\n","category":"type"},{"location":"manuals/debugging/#RxInfer.get_benchmark_stats","page":"Debugging","title":"RxInfer.get_benchmark_stats","text":"get_benchmark_stats(callbacks::RxInferBenchmarkCallbacks)\n\nReturns a matrix containing benchmark statistics for different operations in the inference process. The matrix contains the following columns:\n\nOperation name (String)\nMinimum time (Float64)\nMaximum time (Float64)\nMean time (Float64)\nMedian time (Float64)\nStandard deviation (Float64)\n\nEach row represents a different operation (model creation, inference, iteration, autostart). Times are in nanoseconds.\n\n\n\n\n\n","category":"function"},{"location":"manuals/debugging/#RxInfer.DEFAULT_BENCHMARK_CALLBACKS_BUFFER_CAPACITY","page":"Debugging","title":"RxInfer.DEFAULT_BENCHMARK_CALLBACKS_BUFFER_CAPACITY","text":"DEFAULT_BENCHMARK_CALLBACKS_BUFFER_CAPACITY\n\nThe default capacity of the circular buffers used to store timestamps in the RxInferBenchmarkCallbacks structure.\n\n\n\n\n\n","category":"constant"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"note: Note\nBy default, the RxInferBenchmarkCallbacks structure uses a circular buffer with a limited capacity to store timestamps. This helps limit memory usage in long-running applications. You can change the buffer capacity by passing a different value to the capacity keyword argument of the RxInferBenchmarkCallbacks constructor.","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"This information can be used to:","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"Track performance statistics (min/max/average) of your inference procedure\nIdentify performance variability across runs\nMonitor the time spent in different stages of inference\nEstablish performance baselines for your models\nDetect performance regressions","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"The timestamps are collected using time_ns() for high precision timing measurements and are automatically formatted into human-readable durations when displayed.","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"note: Note\nThe timing measurements include all overhead from the Julia runtime and may vary between runs. For more precise benchmarking of specific code sections, consider using the BenchmarkTools.jl package. When gathering performance statistics, consider running multiple iterations to get more reliable metrics.","category":"page"},{"location":"manuals/debugging/","page":"Debugging","title":"Debugging","text":"","category":"page"},{"location":"manuals/customization/postprocess/#user-guide-inference-postprocess","page":"Inference results postprocessing","title":"Inference results postprocessing","text":"","category":"section"},{"location":"manuals/customization/postprocess/","page":"Inference results postprocessing","title":"Inference results postprocessing","text":"infer allow users to postprocess the inference result with the postprocess = ... keyword argument. The inference engine  operates on wrapper types to distinguish between marginals and messages. By default these wrapper types are removed from the inference results if no addons option is present. Together with the enabled addons, however, the wrapper types are preserved in the inference result output value. Use the options below to change this behaviour:","category":"page"},{"location":"manuals/customization/postprocess/","page":"Inference results postprocessing","title":"Inference results postprocessing","text":"inference_postprocess\nDefaultPostprocess\nUnpackMarginalPostprocess\nNoopPostprocess","category":"page"},{"location":"manuals/customization/postprocess/#RxInfer.inference_postprocess","page":"Inference results postprocessing","title":"RxInfer.inference_postprocess","text":"inference_postprocess(strategy, result)\n\nThis function modifies the result of the inference procedure according to the strategy.  The result can be a Marginal or a collection of Marginals. The default strategy is DefaultPostprocess.\n\n\n\n\n\n","category":"function"},{"location":"manuals/customization/postprocess/#RxInfer.DefaultPostprocess","page":"Inference results postprocessing","title":"RxInfer.DefaultPostprocess","text":"DefaultPostprocess picks the most suitable postprocessing step automatically.\n\n\n\n\n\n","category":"type"},{"location":"manuals/customization/postprocess/#RxInfer.UnpackMarginalPostprocess","page":"Inference results postprocessing","title":"RxInfer.UnpackMarginalPostprocess","text":"This postprocessing step removes the Marginal wrapper type from the result.\n\n\n\n\n\n","category":"type"},{"location":"manuals/customization/postprocess/#RxInfer.NoopPostprocess","page":"Inference results postprocessing","title":"RxInfer.NoopPostprocess","text":"This postprocessing step does nothing.\n\n\n\n\n\n","category":"type"},{"location":"manuals/customization/postprocess/#user-guide-inference-postprocess-custom","page":"Inference results postprocessing","title":"Custom postprocessing step","text":"","category":"section"},{"location":"manuals/customization/postprocess/","page":"Inference results postprocessing","title":"Inference results postprocessing","text":"In order to implement a custom postprocessing strategy simply implement the inference_postprocess method:","category":"page"},{"location":"manuals/customization/postprocess/","page":"Inference results postprocessing","title":"Inference results postprocessing","text":"using RxInfer\n\nstruct CustomPostprocess end\n\n# For demonstration purposes out postprocessing step simply stringifyes the result\nRxInfer.inference_postprocess(::CustomPostprocess, result::Marginal) = string(ReactiveMP.getdata(result))","category":"page"},{"location":"manuals/customization/postprocess/","page":"Inference results postprocessing","title":"Inference results postprocessing","text":"Now, we can use the postprocessing step in the infer function:","category":"page"},{"location":"manuals/customization/postprocess/","page":"Inference results postprocessing","title":"Inference results postprocessing","text":"using Test #hide\n@model function beta_bernoulli(y)\n    θ ~ Beta(1, 1)\n    y ~ Bernoulli(θ)\nend\n\nresult = infer(\n    model = beta_bernoulli(),\n    data  = (y = 1.,),\n    postprocess = CustomPostprocess()\n)\n\n@test occursin(\"Beta{Float64}(α=2.0, β=1.0)\", result.posteriors[:θ]) #hide\nresult.posteriors[:θ] # should be a `String`","category":"page"},{"location":"manuals/customization/postprocess/","page":"Inference results postprocessing","title":"Inference results postprocessing","text":"@test result.posteriors[:θ] isa String #hide\nresult.posteriors[:θ] isa String","category":"page"},{"location":"manuals/customization/postprocess/","page":"Inference results postprocessing","title":"Inference results postprocessing","text":"","category":"page"},{"location":"manuals/inference/initialization/#initialization","page":"Initialization","title":"Understating why we need to initialize posteriors or messages in RxInfer","text":"","category":"section"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"In certain models, after completing the model specification step and moving on to execute the inference procedure, you may encounter an error prompting you to initialize required marginals and messages. Understanding why this step is necessary can be perplexing. This tutorial is designed to explore the intuition behind model initialization using a practical example","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"@initialization","category":"page"},{"location":"manuals/inference/initialization/#RxInfer.@initialization","page":"Initialization","title":"RxInfer.@initialization","text":"@initialization\n\nMacro for specifying the initialization state of a model. Accepts either a function or a block of code. Allows the specification of initial messages and marginals that can be applied to a model in the infer function.\n\n\n\n\n\n","category":"macro"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"The syntax for the @initialization macro is similar to the @constraints and @meta macro. An example is shown below:","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"using RxInfer\n\n@model function submodel(z, x) \n    t := x + 1\n    z ~ Normal(mean = t, var = 1.0)\nend \n\n@model function mymodel(y)\n    x ~ Normal(mean = 0.0, var = 1.0)\n    z ~ submodel(x = x)\n    y ~ Normal(mean = z, var = 1.0)\nend\n\n@initialization begin\n    # Initialize the marginal for the variable x\n    q(x) = vague(NormalMeanVariance)\n\n    # Initialize the message for the variable z\n    μ(z) = vague(NormalMeanVariance)\n\n    # Specify the initialization for a submodel of type `submodel`\n    for init in submodel\n        q(t) = vague(NormalMeanVariance)\n    end\n\n    # Specify the initialization for a submodel of type `submodel` with a specific index\n    for init in (submodel, 1)\n        q(t) = vague(NormalMeanVariance)\n    end\nend","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"Similar to the @constraints macro, the @initialization macro also supports function definitions:","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"@initialization function my_init()\n    # Initialize the marginal for the variable x\n    q(x) = vague(NormalMeanVariance)\n\n    # Initialize the message for the variable z\n    μ(z) = vague(NormalMeanVariance)\n\n    # Specify the initialization for a submodel of type `submodel`\n    for init in submodel\n        q(t) = vague(NormalMeanVariance)\n    end\n\n    # Specify the initialization for a submodel of type `submodel` with a specific index\n    for init in (submodel, 1)\n        q(t) = vague(NormalMeanVariance)\n    end\nend","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"The result of the initialization macro can be passed to the infer function with a keyword argument called initialization.","category":"page"},{"location":"manuals/inference/initialization/#Part-1.-Framing-the-problem","page":"Initialization","title":"Part 1. Framing the problem","text":"","category":"section"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"John has recently acquired a new car and is keenly interested in its fuel consumption rate. He holds the belief that this rate follows a linear relationship with the variable speed. To validate this hypothesis, he plans to conduct tests by driving his car on the urban roads close to his home, recording both the fuel consumption and speed data. To ascertain the fuel consumption rate, John has opted for Bayesian linear regression as his analytical method.","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"using Random, Plots, StableRNGs\n\nfunction generate_data(a, b, v, nr_samples; rng = StableRNG(1234))\n    x = float.(collect(1:nr_samples))\n    y = a .* x .+ b .+ randn(rng, nr_samples) .* sqrt(v)\n    return x, y\nend;\n\n# For demonstration purposes we generate some fake data \nx_data, y_data = generate_data(0.5, 25.0, 1.0, 250)\n\nscatter(x_data, y_data, title = \"Dataset (City road)\", legend=false)\nxlabel!(\"Speed\")\nylabel!(\"Fuel consumption\")","category":"page"},{"location":"manuals/inference/initialization/#Univariate-regression-with-known-noise","page":"Initialization","title":"Univariate regression with known noise","text":"","category":"section"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"First, he drives the car on a urban road. John enjoys driving on the well-built, wide, and flat urban roads. Urban roads also offer the advantage of precise fuel consumption measurement with minimal noise. Therefore John models the fuel consumption y_ninmathbbR as a normal distribution and treats x_n as a fixed hyperparameter:","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"beginaligned\np(y_n mid a b) = mathcalN(y_n mid a x_n + b  1)\nendaligned","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"The recorded speed is denoted as x_n in mathbbR and the recorded fuel consumption as y_n in mathbbR. Prior beliefs on a and b are informed by the vehicle manual.","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"beginaligned\n    p(a) = mathcalN(a mid m_a v_a) \n    p(b) = mathcalN(b mid m_b v_b) \nendaligned","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"Together they form the probabilistic model p(y a b) = p(a)p(b) prod_N=1^N p(y_n mid a b) where the goal is to infer the posterior distributions p(a mid y) and p(bmid y).","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"In order to estimate the two parameters with the recorded data, he uses a RxInfer.jl to create the above described model.","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"using RxInfer\n\n@model function linear_regression(y, x)\n    a  ~ Normal(mean = 0.0, variance = 1.0)\n    b  ~ Normal(mean = 0.0, variance = 100.0)\n    y .~ Normal(mean = a .* x .+ b, variance = 1.0)\nend","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"Delighted with the convenience offered by the package's inference function (infer), he appreciates the time saved from building everything from the ground up. This feature allows him to effortlessly obtain the desired results for his specific road. Upon consulting the documentation, he proceeds to run the inference function.","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"results = infer(\n    model        = linear_regression(), \n    data         = (y = y_data, x = x_data), \n    returnvars   = (a = KeepLast(), b = KeepLast()),\n    iterations   = 20,\n    free_energy  = true\n)","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"Oeps! Exception?","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"exception =\n│    Variables [ a, b ] have not been updated after an update event. \n│    Therefore, make sure to initialize all required marginals and messages. See `initialization` keyword argument for the inference function. \n│    See the function documentation for detailed information regarding the initialization.","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"After running the inference procedure an error appears, which prompts him to initialize all required messages and marginals. Now, John is left pondering the reason behind this requirement. Why is it necessary? Should he indeed initialize all messages and marginals? And if so, how might this impact the inference procedure?","category":"page"},{"location":"manuals/inference/initialization/#Part-2.-Why-and-What-to-initialize","page":"Initialization","title":"Part 2. Why and What to initialize","text":"","category":"section"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"Before delving too deeply into the details, it's important to understand that RxInfer constructs a factorized representation of your model using a factor graph. In this structure, inference is executed through message passing.","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"A challenge arises when RxInfer generates the FFG representation with structural loops in certain parts of the graph. These loops indicate that a message or marginal within the loop depends not only on its prior but also on itself. Consequently, proper initialization is crucial for initiating the inference process. Two general rules of thumb guide this initialization, although the intricate details are beyond the scope of this tutorial:","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"1.\tInitiate as few messages/marginals as possible when dealing with a loop structure, it will be more efficient and accurate. 2.\tPrioritize initializing marginals over messages.","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"How to identify and handle the loops?","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"Identifying loops is currently a manual process, as the current version of RxInfer doesn't support a graphical representation of the created graph. As such, the manual process involves:","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"1.\tDeriving the graphical representation of the model, 2.\tIdentifying loops and the messages or marginals that need to be initialized within the loop.","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"However, once you receive the message Variables [x, y, z] have not been updated after an update event, it is a good indication that there is a loop in your model. If you see this message, you should check your model for loops and try to initialize the messages and/or marginals that are part of the loop.","category":"page"},{"location":"manuals/inference/initialization/#Deriving-factor-graph-and-identifying-the-loops","page":"Initialization","title":"Deriving factor graph and identifying the loops","text":"","category":"section"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"John proceeds to derive the factor graph for his problem where he identifies where the loops are:","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"(Image: Addons_messages)","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"He does note that there is a loop in his model, namely all a and b variables are connected over all observations, therefore he needs to initialize one of the messages and run multiple iterations for the loopy belief propagation algorithm. It is worth noting that loopy belief propagation is not guaranteed to converge in general and might be highly influenced by the choice of the initial messages in the initialization argument. He is going to evaluate the convergency performance of the algorithm with the free_energy = true option:","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"init = @initialization begin\n    μ(b) = NormalMeanVariance(0.0, 100.0)\nend\n\nresults = infer(\n    model           = linear_regression(), \n    data            = (y = y_data, x = x_data), \n    initialization  = init, \n    returnvars      = (a = KeepLast(), b = KeepLast()),\n    iterations      = 20,\n    free_energy     = true\n)\n\n# drop first iteration, which is influenced by the `initmessages`\nplot(2:20, results.free_energy[2:end], title=\"Free energy\", xlabel=\"Iteration\", ylabel=\"Free energy [nats]\", legend=false)","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"Now the inference runs without the error! 🎉","category":"page"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"as = rand(results.posteriors[:a], 100)\nbs = rand(results.posteriors[:b], 100)\np = scatter(x_data, y_data, title = \"Linear regression with more noise\", legend=false)\nxlabel!(\"Speed\")\nylabel!(\"Fuel consumption\")\nfor (a, b) in zip(as, bs)\n    global p = plot!(p, x_data, a .* x_data .+ b, alpha = 0.05, color = :red)\nend\nplot(p, size = (900, 400))","category":"page"},{"location":"manuals/inference/initialization/#Implementation-details","page":"Initialization","title":"Implementation details","text":"","category":"section"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"RxInfer.InitializationPlugin\nRxInfer.convert_init_object","category":"page"},{"location":"manuals/inference/initialization/#RxInfer.InitializationPlugin","page":"Initialization","title":"RxInfer.InitializationPlugin","text":"MetaPlugin(init)\n\nA plugin that adds a init information to the factor nodes of the model.\n\n\n\n\n\n","category":"type"},{"location":"manuals/inference/initialization/#RxInfer.convert_init_object","page":"Initialization","title":"RxInfer.convert_init_object","text":"convert_init_object(e::Expr)\n\nConverts a variable init or a factor init call on the left hand side of a init specification to a GraphPPL.MetaObject.\n\nArguments\n\ne::Expr: The expression to convert.\n\nReturns\n\nExpr: The resulting expression with the variable reference or factor function call converted to a GraphPPL.MetaObject.\n\nExamples\n\n\n\n\n\n","category":"function"},{"location":"manuals/inference/initialization/","page":"Initialization","title":"Initialization","text":"","category":"page"},{"location":"manuals/inference/autoupdates/#autoupdates-guide","page":"Auto-updates","title":"Autoupdates specification","text":"","category":"section"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"@autoupdates","category":"page"},{"location":"manuals/inference/autoupdates/#RxInfer.@autoupdates","page":"Auto-updates","title":"RxInfer.@autoupdates","text":"@autoupdates [ options... ] begin \n    argument_to_update = some_function(q(some_variable_from_the_model))\nend\n\nCreates the auto-updates specification for the infer function for the online-streaming Bayesian inference procedure, where  it is important to update prior states based on the new updated posteriors. Read more information about the  @autoupdates syntax in the official documentation.\n\n\n\n\n\n","category":"macro"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"RxInfer supports streaming inference on infinite datastreams, wherein posterior beliefs over latent states update automatically as soon as new observations are available. However, we also aim to update our priors given updated beliefs. Let's begin with a simple example:","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"using RxInfer\nusing Test #hide\n\n@model function streaming_beta_bernoulli(a, b, y)\n    θ ~ Beta(a, b)\n    y ~ Bernoulli(θ)\nend","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"For this model, the RxInfer engine will update the posterior belief over the variable θ every time we receive a new observation y. However, we also wish to update our prior belief by adjusting the arguments a and b as soon as we have a new belief for the variable θ. The @autoupdates macro automates this process, simplifying the task of writing automatic updates for certain model arguments based on new beliefs within the model. Here's how it could look:","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"autoupdates = @autoupdates begin \n    a, b = params(q(θ))\nend","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"This specification directs the RxInfer inference engine to update a and b by invoking the params function on the posterior q of θ. The params function, defined in the Distributions.jl package, extracts the parameters (a and b in this case) in the form of a tuple of the resulting posterior (Beta) distribution.","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"# Change the text above if this test is failing\nusing RxInfer, Test, Distributions\nautoupdates = @autoupdates begin \n    a, b = params(q(θ))\nend\n@test RxInfer.getmappingfn(RxInfer.getmapping(RxInfer.getautoupdate(autoupdates, 1))) === Distributions.params\nnothing","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"Now, we can use the autoupdates structure in the infer function as following:","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"# The streaming inference supports static datasets as well\ndata = (y = [ 1, 0, 1 ], )\n\nresult = infer(\n    model          = streaming_beta_bernoulli(),\n    autoupdates    = autoupdates,\n    data           = data,\n    keephistory    = 3,\n    initialization = @initialization(q(θ) = Beta(1, 1))\n)\n@test result.history[:θ] == [ Beta(2.0, 1.0), Beta(2.0, 2.0), Beta(3.0, 2.0) ] #hide\n\nresult.history[:θ]","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"In this example, we also used the initialization keyword argument.  This is required for latent states, which are used in the @autoupdates specification together with streaming inference.","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"Consider another example with the following model and auto-update specification:","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"@model function kalman_filter(y, x_current_mean, x_current_var)\n    x_current ~ Normal(mean = x_current_mean, var = x_current_var)\n    x_next    ~ Normal(mean = x_current, var = 1.0)\n    y         ~ Normal(mean = x_next, var = 1.0)\nend","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"This model comprises two arguments representing our prior knowledge of the x_current state of the system.  The latent state x_next represents the subsequent state of the system, linked to the observed variable y.  An auto-update specification could resemble the following:","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"autoupdates = @autoupdates begin\n    x_current_mean = mean(q(x_next))\n    x_current_var  = var(q(x_next))\nend","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"This structure dictates updating our prior immediately upon obtaining a new posterior q(x_next).  It then applies the mean and var functions to the updated posteriors, thereby automatically updating x_current_mean and x_current_var.","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"result = infer(\n    model = kalman_filter(),\n    data  = (y = rand(3), ),\n    autoupdates = autoupdates,\n    initialization = @initialization(q(x_next) = NormalMeanVariance(0, 1)),\n    keephistory = 3,\n)\nresult.history[:x_next]","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"Read more about streaming inference in the Streaming (online) inference section.","category":"page"},{"location":"manuals/inference/autoupdates/#General-syntax","page":"Auto-updates","title":"General syntax","text":"","category":"section"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"The @autoupdates macro accepts either a block of code or a full function definition. It detects and transforms lines structured as follows:","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"(model_arguments...) = some_function(model_variables...)","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"These lines are referred to as individual autoupdate specifications. Other expressions remain unchanged.  The result of the macro execution is the RxInfer.AutoUpdateSpecification structure that holds the collection  of RxInfer.IndividualAutoUpdateSpecification.","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"The @autoupdates macro identifies an individual autoupdate specification if the model_variables... contains:","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"q(s), which monitors updates from marginal posteriors of an individual variable s or a collection of variables s.\nq(s[i]), which monitors updates from marginal posteriors of the collection of variables s at index i.","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"Expressions not meeting the above criteria remain unmodified. For instance, an expression like a = f(1) is not considered an individual autoupdate. Therefore, the @autoupdates macro can contain arbitrary expressions and allows for the definition of temporary variables or even functions. Additionally, within an individual autoupdate specification, it is possible to use any intermediate constants, such as a, b = some_function(q(s), a_constant).","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"The model_arguments... can either be a single model argument or a tuple of model arguments, as defined within the @model macro. However, it's important to note that if model_arguments... is a tuple, for example in a, b = some_function(q(s)), then some_function must also return a tuple of the same length (of length 2 in this example).","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"Individual autoupdate specifications can involve somewhat complex expressions, as demonstrated below:","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"@autoupdates begin \n    a = mean(q(θ)) / 2\n    b = 2 * (mean(q(θ)) + 1)\nend","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"or","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"@autoupdates begin \n    x = clamp(mean(q(z)), 0, 1)\nend","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"warning: Warning\nq(θ)[i] or f(q(θ))[i] syntax is not supported, use getindex(q(θ), i) or getindex(f(q(θ)), i) instead.","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"The @autoupdates macro does also support the broadcasting:","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"@autoupdates begin \n    x = clamp.(mean.(q(z)), 0, 1)\nend","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"Read more about broadcasting in the official Julia documentation.","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"An individual autoupdate can also simultaneously depend on multiple latent states, e.g:","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"f(args...) = nothing #hide\ng(args...) = nothing #hide\n@autoupdates begin \n    a = f(q(μ), q(s), q(τ))\n    b = g(q(θ))\nend","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"As mentioned before, the @autoupdates accepts a full function definition, which can also accepts arbitrary arguments:","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"@autoupdates function generate_autoupdates(f, condition)\n    if condition \n        a = f(q(θ))\n    else\n        a = f(q(s))\n    end\nend\n\nautoupdates = generate_autoupdates(mean, true)","category":"page"},{"location":"manuals/inference/autoupdates/#The-options-block","page":"Auto-updates","title":"The options block","text":"","category":"section"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"Optionally, the @autoupdates macro accepts a set of [ options... ] before the main block or the full function definition. The available options are:","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"warn = true/false: Enables or disables warnings when with incomaptible model. Set to true by default.\nstrict = true/false: Turns warnings into errors. Set to false by default.","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"autoupdates = @autoupdates [ strict = true ] begin \n    a, b = params(q(θ))\nend","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"or ","category":"page"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"@autoupdates [ strict = true ] function generate_autoupdates()\n    a, b = params(q(θ))\nend\nautoupdates = generate_autoupdates()","category":"page"},{"location":"manuals/inference/autoupdates/#Internal-data-structures","page":"Auto-updates","title":"Internal data structures","text":"","category":"section"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"RxInfer.AutoUpdateSpecification\nRxInfer.parse_autoupdates\nRxInfer.autoupdate_check_reserved_expressions\nRxInfer.numautoupdates\nBase.isempty(specification::RxInfer.AutoUpdateSpecification)\nRxInfer.getautoupdate\nRxInfer.addspecification\nRxInfer.getvarlabels\nRxInfer.IndividualAutoUpdateSpecification\nRxInfer.getmapping\nRxInfer.AutoUpdateVariableLabel\nRxInfer.AutoUpdateMapping\nRxInfer.AutoUpdateFetchMarginalArgument\nRxInfer.AutoUpdateFetchMessageArgument\nRxInfer.prepare_autoupdates_for_model","category":"page"},{"location":"manuals/inference/autoupdates/#RxInfer.AutoUpdateSpecification","page":"Auto-updates","title":"RxInfer.AutoUpdateSpecification","text":"AutoUpdateSpecification(specifications)\n\nA structure that holds a collection of individual auto-update specifications.  Each specification defines how to update the model's arguments  based on the new posterior/messages updates. \n\n\n\n\n\n","category":"type"},{"location":"manuals/inference/autoupdates/#RxInfer.parse_autoupdates","page":"Auto-updates","title":"RxInfer.parse_autoupdates","text":"parse_autoupdates(options, expression)\n\nParses the internals of the expression passed to the @autoupdates macro and returns the RxInfer.AutoUpdateSpecification structure.\n\n\n\n\n\n","category":"function"},{"location":"manuals/inference/autoupdates/#RxInfer.autoupdate_check_reserved_expressions","page":"Auto-updates","title":"RxInfer.autoupdate_check_reserved_expressions","text":"autoupdate_check_reserved_expressions(block)\n\nThis function checks if the expression is a valid autoupdate specification some expressions are forbidden within the autoupdate specification.\n\n\n\n\n\n","category":"function"},{"location":"manuals/inference/autoupdates/#RxInfer.numautoupdates","page":"Auto-updates","title":"RxInfer.numautoupdates","text":"Returns the number of auto-updates in the specification\n\n\n\n\n\n","category":"function"},{"location":"manuals/inference/autoupdates/#Base.isempty-Tuple{RxInfer.AutoUpdateSpecification}","page":"Auto-updates","title":"Base.isempty","text":"Returns true if the auto-update specification is empty\n\n\n\n\n\n","category":"method"},{"location":"manuals/inference/autoupdates/#RxInfer.getautoupdate","page":"Auto-updates","title":"RxInfer.getautoupdate","text":"Returns the individual auto-update specification at the given index\n\n\n\n\n\n","category":"function"},{"location":"manuals/inference/autoupdates/#RxInfer.addspecification","page":"Auto-updates","title":"RxInfer.addspecification","text":"Appends the individual auto-update specification to the existing specification\n\n\n\n\n\n","category":"function"},{"location":"manuals/inference/autoupdates/#RxInfer.getvarlabels","page":"Auto-updates","title":"RxInfer.getvarlabels","text":"Returns the labels of the auto-update specification, which are the names of the variables to update\n\n\n\n\n\nReturns the labels of the auto-update specification, which are the names of the variables to update\n\n\n\n\n\n","category":"function"},{"location":"manuals/inference/autoupdates/#RxInfer.IndividualAutoUpdateSpecification","page":"Auto-updates","title":"RxInfer.IndividualAutoUpdateSpecification","text":"IndividualAutoUpdateSpecification(varlabels, arguments, mapping)\n\nA structure that defines how to update a single variable in the model. It consists of the variable labels and the mapping function.\n\n\n\n\n\n","category":"type"},{"location":"manuals/inference/autoupdates/#RxInfer.getmapping","page":"Auto-updates","title":"RxInfer.getmapping","text":"Returns the mapping function of the auto-update specification, which defines how to update the variable\n\n\n\n\n\n","category":"function"},{"location":"manuals/inference/autoupdates/#RxInfer.AutoUpdateVariableLabel","page":"Auto-updates","title":"RxInfer.AutoUpdateVariableLabel","text":"AutoUpdateVariableLabel{L, I}(label, [ index = nothing ])\n\nA structure that holds the label of the variable to update and its index. By default, the index is set to nothing.\n\n\n\n\n\n","category":"type"},{"location":"manuals/inference/autoupdates/#RxInfer.AutoUpdateMapping","page":"Auto-updates","title":"RxInfer.AutoUpdateMapping","text":"AutoUpdateMapping(arguments, mappingFn)\n\nA structure that holds the arguments and the mapping function for the individual auto-update specification.\n\n\n\n\n\n","category":"type"},{"location":"manuals/inference/autoupdates/#RxInfer.AutoUpdateFetchMarginalArgument","page":"Auto-updates","title":"RxInfer.AutoUpdateFetchMarginalArgument","text":"This autoupdate would fetch updates from the marginal of a variable\n\n\n\n\n\n","category":"type"},{"location":"manuals/inference/autoupdates/#RxInfer.AutoUpdateFetchMessageArgument","page":"Auto-updates","title":"RxInfer.AutoUpdateFetchMessageArgument","text":"This autoupdate would fetch updates from the last message (in the array of messages) of a variable\n\n\n\n\n\n","category":"type"},{"location":"manuals/inference/autoupdates/#RxInfer.prepare_autoupdates_for_model","page":"Auto-updates","title":"RxInfer.prepare_autoupdates_for_model","text":"prepare_autoupdates_for_model(autoupdates, model)\n\nThis function extracts the variables saved in the autoupdates from the model. Replaces AutoUpdateFetchMarginalArgument and AutoUpdateFetchMessageArgument with actual streams.\n\n\n\n\n\n","category":"function"},{"location":"manuals/inference/autoupdates/","page":"Auto-updates","title":"Auto-updates","text":"","category":"page"},{"location":"manuals/inference/streamlined/#manual-online-inference","page":"Streamline inference","title":"Streaming (online) inference","text":"","category":"section"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"This guide explains how to use the infer function for dynamic datasets. We show how RxInfer can continuously update beliefs asynchronously whenever a new observation arrives. We use a simple Beta-Bernoulli model as an example, which has been covered in the Getting Started section,  however, these techniques can be applied to any model","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Also read about Static Inference or checkout more complex examples.","category":"page"},{"location":"manuals/inference/streamlined/#manual-online-inference-model-spec","page":"Streamline inference","title":"Model specification","text":"","category":"section"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Also read the Model Specification section.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"In online inference, we want to continuously update our prior beliefs about certain hidden states.  To achieve this, we include extra arguments in our model specification to allow for dynamic prior changes:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"using RxInfer\nusing Test #hide\n\n@model function beta_bernoulli_online(y, a, b)\n    θ ~ Beta(a, b)  \n    y ~ Bernoulli(θ)\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"In this model, we assume we only have one observation y at a time, and the a and b parameters are not fixed to specific values but rather are arguments of the model itself.","category":"page"},{"location":"manuals/inference/streamlined/#manual-online-inference-autoupdates","page":"Streamline inference","title":"Automatic prior update","text":"","category":"section"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Next, we want to enable RxInfer to automatically update the a and b parameters as soon as a new posterior for θ is available. To accomplish this, we utilize the @autoupdates macro.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"beta_bernoulli_autoupdates = @autoupdates begin \n    # We want to update `a` and `b` to be equal to the parameters \n    # of the current posterior for `θ`\n    a, b = params(q(θ))\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"This specification instructs RxInfer to update a and b parameters automatically as as soon as a new posterior for θ is available. Read more about @autoupdates in the Autoupdates guide","category":"page"},{"location":"manuals/inference/streamlined/#manual-online-inference-async-datastream","page":"Streamline inference","title":"Asynchronous data stream of observations","text":"","category":"section"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"For demonstration purposes, we use a handcrafted stream of observations with the Rocket.jl library","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"using Rocket, Distributions, StableRNGs\n\nhidden_θ     = 1 / 3.1415\ndistribution = Bernoulli(hidden_θ)\nrng          = StableRNG(43)\ndatastream   = RecentSubject(Bool)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"The infer function expects the datastream to emit values in the form of the NamedTuples. To simplify this process, Rocket.jl exports labeled function. We also use the combineLatest function to convert a stream of Bools to a stream of Tuple{Bool}s. Read more about these function in the documentation to Rocket.jl.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"observations = labeled(Val((:y, )), combineLatest(datastream))","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Let's verify that our datastream does indeed produce NamedTuples","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"test_values = [] #hide\ntest_subscription = subscribe!(observations, (new_observation) -> push!(test_values, new_observation)) #hide\nsubscription = subscribe!(observations, \n    (new_observation) -> println(\"Got new observation \", new_observation, \" 🎉\")\n)\nnothing #hide","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"for i in 1:5\n    next!(datastream, rand(rng, distribution))\nend\n@test length(test_values) === 5 #hide\n@test all(value -> haskey(value, :y) && (isone(value[:y]) || iszero(value[:y])), test_values) #hide \nnothing #hide","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Nice! Our data stream produces events in a form of the NamedTuples, which is compatible with the infer function.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"unsubscribe!(test_subscription) #hide\n# It is important to keep track of the existing susbcriptions\n# and unsubscribe to reduce the usage of computational resources\nunsubscribe!(subscription)","category":"page"},{"location":"manuals/inference/streamlined/#manual-online-inference-inst-reactive-engine","page":"Streamline inference","title":"Instantiating the reactive inference engine","text":"","category":"section"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Now, we have everything ready to start running the inference with RxInfer on dynamic datasets with the infer function:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"engine = infer(\n    model          = beta_bernoulli_online(),\n    datastream     = observations,\n    autoupdates    = beta_bernoulli_autoupdates,\n    returnvars     = (:θ, ),\n    initialization = @initialization(q(θ) = Beta(1, 1)),\n    autostart      = false\n)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"In the code above, there are several notable differences compared to running inference for static datasets. Firstly, we utilized the autoupdates argument as discussed previously. Secondly, we employed the @initialization macro to initialize the posterior over θ. This is necessary for the @autoupdates macro, as it needs to initialize the a and b parameters before the data becomes available. Thirdly, we set autostart = false to indicate that we do not want to immediately subscribe to the datastream, but rather do so manually later using the RxInfer.start function. The returnvars specification differs a little from Static Inference. In reactive inference, the returnvars = (:θ, ) must be a tuple of Symbols and specifies that we would be interested to get a stream of posteriors update for θ. The returnvars specification is optional and the inference engine will create reactive streams for all latent states if ommited.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"RxInferenceEngine\nRxInfer.start\nRxInfer.stop","category":"page"},{"location":"manuals/inference/streamlined/#RxInfer.RxInferenceEngine","page":"Streamline inference","title":"RxInfer.RxInferenceEngine","text":"RxInferenceEngine\n\nThe return value of the infer function in case of streamlined inference. \n\nPublic fields\n\nposteriors: Dict or NamedTuple of 'random variable' - 'posterior stream' pairs. See the returnvars argument for the infer.\nfree_energy: (optional) A stream of Bethe Free Energy values per VMP iteration. See the free_energy argument for the infer.\nhistory: (optional) Saves history of previous marginal updates. See the historyvars and keephistory arguments for the infer.\nfree_energy_history: (optional) Free energy history, averaged across variational iterations value for all observations  \nfree_energy_raw_history: (optional) Free energy history, returns returns computed values of all variational iterations for each data event (if available)\nfree_energy_final_only_history: (optional) Free energy history, returns computed values of final variational iteration for each data event (if available)\nevents: (optional) A stream of events send by the inference engine. See the events argument for the infer.\nmodel: ProbabilisticModel object reference.\n\nUse the RxInfer.start(engine) function to subscribe on the datastream source and start the inference procedure.  Use RxInfer.stop(engine) to unsubscribe from the datastream source and stop the inference procedure.  Note, that it is not always possible to start/stop the inference procedure.\n\nSee also: infer, RxInferenceEvent, RxInfer.start, RxInfer.stop\n\n\n\n\n\n","category":"type"},{"location":"manuals/inference/streamlined/#RxInfer.start","page":"Streamline inference","title":"RxInfer.start","text":"start(engine::RxInferenceEngine)\n\nStarts the RxInferenceEngine by subscribing to the data source, instantiating free energy (if enabled) and starting the event loop. Use RxInfer.stop to stop the RxInferenceEngine. Note that it is not always possible to stop/restart the engine and this depends on the data source type.\n\nSee also: RxInfer.stop\n\n\n\n\n\n","category":"function"},{"location":"manuals/inference/streamlined/#RxInfer.stop","page":"Streamline inference","title":"RxInfer.stop","text":"stop(engine::RxInferenceEngine)\n\nStops the RxInferenceEngine by unsubscribing to the data source, free energy (if enabled) and stopping the event loop. Use RxInfer.start to start the RxInferenceEngine again. Note that it is not always possible to stop/restart the engine and this depends on the data source type.\n\nSee also: RxInfer.start\n\n\n\n\n\n","category":"function"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Given the engine, we now can subscribe on the posterior updates:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"θ_updates_for_testing_the_example  = [] #hide\nθ_updates_for_testing_subscription = subscribe!(engine.posteriors[:θ], (new_posterior_for_θ) -> push!(θ_updates_for_testing_the_example, new_posterior_for_θ)) #hide\nθ_updates_subscription = subscribe!(engine.posteriors[:θ], \n    (new_posterior_for_θ) -> println(\"A new posterior for θ is \", new_posterior_for_θ, \" 🤩\")\n)\nnothing #hide","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"In this setting, we should get a message every time a new posterior is available for θ. Let's try to generate a new observation!","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"next!(datastream, rand(rng, distribution))\n@test isempty(θ_updates_for_testing_the_example) #hide\nnothing #hide","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Hmm, nothing happened...? Oh, we forgot to start the engine with the RxInfer.start function. Let's do that now:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"RxInfer.start(engine)\n@test length(θ_updates_for_testing_the_example) === 1 #hide\nnothing #hide","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Ah, as soon as we start our engine, we receive the posterior for θ. This occurred because we initialized our stream as RecentSubject, which retains the most recent value and emits it upon subscription. Our engine automatically subscribed to the observations and obtained the most recent value, initiating inference. Let's see if we can add more observations:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"next!(datastream, rand(rng, distribution))\n@test length(θ_updates_for_testing_the_example) === 2 #hide\nnothing #hide","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Great! We got another posterior! Let's try a few more observations:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"for i in 1:5\n    next!(datastream, rand(rng, distribution))\nend\n@test length(θ_updates_for_testing_the_example) === 7 #hide\nnothing #hide","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"As demonstrated, the reactive engine reacts to new observations and performs inference as soon as a new observation is available. But what if we want to maintain a history of posteriors? The infer function supports the historyvars and keephistory arguments precisely for that purpose. In the next section we reinstantiate our engine, with the keephistory argument enabled, but first, we must shutdown the previous engine and unsubscribe from its posteriors:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"RxInfer.stop(engine)\nunsubscribe!(θ_updates_subscription)\nunsubscribe!(θ_updates_for_testing_subscription) #hide\nnothing #hide","category":"page"},{"location":"manuals/inference/streamlined/#manual-online-inference-history","page":"Streamline inference","title":"Keeping the history of posteriors","text":"","category":"section"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"To retain the history of posteriors within the engine, we can utilize the keephistory and historyvars arguments. The keephistory parameter specifies the length of the circular buffer for storing the history of posterior updates, while historyvars determines what variables to save in the history and how often to save them (e.g., every iteration or only at the end of iterations).","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"engine = infer(\n    model          = beta_bernoulli_online(),\n    datastream     = observations,\n    autoupdates    = beta_bernoulli_autoupdates,\n    initialization = @initialization(q(θ) = Beta(1, 1)),\n    keephistory    = 100,\n    historyvars    = (θ = KeepLast(), ),\n    autostart      = true\n)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"In the example above, we specified that we want to store at most 100 posteriors for θ, and KeepLast() indicates that we are only interested in the final value of θ and not in intermediate values during variational iterations. We also specified the autostart = true to start the engine automatically without need for RxInfer.start and RxInfer.stop.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"note: Note\nIn this model, we do not utilize the iterations argument, indicating that we perform a single VMP iteration. If multiple iterations were employed, engine.posteriors[:θ] would emit every intermediate value.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Now, we can feed some more observations to the datastream:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"for i in 1:5\n    next!(datastream, rand(rng, distribution))\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"And inspect the engine.history[:θ] buffer:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"@test length(engine.history[:θ]) === 6 #hide\nengine.history[:θ]","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"As we can see the buffer correctly saved the posteriors in the .history buffer.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"note: Note\nWe have 6 entries, despite having only 5 new observations. As mentioned earlier, this occurs because we initialized our datastream as a RecentSubject, which retains the most recent observation and emits it each time a new subscription occurs.","category":"page"},{"location":"manuals/inference/streamlined/#manual-online-inference-history-visualization","page":"Streamline inference","title":"Visualizing the history of posterior estimation","text":"","category":"section"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Let's feed more observation and visualize how the posterior changes over time:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"for i in 1:94\n    next!(datastream, rand(rng, distribution))\nend\n@test length(engine.history[:θ]) === 100 #hide\nnothing #hide","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"To visualize the history of posteriors we use the @gif macro from the Plots package:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"using Plots\n\n@gif for posterior in engine.history[:θ]\n    rθ = range(0, 1, length = 1000)\n    pθ = plot(rθ, (x) -> pdf(posterior, x), fillalpha=0.3, fillrange = 0, label=\"P(θ|y)\", c=3)\n    pθ = vline!(pθ, [ hidden_θ ], label = \"Real value of θ\")\n\n    plot(pθ)\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"We can keep feeding data to our datastream, but only last 100 posteriors will be saved in the history buffer:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"for i in 1:200\n    next!(datastream, rand(rng, distribution))\nend\n\n@test length(engine.history[:θ]) === 100 #hide\n@gif for posterior in engine.history[:θ]\n    rθ = range(0, 1, length = 1000)\n    pθ = plot(rθ, (x) -> pdf(posterior, x), fillalpha=0.3, fillrange = 0, label=\"P(θ|y)\", c=3)\n    pθ = vline!(pθ, [ hidden_θ ], label = \"Real value of θ\")\n\n    plot(pθ)\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"note: Note\nIt is also possible to visualize the inference estimation continously with manual subscription to engine.posteriors[:θ].","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"As previously it is important to shutdown the inference engine when it becomes unnecessary:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"RxInfer.stop(engine)","category":"page"},{"location":"manuals/inference/streamlined/#manual-online-inference-free-energy","page":"Streamline inference","title":"Subscribing on the stream of free energy","text":"","category":"section"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"To obtain a continuous stream of updates for the Bethe Free Energy, we need to initialize the engine with the free_energy argument set to true:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"engine = infer(\n    model          = beta_bernoulli_online(),\n    datastream     = observations,\n    autoupdates    = beta_bernoulli_autoupdates,\n    initialization = @initialization(q(θ) = Beta(1, 1)),\n    keephistory    = 5,\n    autostart      = true,\n    free_energy    = true\n)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"note: Note\nIt's important to use the keephistory argument alongside the free_energy argument because setting free_energy = true also maintains an internal circular buffer to track its previous updates.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"free_energy_for_testing = [] #hide\nfree_energy_for_testing_subscription = subscribe!(engine.free_energy, (v) -> push!(free_energy_for_testing, v)) #hide\nfree_energy_subscription = subscribe!(engine.free_energy, \n    (bfe_value) -> println(\"New value of Bethe Free Energy has been computed \", bfe_value, \" 👩‍🔬\")\n)\n@test length(free_energy_for_testing) === 1 #hide\nnothing #hide","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Let's emit more observations:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"for i in 1:5\n    next!(datastream, rand(rng, distribution))\nend\n@test length(free_energy_for_testing) === 6 #hide\nnothing #hide","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"In this particular example, we do not perform any variational iterations and do not use any variational constraints, hence, the inference is exact. In this case the BFE values are equal to the minus log-evidence of the model given new observation.  We can also track history of Bethe Free Energy values with the following fields of the engine:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"free_energy_history: free energy history, averaged across variational iterations value for all observations  \nfree_energy_raw_history: free energy history, returns returns computed values of all variational iterations for each data event (if available)\nfree_energy_final_only_history: free energy history, returns computed values of final variational iteration for each data event (if available)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"@test length(engine.free_energy_history) === 1 #hide\nengine.free_energy_history","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"@test length(engine.free_energy_raw_history) === 5 #hide\nengine.free_energy_raw_history","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"@test length(engine.free_energy_final_only_history) === 5 #hide\nengine.free_energy_final_only_history","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"unsubscribe!(free_energy_for_testing_subscription) #hide\n# Stop the engine when not needed as usual\nRxInfer.stop(engine)\nunsubscribe!(free_energy_subscription)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"As has been mentioned, in this particular example we do not perform variational iterations, hence, there is little different between different representations of the BFE history buffers. However, when performing variational inference with the iterations argument, those buffers will be different. To demonstrate this difference let's build a slightly more complex model with variational constraints:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"@model function iid_normal(y, mean_μ, var_μ, shape_τ, rate_τ)\n    μ ~ Normal(mean = mean_μ, var = var_μ)\n    τ ~ Gamma(shape = shape_τ, rate = rate_τ)\n    y ~ Normal(mean = μ, precision = τ)\nend\n\niid_normal_constraints = @constraints begin\n    q(μ, τ) = q(μ)q(τ)\nend\n\niid_normal_autoupdates = @autoupdates begin \n    mean_μ  = mean(q(μ))\n    var_μ   = var(q(μ))\n    shape_τ = shape(q(τ))\n    rate_τ  = rate(q(τ))\nend\n\niid_normal_hidden_μ       = 3.1415\niid_normal_hidden_τ       = 0.0271\niid_normal_distribution   = NormalMeanPrecision(iid_normal_hidden_μ, iid_normal_hidden_τ)\niid_normal_rng            = StableRNG(123)\niid_normal_datastream     = RecentSubject(Float64)\niid_normal_observations   = labeled(Val((:y, )), combineLatest(iid_normal_datastream))\niid_normal_initialization = @initialization begin \n    q(μ) = NormalMeanPrecision(0.0, 0.001)\n    q(τ) = GammaShapeRate(10.0, 10.0)\nend\n\niid_normal_engine  = infer(\n    model          = iid_normal(),\n    datastream     = iid_normal_observations,\n    autoupdates    = iid_normal_autoupdates,\n    constraints    = iid_normal_constraints,\n    initialization = iid_normal_initialization,\n    historyvars    = (\n        μ = KeepLast(),\n        τ = KeepLast(),\n    ),\n    keephistory    = 100,\n    iterations     = 10,\n    free_energy    = true,\n    autostart      = true\n)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"The notable differences with the previous example is the use of the constraints and iterations arguments. Read more about constraints in the Constraints Specification section of the documentation. We have also indicated in the historyvars that we want to keep track of posteriors only from the last variational iteration in the history buffer.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Now we can feed some observations to the datastream:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"for i in 1:100\n    next!(iid_normal_datastream, rand(iid_normal_rng, iid_normal_distribution))\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Let's inspect the differences in the free_energy buffers:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"@test all(v -> v <= 0.0, diff(iid_normal_engine.free_energy_history)) #hide\n@test length(iid_normal_engine.free_energy_history) === 10 #hide\niid_normal_engine.free_energy_history","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"@test length(iid_normal_engine.free_energy_raw_history) === 1000 #hide\niid_normal_engine.free_energy_raw_history","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"@test length(iid_normal_engine.free_energy_final_only_history) === 100 #hide\niid_normal_engine.free_energy_final_only_history","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"We can also visualize different representations:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"plot(iid_normal_engine.free_energy_history, label = \"Bethe Free Energy (averaged)\")","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"note: Note\nIn general, the averaged Bethe Free Energy values must decrease and converge to a stable point.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"plot(iid_normal_engine.free_energy_raw_history, label = \"Bethe Free Energy (raw)\")","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"plot(iid_normal_engine.free_energy_final_only_history, label = \"Bethe Free Energy (last per observation)\")","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"As we can see, in the case of the variational iterations those buffers are quite different and represent different representations of the same Bethe Free Energy stream (which corresponds to the .free_energy_raw_history). As a sanity check, we could also visualize the history of our posterior estimations in the same way  as we did for a simpler previous example:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"@test length(iid_normal_engine.history[:μ]) === 100 #hide\n@test length(iid_normal_engine.history[:τ]) === 100 #hide\n@gif for (μ_posterior, τ_posterior) in zip(iid_normal_engine.history[:μ], iid_normal_engine.history[:τ])\n    rμ = range(0, 10, length = 1000)\n    rτ = range(0, 1, length = 1000)\n\n    pμ = plot(rμ, (x) -> pdf(μ_posterior, x), fillalpha=0.3, fillrange = 0, label=\"P(μ|y)\", c=3)\n    pμ = vline!(pμ, [ iid_normal_hidden_μ ], label = \"Real value of μ\")\n\n    pτ = plot(rτ, (x) -> pdf(τ_posterior, x), fillalpha=0.3, fillrange = 0, label=\"P(τ|y)\", c=3)\n    pτ = vline!(pτ, [ iid_normal_hidden_τ ], label = \"Real value of τ\")\n\n    plot(pμ, pτ, layout = @layout([ a; b ]))\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Nice, the history of the estimated posteriors aligns well with the real (hidden) values of the underlying parameters.","category":"page"},{"location":"manuals/inference/streamlined/#manual-online-inference-callbacks","page":"Streamline inference","title":"Callbacks","text":"","category":"section"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"The RxInferenceEngine has its own lifecycle. The callbacks differ a little bit from Using callbacks with Static Inference.  Here are available callbacks that can be used together with the streaming inference:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"using RxInfer, Test, Markdown\n# Update the documentation below if this test does not pass\n@test RxInfer.available_callbacks(RxInfer.streaming_inference) === Val((:before_model_creation, :after_model_creation, :before_autostart, :after_autostart))\nnothing","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"before_model_creation()","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Calls before the model is going to be created, does not accept any arguments.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"after_model_creation(model::ProbabilisticModel)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Calls right after the model has been created, accepts a single argument, the model.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"before_autostart(engine::RxInferenceEngine)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Calls before the RxInfer.start() function, if autostart is set to true.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"after_autostart(engine::RxInferenceEngine)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Calls after the RxInfer.start() function, if autostart is set to true.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Here is an example usage of the outlined callbacks:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"before_model_creation_called = Ref(false) #hide\nafter_model_creation_called = Ref(false) #hide\nbefore_autostart_called = Ref(false) #hide\nafter_autostart_called = Ref(false) #hide\n\nfunction before_model_creation()\n    before_model_creation_called[] = true #hide\n    println(\"The model is about to be created\")\nend\n\nfunction after_model_creation(model::ProbabilisticModel)\n    after_model_creation_called[] = true #hide\n    println(\"The model has been created\")\n    println(\"  The number of factor nodes is: \", length(RxInfer.getfactornodes(model)))\n    println(\"  The number of latent states is: \", length(RxInfer.getrandomvars(model)))\n    println(\"  The number of data points is: \", length(RxInfer.getdatavars(model)))\n    println(\"  The number of constants is: \", length(RxInfer.getconstantvars(model)))\nend\n\nfunction before_autostart(engine::RxInferenceEngine)\n    before_autostart_called[] = true #hide\n    println(\"The reactive inference engine is about to start\")\nend\n\nfunction after_autostart(engine::RxInferenceEngine)\n    after_autostart_called[] = true #hide\n    println(\"The reactive inference engine has been started\")\nend\n\nengine = infer(\n    model          = beta_bernoulli_online(),\n    datastream     = observations,\n    autoupdates    = beta_bernoulli_autoupdates,\n    initialization = @initialization(q(θ) = Beta(1, 1)),\n    keephistory    = 5,\n    autostart      = true,\n    free_energy    = true,\n    callbacks      = (\n        before_model_creation = before_model_creation,\n        after_model_creation  = after_model_creation,\n        before_autostart      = before_autostart,\n        after_autostart       = after_autostart\n    )\n)\n\n@test before_model_creation_called[] #hide\n@test after_model_creation_called[] #hide\n@test before_autostart_called[] #hide\n@test after_autostart_called[] #hide\n\nRxInfer.stop(engine) #hide\nnothing #hide","category":"page"},{"location":"manuals/inference/streamlined/#manual-online-inference-event-loop","page":"Streamline inference","title":"Event loop","text":"","category":"section"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"In constrast to Static Inference, the streaming version of the infer function  does not provide callbacks such as on_marginal_update, since it is possible to subscribe directly on those updates with the  engine.posteriors field. However, the reactive inference engine provides an ability to listen to its internal event loop, that also includes \"pre\" and \"post\" events for posterior updates.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"RxInferenceEvent","category":"page"},{"location":"manuals/inference/streamlined/#RxInfer.RxInferenceEvent","page":"Streamline inference","title":"RxInfer.RxInferenceEvent","text":"RxInferenceEvent{T, D}\n\nThe RxInferenceEngine sends events in a form of the RxInferenceEvent structure. T represents the type of an event, D represents the type of a data associated with the event. The type of data depends on the type of an event, but usually represents a tuple, which can be unrolled automatically with the Julia's splitting syntax, e.g. model, iteration = event.  See the documentation of the rxinference function for possible event types and their associated data types.\n\nThe events system itself uses the Rocket.jl library API. For example, one may create a custom event listener in the following way:\n\nusing Rocket\n\nstruct MyEventListener <: Rocket.Actor{RxInferenceEvent}\n    # ... extra fields\nend\n\nfunction Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :after_iteration })\n    model, iteration = event\n    println(\"Iteration $(iteration) has been finished.\")\nend\n\nfunction Rocket.on_error!(listener::MyEventListener, err)\n    # ...\nend\n\nfunction Rocket.on_complete!(listener::MyEventListener)\n    # ...\nend\n\n\nand later on:\n\nengine = infer(events = Val((:after_iteration, )), ...)\n\nsubscription = subscribe!(engine.events, MyEventListener(...))\n\nSee also: infer, RxInferenceEngine\n\n\n\n\n\n","category":"type"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Let's build a simple example by implementing our own event listener that does not do anything complex but simply prints some debugging information.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"using RxInfer, Test, Markdown\n# Update the documentation below if this test does not pass\n@test RxInfer.available_events(RxInfer.streaming_inference) === Val((\n    :before_start,\n    :after_start,\n    :before_stop,\n    :after_stop,\n    :on_new_data,\n    :before_iteration,\n    :before_auto_update,\n    :after_auto_update,\n    :before_data_update,\n    :after_data_update,\n    :after_iteration,\n    :before_history_save,\n    :after_history_save,\n    :on_tick,\n    :on_error,\n    :on_complete\n))\nnothing","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"struct MyEventListener <: Rocket.Actor{RxInferenceEvent}\n    # ... extra fields\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"The available events are","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":":before_start","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Emits right before starting the engine with the RxInfer.start function. The data is (engine::RxInferenceEngine, )","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :before_start })\n    (engine, ) = event\n    @test engine isa RxInferenceEngine #hide\n    println(\"The engine is about to start.\")\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":":after_start","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Emits right after starting the engine with the RxInfer.start function. The data is (engine::RxInferenceEngine, )","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :after_start })\n    (engine, ) = event\n    @test engine isa RxInferenceEngine #hide\n    println(\"The engine has been started.\")\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":":before_stop","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Emits right before stopping the engine with the RxInfer.stop function. The data is (engine::RxInferenceEngine, )","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :before_stop })\n    (engine, ) = event\n    @test engine isa RxInferenceEngine #hide\n    println(\"The engine is about to be stopped.\")\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":":after_stop","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Emits right after stopping the engine with the RxInfer.stop function. The data is (engine::RxInferenceEngine, )","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :after_stop })\n    (engine, ) = event\n    @test engine isa RxInferenceEngine #hide\n    println(\"The engine has been stopped.\")\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":":on_new_data","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Emits right before processing new data point. The data is (model::ProbabilisticModel, data)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :on_new_data })\n    (model, data) = event\n    @test model isa ProbabilisticModel #hide\n    @test data isa NamedTuple #hide\n    @test haskey(data, :y) #hide\n    @test iszero(data[:y]) || isone(data[:y]) #hide\n    println(\"The new data point has been received: \", data)\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":":before_iteration","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Emits right before starting new variational iteration. The data is (model::ProbabilisticModel, iteration::Int)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :before_iteration })\n    (model, iteration) = event\n    @test model isa ProbabilisticModel #hide\n    @test iteration isa Int #hide\n    println(\"Starting new variational iteration #\", iteration)\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":":before_auto_update","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Emits right before executing the @autoupdates. The data is (model::ProbabilisticModel, iteration::Int, autoupdates)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :before_auto_update })\n    (model, iteration, autoupdates) = event\n    @test model isa ProbabilisticModel #hide\n    @test iteration isa Int #hide\n    @test RxInfer.numautoupdates(autoupdates) === 1 #hide\n    println(\"Before processing autoupdates\")\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":":after_auto_update","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Emits right after executing the @autoupdates. The data is (model::ProbabilisticModel, iteration::Int, autoupdates)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :after_auto_update })\n    (model, iteration, autoupdates) = event\n    @test model isa ProbabilisticModel #hide\n    @test iteration isa Int #hide\n    @test RxInfer.numautoupdates(autoupdates) === 1 #hide\n    println(\"After processing autoupdates\")\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":":before_data_update","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Emits right before feeding the model with the new data. The data is (model::ProbabilisticModel, iteration::Int, data)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :before_data_update })\n    (model, iteration, data) = event\n    @test model isa ProbabilisticModel #hide\n    @test iteration isa Int #hide\n    println(\"Before processing new data \", data)\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":":after_data_update","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Emits right after feeding the model with the new data. The data is (model::ProbabilisticModel, iteration::Int, data)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :after_data_update })\n    (model, iteration, data) = event\n    @test model isa ProbabilisticModel #hide\n    @test iteration isa Int #hide\n    println(\"After processing new data \", data)\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":":after_iteration","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Emits right after finishing a variational iteration. The data is (model::ProbabilisticModel, iteration::Int)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :after_iteration })\n    (model, iteration) = event\n    @test model isa ProbabilisticModel #hide\n    @test iteration isa Int #hide\n    println(\"Finishing the variational iteration #\", iteration)\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":":before_history_save","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Emits right before saving the history (if requested). The data is (model::ProbabilisticModel, )","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :before_history_save })\n    (model, ) = event\n    @test model isa ProbabilisticModel #hide\n    println(\"Before saving the history\")\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":":after_history_save","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Emits right after saving the history (if requested). The data is (model::ProbabilisticModel, )","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :after_history_save })\n    (model, ) = event\n    @test model isa ProbabilisticModel #hide\n    println(\"After saving the history\")\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":":on_tick","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Emits right after finishing processing the new observations and completing the inference step. The data is (model::ProbabilisticModel, )","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :on_tick })\n    (model, ) = event\n    @test model isa ProbabilisticModel #hide\n    println(\"Finishing the inference for the new observations\")\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":":on_error","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Emits if an error occurs in the inference engine. The data is (model::ProbabilisticModel, err::Any)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :on_error })\n    (model, err) = event\n    @test model isa ProbabilisticModel #hide\n    println(\"An error occured during the inference procedure: \", err)\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":":on_complete","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Emits when the datastream completes. The data is (model::ProbabilisticModel, )","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :on_complete })\n    (model, ) = event\n    @test model isa ProbabilisticModel #hide\n    println(\"The data stream completed. The inference has been finished.\")\nend","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Let's use our event listener with the infer function:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"engine = infer(\n    model          = beta_bernoulli_online(),\n    datastream     = observations,\n    autoupdates    = beta_bernoulli_autoupdates,\n    initialization = @initialization(q(θ) = Beta(1, 1)),\n    keephistory    = 5,\n    iterations     = 2,\n    autostart      = false,\n    free_energy    = true,\n    events         = Val((\n        :before_start,\n        :after_start,\n        :before_stop,\n        :after_stop,\n        :on_new_data,\n        :before_iteration,\n        :before_auto_update,\n        :after_auto_update,\n        :before_data_update,\n        :after_data_update,\n        :after_iteration,\n        :before_history_save,\n        :after_history_save,\n        :on_tick,\n        :on_error,\n        :on_complete\n    ))\n)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"After we have created the engine, we can subscribe on events and RxInfer.start the engine:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"events_subscription = subscribe!(engine.events, MyEventListener())\n\nRxInfer.start(engine)\nnothing #hide","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"The event loop stays idle without new observation and runs again when a new observation becomes available:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"next!(datastream, rand(rng, distribution))","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Let's complete the datastream ","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"complete!(datastream)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"In this case, it is not necessary to RxInfer.stop the engine, because  it will be stopped automatically.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"@test_logs (:warn, r\"The engine has been completed.*\") RxInfer.stop(engine) #hide\nRxInfer.stop(engine)\nnothing #hide","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"note: Note\nThe :before_stop and :after_stop events are not emmited in case of the datastream completion. Use the :on_complete instead.","category":"page"},{"location":"manuals/inference/streamlined/#manual-online-inference-data","page":"Streamline inference","title":"Using data keyword argument with streaming inference","text":"","category":"section"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"The streaming version does support static datasets as well.  Internally, it converts it to a datastream, that emits all observations in a sequntial order without any delay. As an example:","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"staticdata = rand(rng, distribution, 1_000)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"Use the data keyword argument instead of the datastream to pass the static data.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"engine = infer(\n    model          = beta_bernoulli_online(),\n    data           = (y = staticdata, ),\n    autoupdates    = beta_bernoulli_autoupdates,\n    initialization = @initialization(q(θ) = Beta(1, 1)),\n    keephistory    = 1000,\n    autostart      = true,\n    free_energy    = true,\n)","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"engine.history[:θ]","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"@gif for posterior in engine.history[:θ]\n    rθ = range(0, 1, length = 1000)\n    pθ = plot(rθ, (x) -> pdf(posterior, x), fillalpha=0.3, fillrange = 0, label=\"P(θ|y)\", c=3)\n    pθ = vline!(pθ, [ hidden_θ ], label = \"Real value of θ\")\n\n    plot(pθ)\nend","category":"page"},{"location":"manuals/inference/streamlined/#manual-online-inference-where-to-go","page":"Streamline inference","title":"Where to go next?","text":"","category":"section"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"This guide covered some fundamental usages of the infer function in the context of streamline inference,  but did not cover all the available keyword arguments of the function. Read more explanation about the other keyword arguments  in the Overview section or check out the Static Inference section. Also check out more complex examples.","category":"page"},{"location":"manuals/inference/streamlined/","page":"Streamline inference","title":"Streamline inference","text":"","category":"page"},{"location":"library/model-construction/#lib-model-construction","page":"Model construction","title":"Model construction in RxInfer","text":"","category":"section"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"Model creation in RxInfer largely depends on GraphPPL package. RxInfer re-exports the @model macro from GraphPPL and defines extra plugins and data structures on top of the default functionality.","category":"page"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"note: Note\nThe model creation and construction were largely refactored in GraphPPL v4.  Read Migration Guide for more details.","category":"page"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"Also read the Model Specification guide.","category":"page"},{"location":"library/model-construction/#lib-model-construction-model-macro","page":"Model construction","title":"@model macro","text":"","category":"section"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"RxInfer operates with so-called graphical probabilistic models, more specifically factor graphs. Working with graphs directly is, however, tedious and error-prone, especially for large models. To simplify the process, RxInfer exports the @model macro, which translates a textual description of a probabilistic model into a corresponding factor graph representation.","category":"page"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"RxInfer.@model","category":"page"},{"location":"library/model-construction/#RxInfer.@model","page":"Model construction","title":"RxInfer.@model","text":"@model function model_name(model_arguments...)\n    # model description\nend\n\n@model macro generates a function that returns an equivalent graph-representation of the given probabilistic model description. See the documentation to GraphPPL.@model for more information.\n\nSupported aliases in the model specification specifically for RxInfer.jl and ReactiveMP.jl\n\na || b: alias for ReactiveMP.OR(a, b) node (operator precedence between ||, &&, -> and ! is the same as in Julia).\na && b: alias for ReactiveMP.AND(a, b) node (operator precedence ||, &&, -> and ! is the same as in Julia).\na -> b: alias for ReactiveMP.IMPLY(a, b) node (operator precedence ||, &&, -> and ! is the same as in Julia).\n¬a and !a: alias for ReactiveMP.NOT(a) node (Unicode \\neg, operator precedence ||, &&, -> and ! is the same as in Julia).\n\n\n\n\n\n","category":"macro"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"Note, that GraphPPL also implements @model macro, but does not export it by default. This was a deliberate choice to allow inference backends (such as RxInfer) to implement custom functionality on top of the default GraphPPL.@model macro. This is done with a custom  backend for GraphPPL.@model macro. Read more about backends in the corresponding section of GraphPPL documentation.","category":"page"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"RxInfer.ReactiveMPGraphPPLBackend","category":"page"},{"location":"library/model-construction/#RxInfer.ReactiveMPGraphPPLBackend","page":"Model construction","title":"RxInfer.ReactiveMPGraphPPLBackend","text":"A backend for GraphPPL that uses ReactiveMP for inference.\n\n\n\n\n\n","category":"type"},{"location":"library/model-construction/#lib-model-construction-conditioning","page":"Model construction","title":"Conditioning on data","text":"","category":"section"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"After model creation RxInfer uses RxInfer.condition_on function to condition on data.  As an alias it is also possible to use the | operator for the same purpose, but with a nicer syntax.","category":"page"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"RxInfer.condition_on\nBase.:(|)(generator::RxInfer.ModelGenerator, data)\nRxInfer.ConditionedModelGenerator","category":"page"},{"location":"library/model-construction/#RxInfer.condition_on","page":"Model construction","title":"RxInfer.condition_on","text":"condition_on(generator::ModelGenerator; kwargs...)\n\nA function that creates a ConditionedModelGenerator object from GraphPPL.ModelGenerator. The | operator can be used as a shorthand for this function.\n\njulia> using RxInfer\n\njulia> @model function beta_bernoulli(y, a, b)\n           θ ~ Beta(a, b)\n           y .~ Bernoulli(θ)\n       end\n\njulia> conditioned_model = beta_bernoulli(a = 1.0, b = 2.0) | (y = [ 1.0, 0.0, 1.0 ], )\nbeta_bernoulli(a = 1.0, b = 2.0) conditioned on: \n  y = [1.0, 0.0, 1.0]\n\njulia> RxInfer.create_model(conditioned_model) isa RxInfer.ProbabilisticModel\ntrue\n\n\n\n\n\n","category":"function"},{"location":"library/model-construction/#Base.:|-Tuple{GraphPPL.ModelGenerator, Any}","page":"Model construction","title":"Base.:|","text":"An alias for RxInfer.condition_on.\n\n\n\n\n\n","category":"method"},{"location":"library/model-construction/#RxInfer.ConditionedModelGenerator","page":"Model construction","title":"RxInfer.ConditionedModelGenerator","text":"ConditionedModelGenerator(generator, conditioned_on)\n\nAccepts a model generator and data to condition on.  The generator must be GraphPPL.ModelGenerator object. The conditioned_on must be named tuple or a dictionary with keys corresponding to the names of the input arguments in the model.\n\n\n\n\n\n","category":"type"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"Sometimes it might be useful to condition on data, which is not available at model creation time.  This might be especially useful in reactive inference setting, where data, e.g. might be available later on from some asynchronous sensor input. For this reason, RxInfer implements a special deferred data handler, that does mark model argument as data, but does not specify any particular value for this data nor its shape.","category":"page"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"RxInfer.DeferredDataHandler","category":"page"},{"location":"library/model-construction/#RxInfer.DeferredDataHandler","page":"Model construction","title":"RxInfer.DeferredDataHandler","text":"An object that is used to condition on unknown data. That may be necessary to create a model from a ModelGenerator object for which data is not known at the time of the model creation. \n\n\n\n\n\n","category":"type"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"After the model has been conditioned it can be materialized with the RxInfer.create_model function. This function takes the RxInfer.ConditionedModelGenerator object and materializes it into a RxInfer.ProbabilisticModel.","category":"page"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"RxInfer.create_model(generator::RxInfer.ConditionedModelGenerator)\nRxInfer.ProbabilisticModel\nRxInfer.getmodel(model::RxInfer.ProbabilisticModel)\nRxInfer.getreturnval(model::RxInfer.ProbabilisticModel)\nRxInfer.getvardict(model::RxInfer.ProbabilisticModel)\nRxInfer.getrandomvars(model::RxInfer.ProbabilisticModel)\nRxInfer.getdatavars(model::RxInfer.ProbabilisticModel)\nRxInfer.getconstantvars(model::RxInfer.ProbabilisticModel)\nRxInfer.getfactornodes(model::RxInfer.ProbabilisticModel)","category":"page"},{"location":"library/model-construction/#GraphPPL.create_model-Tuple{RxInfer.ConditionedModelGenerator}","page":"Model construction","title":"GraphPPL.create_model","text":"create_model(generator::ConditionedModelGenerator)\n\nMaterializes the model specification conditioned on some data into a corresponding factor graph representation. Returns ProbabilisticModel.\n\n\n\n\n\n","category":"method"},{"location":"library/model-construction/#RxInfer.ProbabilisticModel","page":"Model construction","title":"RxInfer.ProbabilisticModel","text":"A structure that holds the factor graph representation of a probabilistic model.\n\n\n\n\n\n","category":"type"},{"location":"library/model-construction/#GraphPPL.getmodel-Tuple{ProbabilisticModel}","page":"Model construction","title":"GraphPPL.getmodel","text":"Returns the underlying factor graph model.\n\n\n\n\n\n","category":"method"},{"location":"library/model-construction/#RxInfer.getreturnval-Tuple{ProbabilisticModel}","page":"Model construction","title":"RxInfer.getreturnval","text":"Returns the value from the return ... operator inside the model specification.\n\n\n\n\n\n","category":"method"},{"location":"library/model-construction/#RxInfer.getvardict-Tuple{ProbabilisticModel}","page":"Model construction","title":"RxInfer.getvardict","text":"Returns the (nested) dictionary of random variables from the model specification.\n\n\n\n\n\n","category":"method"},{"location":"library/model-construction/#RxInfer.getrandomvars-Tuple{ProbabilisticModel}","page":"Model construction","title":"RxInfer.getrandomvars","text":"Returns the random variables from the model specification.\n\n\n\n\n\n","category":"method"},{"location":"library/model-construction/#RxInfer.getdatavars-Tuple{ProbabilisticModel}","page":"Model construction","title":"RxInfer.getdatavars","text":"Returns the data variables from the model specification.\n\n\n\n\n\n","category":"method"},{"location":"library/model-construction/#RxInfer.getconstantvars-Tuple{ProbabilisticModel}","page":"Model construction","title":"RxInfer.getconstantvars","text":"Returns the constant variables from the model specification.\n\n\n\n\n\n","category":"method"},{"location":"library/model-construction/#RxInfer.getfactornodes-Tuple{ProbabilisticModel}","page":"Model construction","title":"RxInfer.getfactornodes","text":"Returns the factor nodes from the model specification.\n\n\n\n\n\n","category":"method"},{"location":"library/model-construction/#lib-model-construction-pipelines","page":"Model construction","title":"Additional GraphPPL pipeline stages","text":"","category":"section"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"RxInfer implements several additional pipeline stages for default parsing stages in GraphPPL. A notable distinction of the RxInfer model specification language is the fact that RxInfer \"folds\"  some mathematical expressions and adds extra brackets to ensure the correct number of arguments for factor nodes. For example an expression x ~ x1 + x2 + x3 + x4 becomes x ~ ((x1 + x2) + x3) + x4 to ensure that the + function has exactly two arguments.","category":"page"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"RxInfer.error_datavar_constvar_randomvar\nRxInfer.compose_simple_operators_with_brackets\nRxInfer.inject_tilderhs_aliases\nRxInfer.ReactiveMPNodeAliases","category":"page"},{"location":"library/model-construction/#RxInfer.error_datavar_constvar_randomvar","page":"Model construction","title":"RxInfer.error_datavar_constvar_randomvar","text":"warn_datavar_constvar_randomvar(expr::Expr)\n\nAn additional pipeline stage for the @model macro from GraphPPL.  Notify the user that the datavar, constvar and randomvar syntax has been removed and is not be supported in the current version.\n\n\n\n\n\n","category":"function"},{"location":"library/model-construction/#RxInfer.compose_simple_operators_with_brackets","page":"Model construction","title":"RxInfer.compose_simple_operators_with_brackets","text":"compose_simple_operators_with_brackets(expr::Expr)\n\nAn additional pipeline stage for the @model macro from GraphPPL.  This pipeline converts simple multi-argument operators to their corresponding bracketed expression.  E.g. the expression x ~ x1 + x2 + x3 + x4 becomes x ~ ((x1 + x2) + x3) + x4). The operators to compose are + and *.\n\n\n\n\n\n","category":"function"},{"location":"library/model-construction/#RxInfer.inject_tilderhs_aliases","page":"Model construction","title":"RxInfer.inject_tilderhs_aliases","text":"inject_tilderhs_aliases(e::Expr)\n\nA pipeline stage for the @model macro from GraphPPL. This pipeline applies the aliases defined in ReactiveMPNodeAliases to the expression.\n\n\n\n\n\n","category":"function"},{"location":"library/model-construction/#RxInfer.ReactiveMPNodeAliases","page":"Model construction","title":"RxInfer.ReactiveMPNodeAliases","text":"Syntaxic sugar for ReactiveMP nodes. Replaces a || b with ReactiveMP.OR(a, b), a && b with ReactiveMP.AND(a, b), a -> b with ReactiveMP.IMPLY(a, b) and ¬a with ReactiveMP.NOT(a).\n\n\n\n\n\n","category":"constant"},{"location":"library/model-construction/#lib-model-constriction-internal-variable","page":"Model construction","title":"Getting access to an internal variable data structures","text":"","category":"section"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"To get an access to an internal ReactiveMP data structure of a variable in RxInfer model, it is possible to return  a so called label of the variable from the model macro, and access it later on as the following:","category":"page"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"using RxInfer\nusing Test #hide\n\n@model function beta_bernoulli(y)\n    θ ~ Beta(1, 1)\n    y ~ Bernoulli(θ)\n    return θ\nend\n\nresult = infer(\n    model = beta_bernoulli(),\n    data  = (y = 0.0, )\n)","category":"page"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"graph     = RxInfer.getmodel(result.model)\nreturnval = RxInfer.getreturnval(graph)\nθ         = returnval\nvariable  = RxInfer.getvariable(RxInfer.getvarref(graph, θ))\n@test variable isa ReactiveMP.RandomVariable #hide\nReactiveMP.israndom(variable)","category":"page"},{"location":"library/model-construction/","page":"Model construction","title":"Model construction","text":"","category":"page"},{"location":"manuals/session_summary/#manual-session-summary","page":"Session summary","title":"Session Summary","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"RxInfer provides a built-in session logging system that helps track and analyze various aspects of RxInfer usages. This feature is particularly useful for debugging, performance monitoring, and understanding the behavior of your inference models.","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"note: Note\nSessions are not shared and are intended for your personal use. However, you can opt-in to share your session data with the RxInfer team. See RxInfer Usage Telemetry for more details.","category":"page"},{"location":"manuals/session_summary/#Overview","page":"Session summary","title":"Overview","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"Session logging in RxInfer automatically captures and maintains statistics for:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"Model source code and metadata\nInput data characteristics\nExecution timing and success rates\nError information (if any)\nEnvironment information (Julia version, OS, etc.)\nContext keys used across invocations","category":"page"},{"location":"manuals/session_summary/#Basic-Usage","page":"Session summary","title":"Basic Usage","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"By default, RxInfer creates and maintains a global session that logs all inference invocations:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"using RxInfer\n\n# Define a simple model\n@model function simple_model(y)\n    x ~ Normal(mean = 0.0, var = 1.0)\n    y ~ Normal(mean = x, var = 1.0)\nend\n\n# Run inference with default session logging\nresult = infer(\n    model = simple_model(),\n    data = (y = 1.0,)\n)\n\n# Access the current session\nsession = RxInfer.default_session()\n\n# Get statistics for inference invocations\nstats = RxInfer.get_session_stats(session, :inference)\nprintln(\"Number of invokes: $(stats.total_invokes)\")\nprintln(\"Success rate: $(round(stats.success_rate * 100, digits=1))%\")","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"note: Note\nThe number of logged invocations may be different from the number of invocations in the example above since the session is created and logged at the start of the documentation build.","category":"page"},{"location":"manuals/session_summary/#Session-Capacity","page":"Session summary","title":"Session Capacity","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"By default, RxInfer maintains a fixed-size history of the invocations.  When this limit is exceeded, the oldest invocations are automatically dropped. This prevents  memory growth while maintaining recent history. ","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"RxInfer.DEFAULT_SESSION_STATS_CAPACITY\nRxInfer.set_session_stats_capacity!","category":"page"},{"location":"manuals/session_summary/#RxInfer.DEFAULT_SESSION_STATS_CAPACITY","page":"Session summary","title":"RxInfer.DEFAULT_SESSION_STATS_CAPACITY","text":"DEFAULT_SESSION_STATS_CAPACITY\n\nThe default capacity for the circular buffer storing session invocations. This value determines how many past invocations are stored for each label's statistics. Can be modified at compile time using preferences:\n\nusing RxInfer\nset_session_stats_capacity!(100)\n\nThe change requires a Julia session restart to take effect. Default value is 1000. Must be a positive integer.\n\n\n\n\n\n","category":"constant"},{"location":"manuals/session_summary/#RxInfer.set_session_stats_capacity!","page":"Session summary","title":"RxInfer.set_session_stats_capacity!","text":"set_session_stats_capacity!(capacity::Int)\n\nSet the default capacity for session statistics at compile time. The change requires a Julia session restart to take effect.\n\n\n\n\n\n","category":"function"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"This is particularly useful when:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"Running benchmarks that might generate many invocations\nWorking with long-running applications\nManaging memory usage in resource-constrained environments","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"note: Note\nChanging the session stats capacity requires a Julia session restart to take effect. The change is persistent across Julia sessions until explicitly changed again.","category":"page"},{"location":"manuals/session_summary/#Custom-sessions","page":"Session summary","title":"Custom sessions","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"You can also pass custom sessions to the infer function:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"using RxInfer\n\n@model function simple_model(y)\n    x ~ Normal(mean = 0.0, var = 1.0)\n    y ~ Normal(mean = x, var = 1.0)\nend\n\n# Create a custom session\nsession = RxInfer.create_session()\n\n# Run inference with custom session\nresult = infer(\n    model = simple_model(),\n    data = (y = 1.0,),\n    session = session\n)\n\nprintln(\"Session ID: $(session.id)\")\nprintln(\"Created at: $(session.created_at)\")","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"or pass nothing to disable session logging:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"result = infer(\n    model = simple_model(),\n    data = (y = 1.0,),\n    session = nothing # skips session logging for this invocation\n)","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"See Configuration for more details on how to manage sessions.","category":"page"},{"location":"manuals/session_summary/#Session-Reset","page":"Session summary","title":"Session Reset","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"You can reset the session to its initial state with RxInfer.reset_session! function:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"RxInfer.reset_session!","category":"page"},{"location":"manuals/session_summary/#RxInfer.reset_session!","page":"Session summary","title":"RxInfer.reset_session!","text":"reset_session!(session, [ labels ])\n\nRemoves gathered statistics from the session. Optionally accepts a vector of labels to delete. If no labels specified deletes everything.\n\n\n\n\n\n","category":"function"},{"location":"manuals/session_summary/#Session-Statistics","page":"Session summary","title":"Session Statistics","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"RxInfer maintains detailed statistics for each label in a session. Currently, only the :inference label is actively used, which collects information about inference invocations.","category":"page"},{"location":"manuals/session_summary/#What's-being-collected","page":"Session summary","title":"What's being collected","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"For the :inference label, each invocation records:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"Basic Information:\nUnique identifier (UUID)\nStatus (:success or :error)\nExecution start and end timestamps\nModel Information:\nModel source code (via GraphPPL.getsource)\nModel name (via GraphPPL.getmodel)\nModel constraints (if specified)\nModel meta information (if specified)\nModel autoupdates specification (if specified)\nModel initialization specification (if specified)\nData Information:\nInput data characteristics (names, types, sizes) - no actual data is collected`\nDatastream type (for streaming inference)\nReturn variables structure\nPredict variables structure (for batch inference)\nHistory variables structure (for streaming inference)\nHistory buffer size (if specified)\nInference Parameters:\nNumber of iterations\nFree energy computation flag\nNode contraction settings\nProgress display settings\nException catching settings\nAdditional Settings:\nCallbacks configuration\nAddons configuration\nOptions configuration","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"note: Note\nNo actual data is collected for the :inference label. Only metadata such as size and type is recorded.","category":"page"},{"location":"manuals/session_summary/#An-example-of-a-last-infer-call-in-the-session","page":"Session summary","title":"An example of a last infer call in the session","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"The documentation build for RxInfer executes real code and maintains its own session. Let's look at an example of a last infer call in the session:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"using RxInfer\n\nsession = RxInfer.default_session()","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"stats = RxInfer.get_session_stats(session, :inference)","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"last_invoke = stats.invokes[end]","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"last_invoke.context","category":"page"},{"location":"manuals/session_summary/#Aggregated-statistics","page":"Session summary","title":"Aggregated statistics","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"These individual invocations are then aggregated into real-time statistics:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"Total number of invocations and success/failure counts\nSuccess rate (fraction of successful invokes)\nExecution timing statistics (min, max, total duration)\nSet of all context keys used across invocations\nFixed-size history of recent invocations (controlled by DEFAULT_SESSION_STATS_CAPACITY)","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"RxInfer.SessionStats","category":"page"},{"location":"manuals/session_summary/#RxInfer.SessionStats","page":"Session summary","title":"RxInfer.SessionStats","text":"SessionStats\n\nStatistics for a specific label in a session.\n\nFields\n\nid::UUID: Unique identifier for these statistics\nlabel::Symbol: The label these statistics are for\ntotal_invokes::Int: Total number of invokes with this label\nsuccess_count::Int: Number of successful invokes\nfailed_count::Int: Number of failed invokes\nsuccess_rate::Float64: Fraction of successful invokes (between 0 and 1)\nmin_duration_ms::Float64: Minimum execution duration in milliseconds\nmax_duration_ms::Float64: Maximum execution duration in milliseconds\ntotal_duration_ms::Float64: Total execution duration for mean calculation\ncontext_keys::Set{Symbol}: Set of all context keys used across invokes\ninvokes::CircularBuffer{SessionInvoke}: A series of invokes attached to the statistics\n\n\n\n\n\n","category":"type"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"You can access these statistics using get_session_stats:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"using RxInfer\n\nsession = RxInfer.default_session()\nstats = RxInfer.get_session_stats(session, :inference)\n\nprintln(\"Total invokes: $(stats.total_invokes)\")\nprintln(\"Success rate: $(round(stats.success_rate * 100, digits=1))%\")\nprintln(\"Failed invokes: $(stats.failed_count)\")\nprintln(\"Mean duration (ms): $(stats.total_invokes > 0 ? round(stats.total_duration_ms / stats.total_invokes, digits=2) : 0.0)\")","category":"page"},{"location":"manuals/session_summary/#Session-Structure","page":"Session summary","title":"Session Structure","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"A session consists of the following components:","category":"page"},{"location":"manuals/session_summary/#Session-Fields","page":"Session summary","title":"Session Fields","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"id::UUID: Unique identifier for the session\ncreated_at::DateTime: Session creation timestamp\nenvironment::Dict{Symbol, Any}: System and environment information\nstats::Dict{Symbol, SessionStats}: Statistics per label\nsemaphore::Base.Semaphore: Thread-safe semaphore for concurrent updates","category":"page"},{"location":"manuals/session_summary/#Environment-Information","page":"Session summary","title":"Environment Information","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"The session automatically captures system information including:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"Julia version\nRxInfer version\nOperating system\nMachine architecture\nCPU threads\nSystem word size","category":"page"},{"location":"manuals/session_summary/#Statistics-Information","page":"Session summary","title":"Statistics Information","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"Each label's statistics (SessionStats) captures:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"id::UUID: Unique identifier for these statistics\nlabel::Symbol: The label these statistics are for\ntotal_invokes::Int: Total number of invokes\nsuccess_count::Int: Number of successful invokes\nfailed_count::Int: Number of failed invokes\nsuccess_rate::Float64: Fraction of successful invokes\nmin_duration_ms::Float64: Minimum execution duration\nmax_duration_ms::Float64: Maximum execution duration\ntotal_duration_ms::Float64: Total execution duration\ncontext_keys::Set{Symbol}: Set of all context keys used\ninvokes::CircularBuffer{SessionInvoke}: Recent invocations history","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"RxInfer.SessionInvoke\nRxInfer.create_invoke","category":"page"},{"location":"manuals/session_summary/#RxInfer.SessionInvoke","page":"Session summary","title":"RxInfer.SessionInvoke","text":"SessionInvoke\n\nRepresents a single invocation of an inference operation.\n\nFields\n\nid::UUID: Unique identifier for this invocation\nstatus::Symbol: Status of the invocation (e.g. :success, :failure)\nexecution_start::DateTime: When the invocation started\nexecution_end::DateTime: When the invocation completed\ncontext::Dict{Symbol, Any}: Additional contextual information\n\n\n\n\n\n","category":"type"},{"location":"manuals/session_summary/#RxInfer.create_invoke","page":"Session summary","title":"RxInfer.create_invoke","text":"create_invoke()\n\nCreate a new session invoke with status set to :unknown.\n\n\n\n\n\n","category":"function"},{"location":"manuals/session_summary/#Accessing-Session-Data","page":"Session summary","title":"Accessing Session Data","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"You can inspect session data to analyze inference behavior:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"using RxInfer\n\n@model function simple_model(y)\n    x ~ Normal(mean = 0.0, var = 1.0)\n    y ~ Normal(mean = x, var = 1.0)\nend\n\nsession = RxInfer.create_session()\nresult = infer(model = simple_model(), data = (y = 1.0,), session = session)\n\n# Get inference statistics\nstats = RxInfer.get_session_stats(session, :inference)\n\n# Get the latest invoke\nlatest_invoke = stats.invokes[end]\n\n# Check invocation status\nprintln(\"Status: $(latest_invoke.status)\")\n\n# Calculate execution duration\nduration = latest_invoke.execution_end - latest_invoke.execution_start\nprintln(\"Duration: $duration\")\n\n# Access model source\nprintln(\"Model name: $(latest_invoke.context[:model_name])\")\nprintln(\"Model source: $(latest_invoke.context[:model])\")\n\n# Examine data properties\nfor entry in latest_invoke.context[:data]\n    println(\"\\nData variable: $(entry.name)\")\n    println(\"Type: $(entry.type)\")\n    println(\"Size: $(entry.size)\")\nend","category":"page"},{"location":"manuals/session_summary/#session-configuration","page":"Session summary","title":"Configuration","text":"","category":"section"},{"location":"manuals/session_summary/#Default-Session","page":"Session summary","title":"Default Session","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"The default session is created automatically when RxInfer is first imported. It is used for logging all inference invocations by default.","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"RxInfer.default_session","category":"page"},{"location":"manuals/session_summary/#RxInfer.default_session","page":"Session summary","title":"RxInfer.default_session","text":"default_session()::Union{Nothing, Session}\n\nGet the current default session. If no session exists, returns nothing.\n\nReturns\n\nUnion{Nothing, Session}: The current default session or nothing if logging is disabled\n\n\n\n\n\n","category":"function"},{"location":"manuals/session_summary/#Enabling/Disabling-Logging","page":"Session summary","title":"Enabling/Disabling Logging","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"Session logging can be enabled or disabled globally","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"RxInfer.disable_session_logging!\nRxInfer.enable_session_logging!","category":"page"},{"location":"manuals/session_summary/#RxInfer.disable_session_logging!","page":"Session summary","title":"RxInfer.disable_session_logging!","text":"Disables session logging for RxInfer globally at compile time and saves it in package preferences. Has effect after Julia restart.\n\nRestart Julia and verify it by isnothing(RxInfer.default_session()). \n\nNote that session logging still can be enabled manually for the current session if set_default_session! is called manually with appropriate Session object. \n\n\n\n\n\n","category":"function"},{"location":"manuals/session_summary/#RxInfer.enable_session_logging!","page":"Session summary","title":"RxInfer.enable_session_logging!","text":"Enables session logging for RxInfer globally at compile time and saves it in package preferences. Has effect after Julia restart.\n\nRestart Julia and verify it by !isnothing(RxInfer.default_session()).     \n\n\n\n\n\n","category":"function"},{"location":"manuals/session_summary/#Managing-Sessions","page":"Session summary","title":"Managing Sessions","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"RxInfer.create_session\nRxInfer.set_default_session!","category":"page"},{"location":"manuals/session_summary/#RxInfer.create_session","page":"Session summary","title":"RxInfer.create_session","text":"create_session()\n\nCreate a new session with a unique identifier, environment info and current timestamp. The session maintains separate statistics for each label, with each label's statistics having its own circular buffer of invokes.\n\n\n\n\n\n","category":"function"},{"location":"manuals/session_summary/#RxInfer.set_default_session!","page":"Session summary","title":"RxInfer.set_default_session!","text":"set_default_session!(session::Union{Nothing, Session})\n\nSet the default session to a new session or disable logging by passing nothing. \n\nArguments\n\nsession::Union{Nothing, Session}: The new session to set as default, or nothing to disable logging\n\n\n\n\n\n","category":"function"},{"location":"manuals/session_summary/#Best-Practices","page":"Session summary","title":"Best Practices","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"Error Handling: Session logging automatically captures errors, making it easier to debug issues:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"using RxInfer\n\n@model function problematic_model(y)\n    x ~ Normal(mean = 0.0, var = sqrt(-1.0)) # Invalid variance\n    y ~ Normal(mean = x, var = 1.0)\nend\n\ntry\n    result = infer(model = problematic_model(), data = (y = 1.0,))\ncatch e\n    # Check the latest invoke for error details\n    stats = RxInfer.get_session_stats(RxInfer.default_session(), :inference)\n    latest_invoke = stats.invokes[end]\n    println(\"Status: $(latest_invoke.status)\")\n    println(\"Error: $(latest_invoke.context[:error])\")\nend","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"Performance Monitoring: Use session statistics to monitor inference performance:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"using RxInfer, Statistics\n\n@model function simple_model(y)\n    x ~ Normal(mean = 0.0, var = 1.0)\n    y ~ Normal(mean = x, var = 1.0)\nend\n\nsession = RxInfer.create_session()\n\n# Run multiple inferences\nfor i in 1:5\n    infer(model = simple_model(), data = (y = randn(),), session = session)\nend\n\nstats = RxInfer.get_session_stats(session, :inference)\nprintln(\"Mean duration (ms): $(round(stats.total_duration_ms / stats.total_invokes, digits=2))\")\nprintln(\"Success rate: $(round(stats.success_rate * 100, digits=1))%\")","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"note: Note\nThe first invocation is typically slower due to Julia's JIT compilation.","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"Data Validation: Session logging helps track data characteristics:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"using RxInfer\n\n@model function simple_model(y)\n    x ~ Normal(mean = 0.0, var = 1.0)\n    y ~ Normal(mean = x, var = 1.0)\nend\n\nsession = RxInfer.create_session()\nresult = infer(model = simple_model(), data = (y = 1.0,), session = session)\n\nstats = RxInfer.get_session_stats(session, :inference)\nlatest_invoke = stats.invokes[end]\n\n# Check data properties\nfor entry in latest_invoke.context[:data]\n    println(\"Variable: $(entry.name)\")\n    println(\"Type: $(entry.type)\")\nend","category":"page"},{"location":"manuals/session_summary/#Session-Summary","page":"Session summary","title":"Session Summary","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"You can view a tabular summary of these statistics at any time to understand how your inference tasks are performing:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"note: Note\nSession statistics below are collected during the documentation build.","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"The main function for viewing session statistics is summarize_session:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"RxInfer.summarize_session","category":"page"},{"location":"manuals/session_summary/#RxInfer.summarize_session","page":"Session summary","title":"RxInfer.summarize_session","text":"summarize_session([io::IO], session::Session, label::Symbol = :inference; n_last = 5)\n\nPrint a concise summary of session statistics for invokes with the specified label. The default label is :inference which gathers statistics of the infer function calls.\n\n\n\n\n\n","category":"function"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"using RxInfer #hide\nRxInfer.summarize_session(; n_last = 25)","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"The summary includes:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"Total number of inference invocations and success rate\nExecution time statistics (mean, min, max)\nList of context keys present\nNumber of unique models used\nTable of most recent invocations showing:\nStatus (success/failed)\nDuration in milliseconds\nModel name\nData variables used","category":"page"},{"location":"manuals/session_summary/#Programmatic-Access","page":"Session summary","title":"Programmatic Access","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"If you need to access the statistics programmatically, use get_session_stats:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"RxInfer.get_session_stats","category":"page"},{"location":"manuals/session_summary/#RxInfer.get_session_stats","page":"Session summary","title":"RxInfer.get_session_stats","text":"get_session_stats(session::Session, label::Symbol = :inference)\n\nGet statistics for invokes with the specified label. If the label doesn't exist in the session, returns a new empty SessionStats instance.\n\nArguments\n\nsession::Union{Nothing, Session}: The session to get statistics from, or nothing\nlabel::Symbol: The label to get statistics for, defaults to :inference\n\n\n\n\n\n","category":"function"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"using RxInfer #hide\nsession = RxInfer.default_session()\nstats = RxInfer.get_session_stats(session, :inference)","category":"page"},{"location":"manuals/session_summary/#Benchmarking-Considerations","page":"Session summary","title":"Benchmarking Considerations","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"When benchmarking code that involves the infer function, it's important to be aware of session logging behavior:","category":"page"},{"location":"manuals/session_summary/#Why-Disable-Session-Logging-During-Benchmarking?","page":"Session summary","title":"Why Disable Session Logging During Benchmarking?","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"Multiple Executions: Benchmarking tools like BenchmarkTools.jl execute the code multiple times to gather accurate performance metrics. Each execution is logged as a separate invoke in the session, which can quickly fill up the session buffer.\nSession Pollution: These benchmark runs can pollute your session history with test invocations, making it harder to track and analyze your actual inference calls.\nPerformance Impact: While minimal, session logging does add some overhead to each infer call, which could affect benchmark results.","category":"page"},{"location":"manuals/session_summary/#Best-Practices-2","page":"Session summary","title":"Best Practices","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"To get accurate benchmarking results and maintain a clean session history:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"# DON'T: This will fill your session with benchmark invocations\n@benchmark infer(model = my_model, data = my_data)\n\n# DO: Explicitly disable session logging during benchmarking\n@benchmark infer(model = my_model, data = my_data, session = nothing)","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"You can also temporarily disable session logging globally:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"# Disable session logging\nprevious_session = RxInfer.default_session()\nRxInfer.set_default_session!(nothing)\n# Run your benchmarks\n# ...\n# Re-enable session logging reusing the previous session\nRxInfer.set_default_session!(previous_session)","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"or disable it explicitly:","category":"page"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"RxInfer.disable_session_logging!() # works after Julia restart","category":"page"},{"location":"manuals/session_summary/#Developers-Reference","page":"Session summary","title":"Developers Reference","text":"","category":"section"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"RxInfer.Session\nRxInfer.with_session\nRxInfer.append_invoke_context\nRxInfer.update_session!\nRxInfer.update_stats!","category":"page"},{"location":"manuals/session_summary/#RxInfer.Session","page":"Session summary","title":"RxInfer.Session","text":"Session\n\nA structure that maintains a log of RxInfer usage. Each session has a unique identifier and saves when it was created together with its environment.  The session maintains a dictionary of labeled statistics, each tracking a series of invocations (SessionInvoke)  and computing real-time statistics.\n\nFields\n\nid::UUID: A unique identifier for the session\ncreated_at::DateTime: Timestamp when the session was created\nenvironment::Dict{Symbol, Any}: Information about the Julia & RxInfer versions and system when the session was created\nsemaphore::Base.Semaphore: Thread-safe semaphore for updating stats\nstats::Dict{Symbol, SessionStats}: Statistics per label\n\nThe session logging is transparent and only collects non-sensitive information about calls. Users can inspect the session at any time using get_current_session() and reset it using reset_session!().\n\n\n\n\n\n","category":"type"},{"location":"manuals/session_summary/#RxInfer.with_session","page":"Session summary","title":"RxInfer.with_session","text":"with_session(f::F, session, label::Symbol = :unknown) where {F}\n\nExecute function f within a session context with the specified label. If session is provided, logs execution details including timing and errors, and updates the session statistics for the given label. If session is nothing, executes f without logging.\n\n\n\n\n\n","category":"function"},{"location":"manuals/session_summary/#RxInfer.append_invoke_context","page":"Session summary","title":"RxInfer.append_invoke_context","text":"append_invoke_context(f, invoke)\n\nAppend context information to a session invoke. If invoke is a SessionInvoke, executes function f with the invoke's context. If invoke is nothing, does nothing.\n\n\n\n\n\n","category":"function"},{"location":"manuals/session_summary/#RxInfer.update_session!","page":"Session summary","title":"RxInfer.update_session!","text":"update_session!(session::Session, label::Symbol, invoke::SessionInvoke)\n\nThread-safely update session statistics for a given label with a new invoke. Uses a semaphore to ensure thread safety when multiple threads try to update statistics simultaneously.\n\nArguments\n\nsession::Session: The session to update\nlabel::Symbol: Label for the invoke\ninvoke::SessionInvoke: The invoke to add to statistics\n\n\n\n\n\n","category":"function"},{"location":"manuals/session_summary/#RxInfer.update_stats!","page":"Session summary","title":"RxInfer.update_stats!","text":"update_stats!(stats::SessionStats, invoke::SessionInvoke)\n\nUpdate session statistics with a new invoke.\n\n\n\n\n\n","category":"function"},{"location":"manuals/session_summary/","page":"Session summary","title":"Session summary","text":"","category":"page"},{"location":"library/functional-forms/#lib-forms","page":"Functional form constraints","title":"Built-in Functional Forms","text":"","category":"section"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"This section describes built-in functional forms that can be used for posterior marginal and/or messages form constraints specification. Read more information about constraints specification syntax in the Constraints Specification section.","category":"page"},{"location":"library/functional-forms/#lib-forms-background","page":"Functional form constraints","title":"Background","text":"","category":"section"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"In message passing framework, in order to compute a posterior over some latent state q(x), it is necessary to compute a normalized product of two messages q(x) = fracmu_1(x) mu_2(x)int mu_1(x) mu_2(x) mathrmdx In some situations, when functional forms of mu_1(x) and mu_2(x) are know in advance, it is possible to compute the normalized product efficiently and analytically. It is, however, not always the case, since the messages can have arbitrary functional form and it is not always easy to compute the normalization factor.","category":"page"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"Functional forms help to circumvent this. They implement a custom callback on the product of two messages, which cannot  be computed analytically. Essentially, a functional form constraint defines a functional F, such that  q(x) = Fmu_1 mu_2 approx fracmu_1(x) mu_2(x)int mu_1(x) mu_2(x) mathrmdx","category":"page"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"See also Bethe Free Energy section for more information on variational inference and posterior computation.","category":"page"},{"location":"library/functional-forms/#lib-forms-unspecified-constraint","page":"Functional form constraints","title":"UnspecifiedFormConstraint","text":"","category":"section"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"Unspecified functional form constraint is used by default and uses only analytical update rules for computing posterior marginals. Throws an error if a product of two colliding messages cannot be computed analytically.","category":"page"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"using RxInfer, Distributions #hide\n@constraints begin \n    # This is the default setting for all latent variables\n    q(x) :: UnspecifiedFormConstraint() \nend\nnothing #hide","category":"page"},{"location":"library/functional-forms/#lib-forms-point-mass-constraint","page":"Functional form constraints","title":"PointMassFormConstraint","text":"","category":"section"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"The most basic form of posterior marginal approximation is the PointMass function. In a few words PointMass represents the delta function. In the context of functional form constraints PointMass approximation corresponds to the MAP estimate. For a given distribution d - PointMass functional form simply finds the argmax of the logpdf of q(x), thus q(x) = Fmu_1 mu_2 = delta(x - argmin_x mu_1(x) mu_2(x)). This is especially useful when exact functional form of q(x) is not available or cannot be parametrized efficiently. ","category":"page"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"@constraints begin \n    q(x) :: PointMassFormConstraint()\nend\n\n@constraints begin \n    q(x) :: PointMassFormConstraint(starting_point = (args...) -> 1.0)\nend\nnothing #hide","category":"page"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"RxInfer.PointMassFormConstraint\nRxInfer.default_point_mass_form_constraint_optimizer\nRxInfer.default_point_mass_form_constraint_starting_point\nRxInfer.default_point_mass_form_constraint_boundaries","category":"page"},{"location":"library/functional-forms/#RxInfer.PointMassFormConstraint","page":"Functional form constraints","title":"RxInfer.PointMassFormConstraint","text":"PointMassFormConstraint\n\nOne of the form constraint objects. Constraint a message to be in a form of dirac's delta point mass.  By default uses Optim.jl package to find argmin of -logpdf(x).  Accepts custom optimizer callback which might be used to customise optimisation procedure with different packages  or different arguments for Optim.jl package.\n\nKeyword arguments\n\noptimizer: specifies a callback function for logpdf optimisation. See also: RxInfer.default_point_mass_form_constraint_optimizer\nstarting_point: specifies a callback function for initial optimisation point: See also: RxInfer.default_point_mass_form_constraint_starting_point\nboundaries: specifies a callback function for determining optimisation boundaries: See also: RxInfer.default_point_mass_form_constraint_boundaries\n\nCustom optimizer callback interface\n\n# This is an example of the `custom_optimizer` interface\nfunction custom_optimizer(::Type{ Univariate }, ::Type{ Continuous }, constraint::PointMassFormConstraint, distribution)\n    # should return argmin of the -logpdf(distribution)\nend\n\nCustom starting point callback interface\n\n# This is an example of the `custom_starting_point` interface\nfunction custom_starting_point(::Type{ Univariate }, ::Type{ Continuous }, constraint::PointMassFormConstraint, distribution)\n    # built-in optimizer expects an array, even for a univariate distribution\n    return [ 0.0 ] \nend\n\nCustom boundaries callback interface\n\n# This is an example of the `custom_boundaries` interface\nfunction custom_boundaries(::Type{ Univariate }, ::Type{ Continuous }, constraint::PointMassFormConstraint, distribution)\n    # returns a tuple of `lower` and `upper` boundaries\n    return (-Inf, Inf)\nend\n\n\n\n\n\n","category":"type"},{"location":"library/functional-forms/#RxInfer.default_point_mass_form_constraint_optimizer","page":"Functional form constraints","title":"RxInfer.default_point_mass_form_constraint_optimizer","text":"default_point_mass_form_constraint_optimizer(::Type{<:VariateType}, ::Type{<:ValueSupport}, constraint::PointMassFormConstraint, distribution)\n\nDefines a default optimisation procedure for the PointMassFormConstraint. By default uses Optim.jl package to find argmin of -logpdf(x). Uses the starting_point and boundaries callbacks to determine the starting point and boundaries for the optimisation procedure.\n\n\n\n\n\n","category":"function"},{"location":"library/functional-forms/#RxInfer.default_point_mass_form_constraint_starting_point","page":"Functional form constraints","title":"RxInfer.default_point_mass_form_constraint_starting_point","text":"default_point_mass_form_constraint_starting_point(::Type{<:VariateType}, ::Type{<:ValueSupport}, constraint::PointMassFormConstraint, distribution)\n\nDefines a default starting point for the PointMassFormConstraint. By default uses the support of the distribution. If support is unbounded returns a zero point. Otherwise throws an error.\n\n\n\n\n\n","category":"function"},{"location":"library/functional-forms/#RxInfer.default_point_mass_form_constraint_boundaries","page":"Functional form constraints","title":"RxInfer.default_point_mass_form_constraint_boundaries","text":"default_point_mass_form_constraint_boundaries(::Type{<:VariateType}, ::Type{<:ValueSupport}, constraint::PointMassFormConstraint, distribution)\n\nDefines a default boundaries for the PointMassFormConstraint. By default simply uses the support of the distribution.\n\n\n\n\n\n","category":"function"},{"location":"library/functional-forms/#lib-forms-sample-list-constraint","page":"Functional form constraints","title":"SampleListFormConstraint","text":"","category":"section"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"SampleListFormConstraints approximates the resulting posterior marginal (product of two colliding messages) as a list of weighted samples. Hence, it requires one of the arguments to be a proper distribution (or at least the inference backend should be able to sample from it). This setting is controlled with LeftProposal(), RightProposal() or AutoProposal() objects. It also accepts an optional method object, but the only one available sampling method currently is the BayesBase.BootstrapImportanceSampling.","category":"page"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"@constraints begin \n    q(x) :: SampleListFormConstraint(1000)\n    # or \n    q(y) :: SampleListFormConstraint(1000, LeftProposal())\nend\nnothing #hide","category":"page"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"RxInfer.SampleListFormConstraint\nRxInfer.AutoProposal\nRxInfer.LeftProposal\nRxInfer.RightProposal","category":"page"},{"location":"library/functional-forms/#RxInfer.SampleListFormConstraint","page":"Functional form constraints","title":"RxInfer.SampleListFormConstraint","text":"SampleListFormConstraint(rng, strategy, method)\n\nOne of the form constraint objects. Approximates DistProduct with a SampleList object. \n\n\n\n\n\n","category":"type"},{"location":"library/functional-forms/#RxInfer.AutoProposal","page":"Functional form constraints","title":"RxInfer.AutoProposal","text":"Tries to determine the proposal distribution in the SampleList approximation automatically.\n\n\n\n\n\n","category":"type"},{"location":"library/functional-forms/#RxInfer.LeftProposal","page":"Functional form constraints","title":"RxInfer.LeftProposal","text":"Uses the left argument in the prod call as the proposal distribution in the SampleList approximation.\n\n\n\n\n\n","category":"type"},{"location":"library/functional-forms/#RxInfer.RightProposal","page":"Functional form constraints","title":"RxInfer.RightProposal","text":"Uses the right argument in the prod call as the proposal distribution in the SampleList approximation.\n\n\n\n\n\n","category":"type"},{"location":"library/functional-forms/#lib-forms-fixed-marginal-constraint","page":"Functional form constraints","title":"FixedMarginalFormConstraint","text":"","category":"section"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"Fixed marginal form constraint replaces the resulting posterior marginal obtained during the inference procedure with the prespecified one. Worth to note that the inference backend still tries to compute real posterior marginal and may fail during this process. Might be useful for debugging purposes. If nothing is passed then the computed posterior marginal is returned (see also UnspecifiedFormConstraint).","category":"page"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"@constraints function block_updates(x_posterior = nothing) \n    # `nothing` returns the computed posterior marginal\n    q(x) :: FixedMarginalFormConstraint(x_posterior)\nend\nnothing #hide","category":"page"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"RxInfer.FixedMarginalFormConstraint","category":"page"},{"location":"library/functional-forms/#RxInfer.FixedMarginalFormConstraint","page":"Functional form constraints","title":"RxInfer.FixedMarginalFormConstraint","text":"FixedMarginalFormConstraint\n\nOne of the form constraint objects. Provides a constraint on the marginal distribution such that it remains fixed during inference.  Can be viewed as blocking of updates of a specific edge associated with the marginal. If nothing is passed then the computed posterior marginal is returned. Use .fixed_value field to update the value of the constraint.\n\n\n\n\n\n","category":"type"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"It is also possible to control the constraint manually, e.g:","category":"page"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"form_constraint = FixedMarginalFormConstraint(nothing)\n\nconstraints_specification = @constraints function manual_block_updates(form_constraint) \n    q(x) :: form_constraint\nend\n\n# later on ...\nform_constraint.fixed_value = Gamma(1.0, 1.0)","category":"page"},{"location":"library/functional-forms/#lib-forms-composite-constraint","page":"Functional form constraints","title":"CompositeFormConstraint","text":"","category":"section"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"It is possible to create a composite functional form by stacking operators, e.g:","category":"page"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"@constraints begin \n    q(x) :: SampleListFormConstraint(1000) :: PointMassFormConstraint()\nend","category":"page"},{"location":"library/functional-forms/#lib-forms-custom-constraints","page":"Functional form constraints","title":"Custom functional forms","text":"","category":"section"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"See the ReactiveMP.jl library documentation for more information about defining novel custom functional forms that are compatible with ReactiveMP inference backend.","category":"page"},{"location":"library/functional-forms/","page":"Functional form constraints","title":"Functional form constraints","text":"","category":"page"},{"location":"contributing/guide/#contributing-overview","page":"Contribution guide","title":"Contributing","text":"","category":"section"},{"location":"contributing/guide/","page":"Contribution guide","title":"Contribution guide","text":"Welcome to the contribution guide for RxInfer.jl. Here you'll find information on the RxInfer project structure, and how to get started with contributing to the project. For more practical instructions and guidelines, refer to the contribution guidelines.","category":"page"},{"location":"contributing/guide/#Project-structure","page":"Contribution guide","title":"Project structure","text":"","category":"section"},{"location":"contributing/guide/","page":"Contribution guide","title":"Contribution guide","text":"RxInfer.jl is a Julia package that provides a high-level interface for probabilistic programming. It is composed of three major core dependencies:","category":"page"},{"location":"contributing/guide/","page":"Contribution guide","title":"Contribution guide","text":"Rocket.jl: A package for reactive programming, allowing asynchronous data processing\nGraphPPL.jl: A domain-specific language for probabilistic programming, facilitating the @model macro and other crucial user-facing features.\nReactiveMP.jl: Reactive message passing engine, using Rocket.jl to pass messages between nodes in a probabilistic model defined with GraphPPL.jl.","category":"page"},{"location":"contributing/guide/","page":"Contribution guide","title":"Contribution guide","text":"In general, non-inference related functionality is implemented in Rocket.jl and GraphPPL.jl, while inference-related functionality is implemented in ReactiveMP.jl. For example, all factor nodes and inference rules for messages are implemented in ReactiveMP.jl.","category":"page"},{"location":"contributing/guide/#Getting-started","page":"Contribution guide","title":"Getting started","text":"","category":"section"},{"location":"contributing/guide/","page":"Contribution guide","title":"Contribution guide","text":"To familiarize yourself with development in RxInfer, we recommend the following steps:","category":"page"},{"location":"contributing/guide/","page":"Contribution guide","title":"Contribution guide","text":"Familiarize yourself with the collaborative tools used in the project. RxInfer uses GitHub for version control, issue tracking, and pull requests. We aim to maintain the good first issue label on issues that are suitable for new contributors. Furthermore, the core development team tracks the project's progress and development tasks on the project board. Because the project board is overwhelming, we recommend focusing first on issues labeled with the good first issue label. \nRead the contribution guidelines to understand the contribution process and best practices for contributing to RxInfer, as well as coding practices and testing procedures.\nFamiliarize yourself with the RxInfer codebase and its core dependencies. While most information can be found on the RxInfer documentation page, it is also recommended to read the documentation for Rocket.jl, GraphPPL.jl, and ReactiveMP.jl to understand the core functionality and design principles of the project.\nPick an issue to work on. We recommend starting with a good first issue to familiarize yourself with the contribution process. Once you're comfortable with the process, you can move on to more complex issues.","category":"page"},{"location":"contributing/guide/#Contribution-guidelines","page":"Contribution guide","title":"Contribution guidelines","text":"","category":"section"},{"location":"contributing/guide/","page":"Contribution guide","title":"Contribution guide","text":"The contribution guidelines provide detailed instructions on how to contribute effectively to the project. They cover reporting bugs, suggesting features, and contributing code. For more information, refer to the contribution guidelines.","category":"page"},{"location":"contributing/guide/","page":"Contribution guide","title":"Contribution guide","text":"","category":"page"},{"location":"manuals/comparison/#comparison","page":"RxInfer.jl vs. Others","title":"Comparison to other packages","text":"","category":"section"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"Nowadays there's plenty of probabilistic programming languages and packages available. Although all are based on Bayesian inference, their methodologies vary. This section compares RxInfer.jl against other renowned probabilistic programming languages and packages. The goal is to enlighten potential users about the nuances and guide them in choosing the package that best suits their requirements.","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"warning: Warning\nThis comparison is not exhaustive and mirrors the author's hands-on experience with the packages. Others may have undergone more rigorous testing. If you're an author of one of these packages and believe this comparison does not do justice, please reach out, and we will be more than willing to make corrections.\nThe comparison is more qualitative than quantitative, considering the intricacies of upkeeping benchmarking code for perpetually evolving packages.","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"Toolbox Universality Efficiency Expressiveness Debugging & Visualization Modularity Inference Engine Language Community & Ecosystem\nRxInfer.jl ~ ✓ ✓ ~ ✓ Message-passing Julia ✗\nForneyLab.jl ✗ ~ ✗ ~ ✗ Message-passing Julia ✗\nInfer.net ~ ✓ ✗ ✓ ✗ Message-passing C# ✗\nPGMax ✗ ✓ ✗ ✓ ✗ Message-passing Python ✗\nTuring.jl ✓ ✗ ✓ ~ ✗ Sampling Julia ✓\nPyMC ✓ ✗ ✓ ✓ ✗ Sampling Python ✓\nNumPyro ✓ ✓ ~ ✓ ✗ Sampling Python ✓\nTensorFlow Probability ✓ ✗ ~ ✓ ✗ Sampling Python ✓\nStan ✓ ✗ ✓ ✓ ✗ Sampling Stan ✓","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"(Date of creation: 20/10/2023)","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"Legend","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"✓ : Full capability or feature is present.\n~ : Partial capability or feature is present.\n✗ : No capability or feature.","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"Notes:","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"Universality: Denotes the capability to depict a vast array of probabilistic models.\nEfficiency: Highlights computational competence. A \"~\" in this context suggests perceived slowness.\nExpressiveness: Assesses the ability to concisely formulate intricate probabilistic models.\nDebugging & Visualization: Evaluates the suite of tools for model debugging and visualization.\nModularity: Reflects the potential to create models by integrating smaller models.\nInference Engines: Pinpoints the primary inference strategy employed by the toolbox.\nLanguage: Identifies the programming language integral to the toolbox.\nCommunity & Ecosystem: Signifies the vibrancy of the ecosystem, inclusive of tools, libraries, and community backing.","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"","category":"page"},{"location":"manuals/comparison/#RxInfer.jl-breakdown","page":"RxInfer.jl vs. Others","title":"RxInfer.jl breakdown","text":"","category":"section"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"Universality: RxInfer.jl shines in formulating models derived from the exponential family distributions. The package encompasses not only commonly used distributions such as Gaussian or Bernoulli, but also specialized stochastic nodes that represents prevalent probabilistic models like Autoregressive models, Gamma Mixture models, among others. Furthermore, RxInfer.jl proficiently manages deterministic transformations of variables from the exponential family, see Delta node. Nevertheless, for models outside the exponential family, RxInfer.jl might not be the good choice. Such models would require the creation of novel nodes and corresponding rules, as illustrated in this section.\nEfficiency: RxInfer.jl distinguishes itself with its inference engine rooted in reactive message passing. This approach is supremely efficient, facilitating real-time propagation of updates across the system, supporting parallelization, interruptibility, and more. \nModularity: Broadly, the toolboxes in the table aren't modular in the truest sense. They don't offer the fusion of models by integrating smaller models. RxInfer.jl on the other hand provides a way to compose different models:","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"using RxInfer #hide\n\n@model function inner_inner(τ, y, x)\n    y ~ Normal(mean = τ[1], var = τ[2] + x)\nend\n\n@model function inner(θ, α)\n    β ~ Normal(mean = 0.0, var = 1.0)\n    α ~ Gamma(shape = β, rate = 1.0)\n    α ~ inner_inner(τ = θ, x = 3)\nend\n\n@model function outer()\n    local w\n    for i = 1:5\n        w[i] ~ inner(θ = Gamma(shape = 1.0, rate = 1.0))\n    end\n    y ~ inner(θ = w[2:3])\nend","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"Expressiveness: RxInfer.jl empowers users to elegantly and concisely craft models, closely mirroring probabilistic notation, thanks to Julia's macro capabilities.","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"note: Note\nRxInfer uses := for deterministic relationships (see Using = instead of := for deterministic nodes) which might differ from other frameworks but enables powerful message-passing capabilities.","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"To illustrate the expressiveness, let's consider the following model:","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"beginaligned\n x  sim mathrmNormal(00 10)\n w  sim mathrmInverseGamma(10 10)\n y  sim mathrmNormal(x w)\nendaligned","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"The model then is expressed in RxInfer.jl as follows:","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"using RxInfer #hide\n\n@model function example_model()\n    x ~ Normal(mean = 0.0, var = 1.0)\n    w ~ InverseGamma(α = 1, θ = 1)\n    y ~ Normal(mean = x, var = w)\nend","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"Debugging & Visualization: RxInfer.jl does provide a mechanism to debug the inference procedure and visualise the graph structure, even though not as seamlessly as some other packages.","category":"page"},{"location":"manuals/comparison/","page":"RxInfer.jl vs. Others","title":"RxInfer.jl vs. Others","text":"","category":"page"},{"location":"manuals/sharpbits/rule-not-found/#rule-not-found","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"","category":"section"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"When using RxInfer, you might encounter a RuleNotFoundError. This error occurs during message-passing inference when the system cannot find appropriate update rules for computing messages between nodes in your factor graph. Let's understand why this happens and how to resolve it.","category":"page"},{"location":"manuals/sharpbits/rule-not-found/#Why-does-this-happen?","page":"Rule Not Found Error","title":"Why does this happen?","text":"","category":"section"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"Message-passing inference works by exchanging messages between nodes in a factor graph. Each message represents a probability distribution, and the rules for computing these messages depend on:","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"The type of the factor node (e.g., Normal, Gamma, etc.)\nThe types of incoming messages (e.g., Normal, PointMass, etc.) \nThe interface through which the message is being computed\nThe inference method being used (Belief Propagation or Variational Message Passing)","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"The last point is particularly important - some message update rules may exist for Variational Message Passing (VMP) but not for Belief Propagation (BP), or vice versa. This is because BP aims to compute exact posterior distributions through message passing (when possible), while VMP approximates the posterior using the Bethe approximation. For a detailed mathematical treatment of these differences, see our Bethe Free Energy implementation guide.","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"For example, consider this simple model:","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"@model function problematic_model()\n    μ ~ Normal(mean = 0.0, variance = 1.0)\n    τ ~ Gamma(shape = 1.0, rate = 1.0)\n    y ~ Normal(mean = μ, precision = τ)\nend","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"This model will fail with a RuleNotFoundError because there are no belief propagation message passing update rules available for this combination of distributions - only variational message passing rules exist. Even though the model looks simple, the message passing rules needed for exact inference do not exist in closed form.","category":"page"},{"location":"manuals/sharpbits/rule-not-found/#Common-scenarios","page":"Rule Not Found Error","title":"Common scenarios","text":"","category":"section"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"You're likely to encounter this error when:","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"Using non-conjugate pairs of distributions (e.g., Beta prior with Normal likelihood with precision parameterization)\nWorking with custom distributions or factor nodes without defining all necessary update rules\nUsing complex transformations between variables that don't have defined message computations\nMixing different types of distributions in ways that don't have analytical solutions","category":"page"},{"location":"manuals/sharpbits/rule-not-found/#Design-Philosophy","page":"Rule Not Found Error","title":"Design Philosophy","text":"","category":"section"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"RxInfer prioritizes performance over generality in its message-passing implementation. By default, it only uses analytically derived message update rules, even in cases where numerical approximations might be possible. This design choice:","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"Ensures fast and reliable inference when rules exist\nAvoids potential numerical instabilities from approximations\nThrows an error when analytical solutions don't exist","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"This means you may encounter RuleNotFoundError even in cases where approximate solutions could theoretically work. This is intentional - RxInfer will tell you explicitly when you need to consider alternative approaches rather than silently falling back to potentially slower or less reliable approximations. See the Solutions section below for more details.","category":"page"},{"location":"manuals/sharpbits/rule-not-found/#Visualizing-the-message-passing-graph","page":"Rule Not Found Error","title":"Visualizing the message passing graph","text":"","category":"section"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"To better understand where message passing rules are needed, let's look at a simple factor graph visualization:","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"graph LR\n    %% Other parts of the graph\n    g1[g] -.-> x\n    h1[h] -.-> z\n    y -.-> g2[p]\n    \n    %% Main focus area\n    x((x)) -.- m1[[\"μ<sub>x→f</sub>\"]] --> f[f]\n    f --> m2[[\"μ<sub>f→y</sub>\"]] -.- y((y))\n    z((z)) -.- m3[[\"μ<sub>z→f</sub>\"]] --> f\n\n    %% Styling\n    classDef variable fill:#b3e0ff,stroke:#333,stroke-width:2px;\n    classDef factor fill:#ff9999,stroke:#333,stroke-width:2px,shape:square;\n    classDef otherFactor fill:#ff9999,stroke:#333,stroke-width:2px,opacity:0.3;\n    classDef message fill:none,stroke:none;\n    class x,y,z variable;\n    class f factor;\n    class g1,g2,h1 otherFactor;\n    class m1,m2,m3 message;","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"In this example:","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"Variables (x, y, z) are represented as circles\nThe factor node (f) is represented as a square\nMessages (μ) flow along the edges between variables and factors, with subscripts indicating direction (e.g., x→f flows from x to f)\nFaded nodes (g, h) represent other parts of the factor graph that aren't relevant for this local message computation","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"To compute the outgoing message f→y, RxInfer needs:","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"Rules for how to process incoming messages x→f and z→f\nRules for combining these messages based on the factor f's type\nRules for producing the outgoing message type that y expects","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"A RuleNotFoundError occurs when any of these rules are missing. For example, if x sends a Normal message but f doesn't know how to process Normal inputs, or if f can't produce the type of message that y expects.","category":"page"},{"location":"manuals/sharpbits/rule-not-found/#rule-not-found-solutions","page":"Rule Not Found Error","title":"Solutions","text":"","category":"section"},{"location":"manuals/sharpbits/rule-not-found/#1.-Convert-to-conjugate-pairs","page":"Rule Not Found Error","title":"1. Convert to conjugate pairs","text":"","category":"section"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"First, try to reformulate your model using conjugate prior-likelihood pairs. Conjugate pairs have analytical solutions for message passing and are well-supported in RxInfer. For example, instead of using a Normal likelihood with Beta prior on its precision, use a Normal-Gamma conjugate pair. See Conjugate prior - Wikipedia for a comprehensive list of conjugate distributions.","category":"page"},{"location":"manuals/sharpbits/rule-not-found/#2.-Check-available-rules","page":"Rule Not Found Error","title":"2. Check available rules","text":"","category":"section"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"If conjugate pairs aren't suitable, verify if your combination of distributions and message types is supported. RxInfer provides many predefined rules, but not all combinations are possible. A good starting point is to check the List of available nodes section in the documentation of ReactiveMP.jl.","category":"page"},{"location":"manuals/sharpbits/rule-not-found/#3.-Create-custom-update-rules","page":"Rule Not Found Error","title":"3. Create custom update rules","text":"","category":"section"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"If you need specific message computations, you can define your own update rules. See Creating your own custom nodes for a detailed guide on implementing custom nodes and their update rules.","category":"page"},{"location":"manuals/sharpbits/rule-not-found/#4.-Use-approximations","page":"Rule Not Found Error","title":"4. Use approximations","text":"","category":"section"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"When exact message updates aren't available, consider:","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"Using simpler distribution pairs that have defined rules\nEmploying approximation techniques like moment matching or the methods described in Meta Specification and Deterministic nodes","category":"page"},{"location":"manuals/sharpbits/rule-not-found/#5.-Use-variational-inference","page":"Rule Not Found Error","title":"5. Use variational inference","text":"","category":"section"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"Sometimes, adding appropriate factorization constraints can help avoid problematic message computations:","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"constraints = @constraints begin\n    q(μ, τ) = q(μ)q(τ)  # Mean-field assumption\nend\n\nresult = infer(\n    model = problematic_model(),\n    constraints = constraints,\n)","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"note: Note\nWhen using variational constraints, you will likely need to initialize certain messages or marginals to handle loops in the factor graph. See Initialization for details on how to properly initialize your model.","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"For more details on constraints and variational inference, see:","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"Constraints Specification for a complete guide on using constraints\nBethe Free Energy for the mathematical background on variational inference and message passing","category":"page"},{"location":"manuals/sharpbits/rule-not-found/#Implementation-details","page":"Rule Not Found Error","title":"Implementation details","text":"","category":"section"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"When RxInfer encounters a missing rule, it means one of these is missing:","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"A @rule definition for the specific message direction and types\nA @marginalrule for computing joint marginals\nAn @average_energy implementation for free energy computation","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"You can add these using the methods described in Creating your own custom nodes.","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"note: Note\nNot all message-passing rules have analytical solutions. In such cases, you might need to use numerical approximations or choose different model structures.","category":"page"},{"location":"manuals/sharpbits/rule-not-found/","page":"Rule Not Found Error","title":"Rule Not Found Error","text":"","category":"page"},{"location":"manuals/migration-guide-v2-v3/#Migration-Guide-from-version-2.x-to-3.x","page":"Migration from v2 to v3","title":"Migration Guide from version 2.x to 3.x","text":"","category":"section"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"This guide is intended to help you migrate your project from version 2.x to 3.x of RxInfer. The main difference between these two versions is the redefinition of the model specification language. A detailed explanation of the new model definition language can be found in the GraphPPL documentation. Here, we will give an overview of the most important changes and introduce RxInfer specific changes.","category":"page"},{"location":"manuals/migration-guide-v2-v3/#Model-specification","page":"Migration from v2 to v3","title":"Model specification","text":"","category":"section"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"Also read the Model specification guide.","category":"page"},{"location":"manuals/migration-guide-v2-v3/#randomvar,-datavar-and-constvar-have-been-removed","page":"Migration from v2 to v3","title":"randomvar, datavar and constvar have been removed","text":"","category":"section"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"The most notable change in the model specification is the removal of the randomvar, datavar, and constvar functions. Now, the @model macro automatically determines whether to use randomvar or constvar based on their usage. Previously declared datavar variables must now be listed in the argument list of the model.","category":"page"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"The following example is a simple model definition in previous version:","category":"page"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"@model function SSM(n, x0, A, B, Q, P) \n    x = randomvar(n) \n    y = datavar(Vector{Float64}, n) \n    x_prior ~ MvNormal(μ = mean(x0), Σ = cov(x0)) \n    x_prev = x_prior \n    for i in 1:n \n        x[i] ~ MvNormal(μ = A * x_prev, Σ = Q) \n        y[i] ~ MvNormal(μ = B * x[i], Σ = P) \n        x_prev = x[i] \n    end \nend ","category":"page"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"The equivalent model definition in the new version is as follows:","category":"page"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"@model function SSM(y, prior_x, A, B, Q, P) \n    x_prev ~ prior_x\n    for i in eachindex(y)\n        x[i] ~ MvNormal(μ = A * x_prev, Σ = Q) \n        y[i] ~ MvNormal(μ = B * x[i], Σ = P) \n        x_prev = x[i]\n    end\nend","category":"page"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"Read more about the change in the GraphPPL documentation and  in the updated Model specification guide.","category":"page"},{"location":"manuals/migration-guide-v2-v3/#Positional-arguments-are-converted-to-keyword-arguments","page":"Migration from v2 to v3","title":"Positional arguments are converted to keyword arguments","text":"","category":"section"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"The changes in the model specification also have implications for the infer function. Since all interfaces to a model are now passed as arguments to the @model macro, the infer function needs additional information on model construction. Therefore, the model function definition converts all positional arguments to keyword arguments. Positional arguments are no longer supported in the model function definition. Below is an example of the new model definition:","category":"page"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"using Test #hide\nusing RxInfer\n\n@model function coin_toss(prior, y)\n    θ ~ prior\n    y .~ Bernoulli(θ)\nend\n\n# Here, we pass a prior as a parameter to the model, and the data `y` is passed as data. \n# Since we have to distinguish between what should be used as which argument, we have to pass the data as a keyword argument.\ninfer(\n    model = coin_toss(prior = Beta(1, 1)), \n    data  = (y = [1, 0, 1],) \n)","category":"page"},{"location":"manuals/migration-guide-v2-v3/#Multiple-dispatch-is-no-longer-supported","page":"Migration from v2 to v3","title":"Multiple dispatch is no longer supported","text":"","category":"section"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"Due to the previous change, it is not possible to use multiple dispatch for model function definitions. In other words, type constraints for model arguments are ignored because Julia does not support multiple dispatch for keyword arguments.","category":"page"},{"location":"manuals/migration-guide-v2-v3/#Return-value-from-the-model-function","page":"Migration from v2 to v3","title":"Return value from the model function","text":"","category":"section"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"Accessing the return value of the model function has changed. Previously, the return value was returned together with the model upon creation. Now, the return value is saved in the model's data structure, which can be accessed with the RxInfer.getreturnval function. To demonstrate the difference, previously we could do the following:","category":"page"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"@model function test_model(a, b)\n    y = datavar(Float64)\n    θ ~ Beta(1.0, 1.0)\n    y ~ Bernoulli(θ)\n    return \"Hello, world!\"\nend\nmodelgenerator = test_model(1.0, 1.0)\nmodel, returnval = RxInfer.create_model(modelgenerator)\nreturnval # \"Hello, world!\"","category":"page"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"The new API is changed to:","category":"page"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"@model function test_model(y, a, b) #hide\n    θ ~ Beta(1.0, 1.0) #hide\n    y ~ Bernoulli(θ) #hide\n    return \"Hello, world!\" #hide\nend #hide\nmodelgenerator = test_model(a = 1.0, b = 1.0) | (y = 1, )\nmodel = RxInfer.create_model(modelgenerator)\n@test RxInfer.getreturnval(model) == \"Hello, world!\" #hide\nRxInfer.getreturnval(model)","category":"page"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"The InferenceResult  also no longer stores the returnval field. Instead, use the model field and the RxInfer.getreturnval function:","category":"page"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"result = infer(\n    model = test_model(a = 1.0, b = 1.0),\n    data  = (y = 1, )\n)\n@test RxInfer.getreturnval(result.model) == \"Hello, world!\" #hide\nRxInfer.getreturnval(result.model)","category":"page"},{"location":"manuals/migration-guide-v2-v3/#Returning-variables-from-the-model","page":"Migration from v2 to v3","title":"Returning variables from the model","text":"","category":"section"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"Similar to the previous version, you can still return latent variables from the model definition:","category":"page"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"@model function test_model(y, a, b)\n    θ ~ Beta(1.0, 1.0)\n    y ~ Bernoulli(θ)\n    return θ\nend","category":"page"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"However, their type has changed to internal data structures from the GraphPPL package. To access the ReactiveMP data structures (e.g., to retrieve the messages or marginals streams), use RxInfer.getvarref along with RxInfer.getvariable:","category":"page"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"using ReactiveMP, Rocket\nresult = infer(\n    model = test_model(a = 1.0, b = 1.0),\n    data  = (y = 1, )\n)\n\nθlabel  = RxInfer.getreturnval(result.model)\nθvarref = RxInfer.getvarref(result.model, θlabel)\nθvar    = RxInfer.getvariable(θvarref)\n@test θvar isa ReactiveMP.RandomVariable #hide\nqθ_test = [] #hide\nsubscribe!(ReactiveMP.getmarginal(θvar) |> take(1), (qθ) -> push!(qθ_test, qθ)) #hide\n@test length(qθ_test) === 1 #hide\n@test first(ReactiveMP.getdata(qθ_test)) == Beta(2.0, 1.0) #hide\n\n# `|> take(1)` ensures automatic unsubscription \nθmarginals_subscription = subscribe!(ReactiveMP.getmarginal(θvar) |> take(1), (qθ) -> println(qθ))\nnothing #hide","category":"page"},{"location":"manuals/migration-guide-v2-v3/#Initialization","page":"Migration from v2 to v3","title":"Initialization","text":"","category":"section"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"Initialization of messages and marginals to kickstart the inference procedure was previously done with the initmessages and initmarginals keyword. With the introduction of a nested model specificiation in the @model macro, we now need a more specific way to initialize messages and marginals. This is done with the new @initialization macro.  Read more about the new syntax in the Initialization guide.","category":"page"},{"location":"manuals/migration-guide-v2-v3/","page":"Migration from v2 to v3","title":"Migration from v2 to v3","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = RxInfer","category":"page"},{"location":"","page":"Home","title":"Home","text":"<div class=\"light-biglogo\">","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: RxInfer Logo)","category":"page"},{"location":"","page":"Home","title":"Home","text":"</div>","category":"page"},{"location":"","page":"Home","title":"Home","text":"<div class=\"dark-biglogo\">","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: RxInfer Logo)","category":"page"},{"location":"","page":"Home","title":"Home","text":"</div>","category":"page"},{"location":"","page":"Home","title":"Home","text":"Julia package for automatic Bayesian inference on a factor graph with reactive message passing.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Given a probabilistic model, RxInfer allows for an efficient message-passing based Bayesian inference. It uses the model structure to generate an algorithm that consists of a sequence of local computations on a factor graph representation of the model. RxInfer.jl has been designed with a focus on efficiency, scalability and maximum performance for running inference with reactive message passing.","category":"page"},{"location":"#Why-RxInfer","page":"Home","title":"Why RxInfer","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Many important AI applications, including audio processing, self-driving vehicles, weather forecasting, and extended-reality video processing require continually solving an inference task in sophisticated probabilistic models with a large number of latent variables. Often, the inference task in these applications must be performed continually and in real-time in response to new observations.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Popular MC-based inference methods, such as the No U-Turn Sampler (NUTS) or Hamiltonian Monte Carlo (HMC) sampling, rely on computationally heavy sampling procedures that do not scale well to probabilistic models with thousands of latent states. Therefore, while MC-based inference is an very versatile tool, it is practically not suitable for real-time applications. While the alternative variational inference method (VI) promises to scale better to large models than sampling-based inference, VI requires the derivation of gradients of a \"Variational Free Energy\" cost function. For large models, manual derivation of these gradients might not be feasible, while automated \"black-box\" gradient methods do not scale either because they are not capable of taking advantage of sparsity or conjugate pairs in the model. Therefore, while Bayesian inference is known as the optimal data processing framework, in practice, real-time AI applications rely on much simpler, often ad hoc, data processing algorithms.","category":"page"},{"location":"","page":"Home","title":"Home","text":"RxInfer aims to remedy these issues by running efficient Bayesian inference in sophisticated probabilistic models, taking advantage of local conjugate relationships in probabilistic models, and focusing on real-time Bayesian inference in large state-space models with thousands of latent variables. In addition, RxInfer provides a straightforward way to extend its functionality with custom factor nodes and message passing update rules. The engine is capable of running various Bayesian inference algorithms in different parts of the factor graph of a single probabilistic model. This makes it easier to explore different \"what-if\" scenarios and enables very efficient inference in specific cases.","category":"page"},{"location":"#Package-Features","page":"Home","title":"Package Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"User friendly syntax for specification of probabilistic models, achieved with GraphPPL.\nSupport for hybrid models combining discrete and continuous latent variables.\nFactorization and functional form constraints specification.\nGraph visualisation and extensions with different custom plugins.\nSaving graph on a disk and re-loading it later on.\nAutomatic generation of message passing algorithms, achieved with ReactiveMP.\nSupport for hybrid distinct message passing inference algorithm under a unified paradigm.\nEvaluation of Bethe Free Energy as a model performance measure.\nSchedule-free reactive message passing API.\nScalability for large models with millions of parameters and observations.\nHigh performance.\nInference procedure is differentiable.\nEasy to extend with custom nodes and message update rules.\nCommunity-driven development and support\nRegular public meetings to discuss usage patterns and improvements\nActive community support through GitHub discussions\nOptional telemetry to help guide development (see Usage Telemetry)\nSession sharing for better debugging support (see Session Sharing)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Curious about how RxInfer compares to other tools you might be considering? We invite you to view a detailed comparison, where we put RxInfer head-to-head with other popular packages in the field.","category":"page"},{"location":"#How-to-get-started?","page":"Home","title":"How to get started?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Head to the Getting started section to get up and running with RxInfer. Alternatively, explore various examples in the documentation.","category":"page"},{"location":"#Table-of-Contents","page":"Home","title":"Table of Contents","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\n  \"manuals/comparison.md\",\n  \"manuals/getting-started.md\",\n  \"manuals/model-specification.md\",\n  \"manuals/constraints-specification.md\",\n  \"manuals/meta-specification.md\",\n  \"manuals/inference-execution.md\",\n  \"manuals/custom-node.md\",\n  \"manuals/debugging.md\",\n  \"manuals/delta-node.md\",\n  \"examples/overview.md\",\n  \"library/functional-forms.md\",\n  \"library/bethe-free-energy.md\",\n  \"library/model-construction.md\",\n  \"library/exported-methods.md\",\n  \"contributing/overview.md\",\n  \"contributing/new-example.md\"\n]\nDepth = 2","category":"page"},{"location":"#References","page":"Home","title":"References","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"RxInfer: A Julia package for reactive real-time Bayesian inference - a reference paper for the RxInfer.jl framwork.\nReactive Probabilistic Programming for Scalable Bayesian Inference - a PhD dissertation outlining core ideas and principles behind RxInfer (link2, link3).\nVariational Message Passing and Local Constraint Manipulation in Factor Graphs - describes theoretical aspects of the underlying Bayesian inference method.\nReactive Message Passing for Scalable Bayesian Inference - describes implementation aspects of the Bayesian inference engine and performs benchmarks and accuracy comparison on various models.\nA Julia package for reactive variational Bayesian inference - a reference paper for the ReactiveMP.jl package, the underlying inference engine.\nThe Factor Graph Approach to Model-Based Signal Processing - an introduction to message passing and FFGs.","category":"page"},{"location":"#Ecosystem","page":"Home","title":"Ecosystem","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The RxInfer is a part of the ReactiveBayes ecosystem unites 3 core packages into one powerful reactive message passing-based Bayesian inference framework:","category":"page"},{"location":"","page":"Home","title":"Home","text":"ReactiveMP.jl - core package for efficient and scalable for reactive message passing \nGraphPPL.jl - package for model and constraints specification\nRocket.jl - reactive programming tools","category":"page"},{"location":"","page":"Home","title":"Home","text":"note: Note\nReactiveMP.jl engine is a successor of the ForneyLab package. It follows the same ideas and concepts for message-passing based inference, but uses new reactive and efficient message passing implementation under the hood. The API between two packages is different due to a better flexibility, performance and new reactive approach for solving inference problems.","category":"page"},{"location":"","page":"Home","title":"Home","text":"While these packages form the core, RxInfer relies on numerous other excellent open-source packages.  The developers of RxInfer express their deep appreciation to the entire open-source community for their tremendous efforts.","category":"page"},{"location":"#Index","page":"Home","title":"Index","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"library/bethe-free-energy/#lib-bethe-free-energy","page":"Bethe Free Energy","title":"Bethe Free Energy implementation in RxInfer","text":"","category":"section"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"The following text introduces the Bethe Free Energy. We start be defining a factorized model and move from the Variational Free Energy to a definition of the Bethe Free Energy.","category":"page"},{"location":"library/bethe-free-energy/#lib-bethe-factorized-model","page":"Bethe Free Energy","title":"Factorized model","text":"","category":"section"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"Before we can define a model, we must identify all variables that are relevant to the problem at hand. We distinguish between variables that can be directly observed, y = (y_1 dots y_j dots y_m) and variables that can not be observed directly, also known as latent variables, x = (x_1 dots x_i dots x_n) We then define a model that factorizes over consituent smaller factors (functions), as f(yx) = prod_a f_a(y_ax_a)","category":"page"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"Individual factors may represent stochastic functions, such as conditional or prior distributions, but also potential functions or deterministic relationships. A factor may depend on multiple observed and/or latent variables (or none).","category":"page"},{"location":"library/bethe-free-energy/#lib-bethe-vfe","page":"Bethe Free Energy","title":"Variational Free Energy","text":"","category":"section"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"The Variational Free Energy (VFE) then defines a functional objective that includes the model and a variational distribution over the latent variables, Fq(haty) = mathbbE_q(x)leftlog fracq(x)f(y=haty x) right A functional defines a function of a function that returns a scalar. Here, the VFE is a function of the variational distribution (as indicated by square brackets) and returns a number.","category":"page"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"The VFE is also a function of the observed data, as indicated by round brackets, where the data are substituted in the factorized model.","category":"page"},{"location":"library/bethe-free-energy/#lib-bethe-variational-inference","page":"Bethe Free Energy","title":"Variational inference","text":"","category":"section"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"The goal of variational inference is to find a variational distibution that minimizes the VFE, q^*(x) = argmin_qinmathcalQ Fq(haty) This objective can be optimized (under specific constraints) with the use of variational calculus. Constraints are implied by the domain over which the variational distribution is optimized, and can be enforced by Lagrange multipliers.","category":"page"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"For the VFE, constraints enforce e.g. the normalization of the variational distribution. The variational distribution that minimizes the VFE then approximates the true (but often unobtainable) posterior distribution.","category":"page"},{"location":"library/bethe-free-energy/#lib-bethe-approximation","page":"Bethe Free Energy","title":"Bethe approximation","text":"","category":"section"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"Optimization of the VFE is still a daunting task, because the variational distribution is a joint distribution over possibly many latent variables. Instead of optimizing the joint variational distribution directly, a factorized variational distribution is often chosen. The factorized variational distribution is then optimized for its constituent factors.","category":"page"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"A popular choice of factorization is the Bethe approximation, which is constructed from the factorization of the model itself, q(x) triangleq fracprod_a q_a(x_a)prod_i q_i(x_i)^d_i - 1 The numerator iterates over the factors in the model, and carves the joint variational distribution in smaller variational distributions that are more manageable to optimize.","category":"page"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"The denominator of the Bethe approximation iterates over all individual latent variables and discounts them. The discounting factor is chosen as the degree of the variable minus one, where the degree counts the number of factors in which the variable appears.","category":"page"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"The Bethe approximation thus constrains the variational distribution to a factorized form. However, the true posterior distribution might not factorize in this way, e.g. if the grapical representation of the model contains cycles. In these cases the Bethe approximation trades the exact solution for computational tractability.","category":"page"},{"location":"library/bethe-free-energy/#lib-bethe-bfe","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"","category":"section"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"The Bethe Free Energy (BFE) substitutes the Bethe approximation in the VFE, which then fragments over factors and variables, as F_Bq(haty) = sum_a U_aq_a(haty_a) - sum_a Hq_a + sum_i (d_i - 1) Hq_i The first term of the BFE specifies an average energy,  U_aq_a(haty_a) = -mathbbE_q_a(x_a)leftlog f_a(y_a=haty_a x_a)right which internalizes the factors of the  model. The last two terms specify entropies.","category":"page"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"Crucially, the BFE can be iteratively optimized for each individual variational distribution in turn. Optimization of the BFE is thus more manageable than direct optimization of the VFE.","category":"page"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"For iterative optimization of the BFE, the variational distributions must first be initialized. The infer function uses the initialization keyword argument to initialize the variational distributions of the BFE.","category":"page"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"For disambiguation, note that the initialization of the variational distribution is a different design consideration than the choice of priors. A prior specifies a factor in the model definition, while initialization concerns factors in the variational distribution.","category":"page"},{"location":"library/bethe-free-energy/#lib-bethe-further-reading","page":"Bethe Free Energy","title":"Further reading","text":"","category":"section"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"Pearl (1986) on the original foundations of Bayesian networks and belief propagation;\nYedidia et al. (2005) on the connections between belief propagation and regional approximations to the VFE;\nDauwels (2007) on variational message passing on Forney-style factor graphs (FFGs);\nSenoz et al. (2021) on constraint manipulation and message passing on FFGs.","category":"page"},{"location":"library/bethe-free-energy/#Implementation-details","page":"Bethe Free Energy","title":"Implementation details","text":"","category":"section"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"RxInfer implements Bethe Free Energy optimization in an implicit way via the mesasge passing technique. That means that the inference engine does not compute BFE values explicitly,  unless specified explicitly. The infer function has free_energy flag, which indicates whether BFE values must be computed explicitly or not. Note, however, that due to the reactive nature of the message passing implementation in RxInfer the computed BFE value may not represent its actual state. This may happen when updates for certain posteriors arriving more often than updates for other posteriors and usually tend to happen in models with loops in its structure. To circumvent this, instead of checking if BFE value is being minimized it is advised to check if it converges.","category":"page"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"RxInfer.BetheFreeEnergy\nRxInfer.BetheFreeEnergyDefaultMarginalSkipStrategy\nRxInfer.BetheFreeEnergyDefaultScheduler\nRxInfer.ReactiveMPFreeEnergyPlugin","category":"page"},{"location":"library/bethe-free-energy/#RxInfer.BetheFreeEnergy","page":"Bethe Free Energy","title":"RxInfer.BetheFreeEnergy","text":"BetheFreeEnergy(skip_strategy, scheduler)\n\nImplements a reactive stream for Bethe Free Energy values.  Must be used in combination with the score function of ReactiveMP.jl. \n\nArguments\n\n::Type{T}: a type of the counting real number, e.g. Float64. Set to Real by default, otherwise the inference procedure is not automatically differentiable.\nskip_strategy: a strategy that defines which posterior marginals to skip, e.g. SkipInitial().\nscheduler: a scheduler for the underlying stream, e.g. AsapScheduler().\n\n\n\n\n\n","category":"type"},{"location":"library/bethe-free-energy/#RxInfer.BetheFreeEnergyDefaultMarginalSkipStrategy","page":"Bethe Free Energy","title":"RxInfer.BetheFreeEnergyDefaultMarginalSkipStrategy","text":"Default marginal skip strategy for the Bethe Free Energy objective. \n\n\n\n\n\n","category":"constant"},{"location":"library/bethe-free-energy/#RxInfer.BetheFreeEnergyDefaultScheduler","page":"Bethe Free Energy","title":"RxInfer.BetheFreeEnergyDefaultScheduler","text":"Default scheduler for the Bethe Free Energy objective.\n\n\n\n\n\n","category":"constant"},{"location":"library/bethe-free-energy/#RxInfer.ReactiveMPFreeEnergyPlugin","page":"Bethe Free Energy","title":"RxInfer.ReactiveMPFreeEnergyPlugin","text":"A plugin for GraphPPL graph engine that adds the Bethe Free Energy objective computation to the nodes of the model.\n\n\n\n\n\n","category":"type"},{"location":"library/bethe-free-energy/#Extra-diagnostic-checks","page":"Bethe Free Energy","title":"Extra diagnostic checks","text":"","category":"section"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"RxInfer verifies intermediate computations of BFE on each iteration. By default, RxInfer will throw an exception, if local factor node or variable node computations result in either NaN or Inf. Note, that the verification happens only if the computation of BFE has been requested explicitly.","category":"page"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"RxInfer.apply_diagnostic_check\nRxInfer.ObjectiveDiagnosticCheckNaNs\nRxInfer.ObjectiveDiagnosticCheckInfs\nRxInfer.DefaultObjectiveDiagnosticChecks","category":"page"},{"location":"library/bethe-free-energy/#RxInfer.apply_diagnostic_check","page":"Bethe Free Energy","title":"RxInfer.apply_diagnostic_check","text":"apply_diagnostic_check(check, stream)\n\nThis function applies a check to the stream. Does nothing if check is of type Nothing. \n\n\n\n\n\n","category":"function"},{"location":"library/bethe-free-energy/#RxInfer.ObjectiveDiagnosticCheckNaNs","page":"Bethe Free Energy","title":"RxInfer.ObjectiveDiagnosticCheckNaNs","text":"ObjectiveDiagnosticCheckNaNs\n\nIf enabled checks that both variable and factor bound score functions in the objective computation do not return NaNs.  Throws an error if finds NaN. \n\n\n\n\n\n","category":"type"},{"location":"library/bethe-free-energy/#RxInfer.ObjectiveDiagnosticCheckInfs","page":"Bethe Free Energy","title":"RxInfer.ObjectiveDiagnosticCheckInfs","text":"ObjectiveDiagnosticCheckInfs\n\nIf enabled checks that both variable and factor bound score functions in the objective computation do not return Infs.  Throws an error if finds Inf. \n\n\n\n\n\n","category":"type"},{"location":"library/bethe-free-energy/#RxInfer.DefaultObjectiveDiagnosticChecks","page":"Bethe Free Energy","title":"RxInfer.DefaultObjectiveDiagnosticChecks","text":"const DefaultObjectiveDiagnosticChecks = (ObjectiveDiagnosticCheckNaNs(), ObjectiveDiagnosticCheckInfs())\n\nA constant that defines the default objective diagnostic checks.\n\n\n\n\n\n","category":"constant"},{"location":"library/bethe-free-energy/","page":"Bethe Free Energy","title":"Bethe Free Energy","text":"","category":"page"},{"location":"manuals/inference/delta-node/#delta-node-manual","page":"Deterministic nodes","title":"Deterministic nodes","text":"","category":"section"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"RxInfer.jl offers a comprehensive set of stochastic nodes, primarily emphasizing distributions from the exponential family and related compositions, such as Gaussian with controlled variance (GCV) or autoregressive (AR) nodes. The DeltaNode stands out in this package, representing a deterministic transformation of either a single random variable or a group of them. This guide provides insights into the DeltaNode and its functionalities.","category":"page"},{"location":"manuals/inference/delta-node/#Features-and-Supported-Inference-Scenarios","page":"Deterministic nodes","title":"Features and Supported Inference Scenarios","text":"","category":"section"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"The delta node supports several approximation methods for probabilistic inference. The desired approximation method depends on the nodes connected to the delta node. We differentiate the following deterministic transformation scenarios:","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"Gaussian Nodes: For delta nodes linked to strictly multivariate or univariate Gaussian distributions, the recommended methods are Linearization or Unscented transforms.\nExponential Family Nodes: For the delta node connected to nodes from the exponential family, the CVIProjection (Conjugate Variational Inference) is the method of choice.\nStacking Delta Nodes: For scenarios where delta nodes are stacked, either Linearization, Unscented or CVIProjection are suitable.\nSupport for Inverse Functions: For scenarious, where an inverse function is available","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"The table below summarizes the features of the delta node in RxInfer.jl, categorized by the approximation method:","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"Methods Gaussian Nodes Exponential Family Nodes Stacking Delta Nodes Inverse functions\nLinearization ✓ ✗ ✓ ✓\nUnscented ✓ ✗ ✓ ✓\nCVI (deprecated) ✓ ✓ ✗ ✗\nCVI Projection ✓ ✓ ✓ ✗","category":"page"},{"location":"manuals/inference/delta-node/#Gaussian-Case","page":"Deterministic nodes","title":"Gaussian Case","text":"","category":"section"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"In the context of Gaussian distributions, we recommend either the Linearization or Unscented method for delta node approximation. The Linearization method provides a first-order approximation, while the Unscented method delivers a more precise second-order approximation. It's worth noting that while the Unscented method is more accurate, it may require hyperparameters tuning. In addition, both methods are working well when the function is differentiable. The results may not be accurate if the function is not differentiable.","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"For clarity, consider the following example:","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"using RxInfer\n\n@model function delta_node_example(z)\n    x  ~ Normal(mean = 0.0, var = 1.0)\n    y := tanh(x)\n    z  ~ Normal(mean = y, var = 1.0)\nend","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"note: Note\nWhile not strictly required, it is advised to use := to define a deterministic relationship within the @model macro.","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"To perform inference on this model, designate the approximation method for the delta node (here, the tanh function) using the @meta specification:","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"delta_meta = @meta begin \n    tanh() -> Linearization()\nend","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"or","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"delta_meta = @meta begin \n    tanh() -> Unscented()\nend","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"For a deeper understanding of the Unscented method and its parameters, consult the docstrings.","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"Given the invertibility of tanh, indicating its inverse function can optimize the inference procedure:","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"delta_meta = @meta begin \n    tanh() -> DeltaMeta(method = Linearization(), inverse = atanh)\nend","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"To execute the inference procedure:","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"result = infer(\n    model = delta_node_example(), \n    meta  = delta_meta, \n    data = (z = 1.0,)\n)","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"This methodology is consistent even when the delta node is associated with multiple inputs. For instance:","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"f(x, g) = x*tanh(g)","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"@model function delta_node_example(z)\n    x ~ Normal(mean = 1.0, var = 1.0)\n    g ~ Normal(mean = 1.0, var = 1.0)\n    y := f(x, g)\n    z ~ Normal(mean = y, var = 0.1)\nend","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"The corresponding meta specification is:","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"delta_meta = @meta begin \n    f() -> DeltaMeta(method = Linearization())\nend","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"or simply","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"delta_meta = @meta begin \n    f() -> Linearization()\nend","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"If specific functions outline the backward relation of variables within the f function, you can provide a tuple of inverse functions in the order of the variables:","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"f_back_x(out, g) = out/tanh(g)\nf_back_g(out, x) = atanh(out/x)","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"delta_meta = @meta begin \n    f() -> DeltaMeta(method = Linearization(), inverse=(f_back_x, f_back_g))\nend","category":"page"},{"location":"manuals/inference/delta-node/#Exponential-Family-Case","page":"Deterministic nodes","title":"Exponential Family Case","text":"","category":"section"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"When the delta node is associated with nodes from the exponential family (excluding Gaussians), the Linearization and Unscented methods are not applicable. In such cases, the CVI (Conjugate Variational Inference) is available. Here's a modified example:","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"note: Note\nThe CVIProjection method is available only if ExponentialFamilyProjection package is installed in the current environment.","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"using RxInfer, ExponentialFamilyProjection\n\n@model function delta_node_example1(z)\n    x ~ Gamma(shape = 1.0, rate = 1.0)\n    y := tanh(x)\n    z ~ Bernoulli(y)\nend","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"The corresponding meta specification can be represented as:","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"delta_meta = @meta begin \n    tanh() -> CVIProjection()\nend","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"Consult the CVIProjection docstrings for a detailed explanation of its hyper-parameters. Additionally, read the Non-conjugate Inference section.","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"note: Note\nThe CVIProjection method is an improved version of the now-deprecated CVI method. This new implementation features different hyperparameters, better accuracy, and improved stability.","category":"page"},{"location":"manuals/inference/delta-node/#Fuse-deterministic-nodes-with-stochastic-nodes","page":"Deterministic nodes","title":"Fuse deterministic nodes with stochastic nodes","text":"","category":"section"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"Read how to circumvent the need to define the meta structure and, instead, fuse the deterministic relation with a neighboring stochastic factor node in this section.","category":"page"},{"location":"manuals/inference/delta-node/","page":"Deterministic nodes","title":"Deterministic nodes","text":"","category":"page"}]
}

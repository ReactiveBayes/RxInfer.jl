<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Advanced Tutorial · RxInfer.jl</title><meta name="title" content="Advanced Tutorial · RxInfer.jl"/><meta property="og:title" content="Advanced Tutorial · RxInfer.jl"/><meta property="twitter:title" content="Advanced Tutorial · RxInfer.jl"/><meta name="description" content="Julia package for automated Bayesian inference on a factor graph with reactive message passing"/><meta property="og:description" content="Julia package for automated Bayesian inference on a factor graph with reactive message passing"/><meta property="twitter:description" content="Julia package for automated Bayesian inference on a factor graph with reactive message passing"/><meta property="og:url" content="https://reactivebayes.github.io/RxInfer.jl/examples/advanced_examples/Advanced Tutorial/"/><meta property="twitter:url" content="https://reactivebayes.github.io/RxInfer.jl/examples/advanced_examples/Advanced Tutorial/"/><link rel="canonical" href="https://reactivebayes.github.io/RxInfer.jl/examples/advanced_examples/Advanced Tutorial/"/><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/theme.css" rel="stylesheet" type="text/css"/><link href="../../../assets/header.css" rel="stylesheet" type="text/css"/><script src="../../../assets/header.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img class="docs-light-only" src="../../../assets/logo.svg" alt="RxInfer.jl logo"/><img class="docs-dark-only" src="../../../assets/logo-dark.svg" alt="RxInfer.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">RxInfer.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><span class="tocitem">User guide</span><ul><li><a class="tocitem" href="../../../manuals/getting-started/">Getting started</a></li><li><a class="tocitem" href="../../../manuals/comparison/">RxInfer.jl vs. Others</a></li><li><a class="tocitem" href="../../../manuals/model-specification/">Model specification</a></li><li><a class="tocitem" href="../../../manuals/constraints-specification/">Constraints specification</a></li><li><a class="tocitem" href="../../../manuals/meta-specification/">Meta specification</a></li><li><input class="collapse-toggle" id="menuitem-2-6" type="checkbox"/><label class="tocitem" for="menuitem-2-6"><span class="docs-label">Inference specification</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../manuals/inference/overview/">Overview</a></li><li><a class="tocitem" href="../../../manuals/inference/static/">Static inference</a></li><li><a class="tocitem" href="../../../manuals/inference/streamlined/">Streamline inference</a></li><li><a class="tocitem" href="../../../manuals/inference/initialization/">Initialization</a></li><li><a class="tocitem" href="../../../manuals/inference/autoupdates/">Auto-updates</a></li><li><a class="tocitem" href="../../../manuals/inference/delta-node/">Deterministic nodes</a></li><li><a class="tocitem" href="../../../manuals/inference/nonconjugate/">Non-conjugate inference</a></li><li><a class="tocitem" href="../../../manuals/inference/undefinedrules/">Undefined message update rules</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-7" type="checkbox"/><label class="tocitem" for="menuitem-2-7"><span class="docs-label">Inference customization</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../manuals/customization/custom-node/">Defining a custom node and rules</a></li><li><a class="tocitem" href="../../../manuals/customization/postprocess/">Inference results postprocessing</a></li></ul></li><li><a class="tocitem" href="../../../manuals/debugging/">Debugging</a></li><li><a class="tocitem" href="../../../manuals/migration-guide-v2-v3/">Migration from v2 to v3</a></li></ul></li><li><span class="tocitem">Library</span><ul><li><a class="tocitem" href="../../../library/model-construction/">Model construction</a></li><li><a class="tocitem" href="../../../library/bethe-free-energy/">Bethe Free Energy</a></li><li><a class="tocitem" href="../../../library/functional-forms/">Functional form constraints</a></li><li><a class="tocitem" href="../../../library/exported-methods/">Exported methods</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../overview/">Overview</a></li><li><input class="collapse-toggle" id="menuitem-4-2" type="checkbox"/><label class="tocitem" for="menuitem-4-2"><span class="docs-label">Basic examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../basic_examples/overview/">Overview</a></li><li><a class="tocitem" href="../../basic_examples/Coin Toss Model/">Coin toss model (Beta-Bernoulli)</a></li><li><a class="tocitem" href="../../basic_examples/Bayesian Linear Regression Tutorial/">Bayesian Linear Regression Tutorial</a></li><li><a class="tocitem" href="../../basic_examples/Kalman filtering and smoothing/">Kalman filtering and smoothing</a></li><li><a class="tocitem" href="../../basic_examples/Predicting Bike Rental Demand/">Predicting Bike Rental Demand</a></li><li><a class="tocitem" href="../../basic_examples/Hidden Markov Model/">How to train your Hidden Markov Model</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox" checked/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Advanced examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../overview/">Overview</a></li><li><a class="tocitem" href="../Active Inference Mountain car/">Active Inference Mountain car</a></li><li class="is-active"><a class="tocitem" href>Advanced Tutorial</a><ul class="internal"><li><a class="tocitem" href="#General-model-specification-syntax"><span>General model specification syntax</span></a></li><li><a class="tocitem" href="#Probabilistic-inference-in-RxInfer.jl"><span>Probabilistic inference in RxInfer.jl</span></a></li><li><a class="tocitem" href="#Coin-Toss-Model"><span>Coin Toss Model</span></a></li><li><a class="tocitem" href="#Reactive-Online-Inference"><span>Reactive Online Inference</span></a></li><li><a class="tocitem" href="#Variational-inference"><span>Variational inference</span></a></li><li><a class="tocitem" href="#Creating-custom-nodes-and-message-computation-rules"><span>Creating custom nodes and message computation rules</span></a></li></ul></li><li><a class="tocitem" href="../Assessing People Skills/">Assessing People’s Skills</a></li><li><a class="tocitem" href="../Chance Constraints/">Chance-Constrained Active Inference</a></li><li><a class="tocitem" href="../Conjugate-Computational Variational Message Passing/">Conjugate-Computational Variational Message Passing (CVI)</a></li><li><a class="tocitem" href="../Global Parameter Optimisation/">Global Parameter Optimisation</a></li><li><a class="tocitem" href="../GP Regression by SSM/">Solve GP regression by SDE</a></li><li><a class="tocitem" href="../Infinite Data Stream/">Infinite Data Stream</a></li><li><a class="tocitem" href="../Nonlinear Sensor Fusion/">Nonlinear Sensor Fusion</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Problem specific</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../problem_specific/overview/">Overview</a></li><li><a class="tocitem" href="../../problem_specific/Autoregressive Models/">Autoregressive Models</a></li><li><a class="tocitem" href="../../problem_specific/Gamma Mixture/">Gamma Mixture Model</a></li><li><a class="tocitem" href="../../problem_specific/Gaussian Mixture/">Gaussian Mixture</a></li><li><a class="tocitem" href="../../problem_specific/Hierarchical Gaussian Filter/">Hierarchical Gaussian Filter</a></li><li><a class="tocitem" href="../../problem_specific/Invertible Neural Network Tutorial/">Invertible neural networks: a tutorial</a></li><li><a class="tocitem" href="../../problem_specific/Probit Model (EP)/">Probit Model (EP)</a></li><li><a class="tocitem" href="../../problem_specific/RTS vs BIFM Smoothing/">RTS vs BIFM Smoothing</a></li><li><a class="tocitem" href="../../problem_specific/Simple Nonlinear Node/">Simple Nonlinear Node</a></li><li><a class="tocitem" href="../../problem_specific/Universal Mixtures/">Universal Mixtures</a></li><li><a class="tocitem" href="../../problem_specific/Litter Model/">Litter Model</a></li></ul></li><li><a class="tocitem" href="../../../contributing/examples/">Contribute with examples</a></li></ul></li><li><span class="tocitem">Contributing</span><ul><li><a class="tocitem" href="../../../contributing/guide/">Contribution guide</a></li><li><a class="tocitem" href="../../../contributing/guidelines/">Contribution guidelines</a></li><li><a class="tocitem" href="../../../contributing/new-documentation/">Contributing to the documentation</a></li><li><a class="tocitem" href="../../../contributing/new-example/">Contributing to the examples</a></li><li><a class="tocitem" href="../../../contributing/new-release/">Publishing a new release</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li><a class="is-disabled">Advanced examples</a></li><li class="is-active"><a href>Advanced Tutorial</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Advanced Tutorial</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ReactiveBayes/RxInfer.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/ReactiveBayes/RxInfer.jl/blob/main/docs/src/examples/advanced_examples/Advanced Tutorial.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><p>This example has been auto-generated from the <a href="https://github.com/reactivebayes/RxInfer.jl/tree/main/examples"><code>examples/</code></a> folder at GitHub repository.</p><h1 id="examples-advanced-tutorial"><a class="docs-heading-anchor" href="#examples-advanced-tutorial">Advanced Tutorial</a><a id="examples-advanced-tutorial-1"></a><a class="docs-heading-anchor-permalink" href="#examples-advanced-tutorial" title="Permalink"></a></h1><pre><code class="language-julia hljs"># Activate local environment, see `Project.toml`
import Pkg; Pkg.activate(&quot;..&quot;); Pkg.instantiate();</code></pre><pre><code class="language-julia hljs">using RxInfer, Plots</code></pre><p>This notebook covers the fundamentals and advanced usage of the <code>RxInfer.jl</code> package.</p><p>This tutorial is also available in the <a href="https://reactivebayes.github.io/RxInfer.jl/stable/">documentation</a>.</p><h2 id="General-model-specification-syntax"><a class="docs-heading-anchor" href="#General-model-specification-syntax">General model specification syntax</a><a id="General-model-specification-syntax-1"></a><a class="docs-heading-anchor-permalink" href="#General-model-specification-syntax" title="Permalink"></a></h2><p>We use the <code>@model</code> macro from the <code>GraphPPL.jl</code> package to create a probabilistic model <span>$p(s, y)$</span> and we also specify extra constraints on the variational family of distributions <span>$\mathcal{Q}$</span>, used for approximating intractable posterior distributions. Below there is a simple example of the general syntax for model specification. In this tutorial we do not cover all possible ways to create models or advanced features of <code>GraphPPL.jl</code>.  Instead we refer the interested reader to the documentation for a more rigorous explanation and illustrative examples.</p><pre><code class="language-julia hljs"># the `@model` macro accepts a regular Julia function
@model function test_model1(s_mean, s_precision, y)
    
    # the `tilde` operator creates a functional dependency
    # between variables in our model and can be read as 
    # `sampled from` or `is modeled by`
    s ~ Normal(mean = s_mean, precision = s_precision)
    y ~ Normal(mean = s, precision = 1.0)
    
    # It is possible to return something from the model specification (including variables and nodes)
    return &quot;Hello world&quot;
end</code></pre><p>The <code>@model</code> macro creates a function with the same name and with the same set of input arguments as the original function (<code>test_model1(s_mean, s_precision, y)</code> in this example). The arguments are however converted to the keyword arguments. The <code>@model</code> macro does not support positional arguments.</p><p>It is also possible to use control flow statements such as <code>if</code> or <code>for</code> blocks in the model specification function. In general, any valid snippet of Julia code can be used inside the <code>@model</code> block. As an example consider the following (valid!) model:</p><pre><code class="language-julia hljs">@model function test_model2(y)
    
    if length(y) &lt;= 1
        error(&quot;The `length` of `y` argument must be greater than one.&quot;)
    end
    
    s[1] ~ Normal(mean = 0.0, precision = 0.1)
    y[1] ~ Normal(mean = s[1], precision = 1.0)
    
    for i in eachindex(y)
        s[i] ~ Normal(mean = s[i - 1], precision = 1.0)
        y[i] ~ Normal(mean = s[i], precision = 1.0)
    end
    
end</code></pre><p>It is also possible to use complex expressions inside the functional dependency expressions</p><pre><code class="language-julia hljs">y ~ Normal(mean = 2.0 * (s + 1.0), precision = 1.0)</code></pre><p>The <code>~</code> operator automatically creates a random variable if none was created before with the same name and throws an error if this name already exists</p><pre><code class="language-julia hljs"># `~` creates random variables automatically
s ~ Normal(mean = 0.0, precision1.0)</code></pre><h2 id="Probabilistic-inference-in-RxInfer.jl"><a class="docs-heading-anchor" href="#Probabilistic-inference-in-RxInfer.jl">Probabilistic inference in RxInfer.jl</a><a id="Probabilistic-inference-in-RxInfer.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Probabilistic-inference-in-RxInfer.jl" title="Permalink"></a></h2><p><code>RxInfer.jl</code> uses the <code>Rocket.jl</code> package API for inference routines. <code>Rocket.jl</code> is a reactive programming extension for Julia that is higly inspired by <code>RxJS</code> and similar libraries from the <code>Rx</code> ecosystem. It consists of <strong>observables</strong>, <strong>actors</strong>, <strong>subscriptions</strong> and <strong>operators</strong>. For more information and rigorous examples see <a href="https://github.com/biaslab/Rocket.jl">Rocket.jl github page</a>.</p><h3 id="Observables"><a class="docs-heading-anchor" href="#Observables">Observables</a><a id="Observables-1"></a><a class="docs-heading-anchor-permalink" href="#Observables" title="Permalink"></a></h3><p>Observables are lazy push-based collections and they deliver their values over time.</p><pre><code class="language-julia hljs"># Timer that emits a new value every second and has an initial one second delay 
observable = timer(300, 300)</code></pre><pre><code class="nohighlight hljs">TimerObservable(300, 300)</code></pre><p>A subscription allows us to subscribe on future values of some observable, and actors specify what to do with these new values:</p><pre><code class="language-julia hljs">actor = (value) -&gt; println(value)
subscription1 = subscribe!(observable, actor)</code></pre><pre><code class="nohighlight hljs">TimerSubscription()</code></pre><pre><code class="language-julia hljs"># We always need to unsubscribe from some observables
unsubscribe!(subscription1)</code></pre><pre><code class="language-julia hljs"># We can modify our observables
modified = observable |&gt; filter(d -&gt; rem(d, 2) === 1) |&gt; map(Int, d -&gt; d ^ 2)</code></pre><pre><code class="nohighlight hljs">ProxyObservable(Int64, MapProxy(Int64))</code></pre><pre><code class="language-julia hljs">subscription2 = subscribe!(modified, (value) -&gt; println(value))</code></pre><pre><code class="nohighlight hljs">TimerSubscription()</code></pre><pre><code class="language-julia hljs">unsubscribe!(subscription2)</code></pre><h2 id="Coin-Toss-Model"><a class="docs-heading-anchor" href="#Coin-Toss-Model">Coin Toss Model</a><a id="Coin-Toss-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Coin-Toss-Model" title="Permalink"></a></h2><pre><code class="language-julia hljs">@model function coin_toss_model(y)
    # We endow θ parameter of our model with some prior
    θ  ~ Beta(2.0, 7.0)
    # We assume that the outcome of each coin flip 
    # is modeled by a Bernoulli distribution
    y .~ Bernoulli(θ)
end</code></pre><p>We can call the <code>infer</code> function to run inference in such model:</p><pre><code class="language-julia hljs">p = 0.75 # Bias of a coin

dataset = float.(rand(Bernoulli(p), 500));

result = infer(
    model = coin_toss_model(),
    data  = (y = dataset, )
)

println(&quot;Inferred bias is &quot;, mean(result.posteriors[:θ]), &quot; with standard deviation is &quot;, std(result.posteriors[:θ]))</code></pre><pre><code class="nohighlight hljs">Inferred bias is 0.756385068762279 with standard deviation is 0.01900808375
5868727</code></pre><p>We can see that the inferred bias is quite close to the actual value we used in the dataset generation with a low standard deviation.</p><h2 id="Reactive-Online-Inference"><a class="docs-heading-anchor" href="#Reactive-Online-Inference">Reactive Online Inference</a><a id="Reactive-Online-Inference-1"></a><a class="docs-heading-anchor-permalink" href="#Reactive-Online-Inference" title="Permalink"></a></h2><p>RxInfer.jl naturally supports reactive streams of data and it is possible to run reactive inference with some external datasource.</p><pre><code class="language-julia hljs">@model function online_coin_toss_model(θ_a, θ_b, y)
    θ ~ Beta(θ_a, θ_b)
    y ~ Bernoulli(θ)
end</code></pre><pre><code class="language-julia hljs">autoupdates = @autoupdates begin 
    θ_a, θ_b = params(q(θ))
end</code></pre><pre><code class="nohighlight hljs">@autoupdates begin
    (θ_a, θ_b) = params(q(θ))
end</code></pre><pre><code class="language-julia hljs">init = @initialization begin
    q(θ) = vague(Beta)
end</code></pre><pre><code class="nohighlight hljs">Initial state: 
  q(θ) = Beta{Float64}(α=1.0, β=1.0)</code></pre><pre><code class="language-julia hljs">rxresult = infer(
    model = online_coin_toss_model(),
    data  = (y = dataset, ),
    autoupdates = autoupdates,
    historyvars = (θ = KeepLast(), ),
    keephistory = length(dataset),
    initialization = init,
    autostart = true
);</code></pre><pre><code class="language-julia hljs">animation = @animate for i in 1:length(dataset)
    plot(mean.(rxresult.history[:θ][1:i]), ribbon = std.(rxresult.history[:θ][1:i]), title = &quot;Online coin bias inference&quot;, label = &quot;Inferred bias&quot;, legend = :bottomright)
    hline!([ p ], label = &quot;Real bias&quot;, size = (600, 200))
end

gif(animation, &quot;../pics/online-coin-bias-inference.gif&quot;, fps = 24, show_msg = false);</code></pre><p><img src="../../../assets/examples/pics/online-coin-bias-inference.gif" alt/></p><p>In this example we used static dataset and the <code>history</code> field of the reactive inference result, but the <code>rxinference</code> function also supports any real-time reactive stream and can run indefinitely.</p><p>That was an example of exact Bayesian inference with Sum-Product (or Belief Propagation) algorithm. However, <code>RxInfer</code> is not limited to only the sum-product algorithm but it also supports variational message passing with <a href="https://www.mdpi.com/1099-4300/23/7/807">Constrained Bethe Free Energy Minimisation</a>.</p><h2 id="Variational-inference"><a class="docs-heading-anchor" href="#Variational-inference">Variational inference</a><a id="Variational-inference-1"></a><a class="docs-heading-anchor-permalink" href="#Variational-inference" title="Permalink"></a></h2><p>On a very high-level, <code>RxInfer</code> is aimed to solve the Constrained Bethe Free Energy minimisation problem. For this task we approximate our exact posterior marginal distribution by some family of distributions <span>$q \in \mathcal{Q}$</span>. Often this involves assuming some factorization over <span>$q$</span>. </p><pre><code class="language-julia hljs">@model function test_model6(y)
    τ ~ Gamma(shape = 1.0, rate = 1.0) 
    μ ~ Normal(mean = 0.0, variance = 100.0)
    for i in eachindex(y)
        y[i] ~ Normal(mean = μ, precision = τ)
    end
end</code></pre><p>In this example we want to specify extra constraints for <span>$q_a$</span> for Bethe factorisation:</p><p class="math-container">\[\begin{aligned}
q(s) = \prod_{a \in \mathcal{V}} q_a(s_a) \prod_{i \in \mathcal{E}} q_i^{-1}(s_i)
\end{aligned}\]</p><p><code>RxInfer.jl</code> package exports <code>@constraints</code> macro to simplify factorisation and form constraints specification. Read more about <code>@constraints</code> macro in the corresponding documentation section, here we show a simple example of the same factorisation constraints specification, but with <code>@constraints</code> macro:</p><pre><code class="language-julia hljs">constraints6 = @constraints begin
     q(μ, τ) = q(μ)q(τ) # Mean-Field over `μ` and `τ`
end</code></pre><pre><code class="nohighlight hljs">Constraints: 
  q(μ, τ) = q(μ)q(τ)</code></pre><pre><code class="language-julia hljs">init = @initialization begin
    q(μ) = vague(NormalMeanPrecision)
    q(τ) = vague(GammaShapeRate)
end</code></pre><pre><code class="nohighlight hljs">Initial state: 
  q(μ) = NormalMeanPrecision{Float64}(μ=0.0, w=1.0e-12)
  q(τ) = GammaShapeRate{Float64}(a=1.0, b=1.0e-12)</code></pre><h3 id="Inference"><a class="docs-heading-anchor" href="#Inference">Inference</a><a id="Inference-1"></a><a class="docs-heading-anchor-permalink" href="#Inference" title="Permalink"></a></h3><p>To run inference in this model we again need to create a synthetic dataset and call the <code>infer</code> function.</p><pre><code class="language-julia hljs">dataset = rand(Normal(-3.0, inv(sqrt(5.0))), 1000);
result = infer(
    model          = test_model6(),
    data           = (y = dataset, ),
    constraints    = constraints6, 
    initialization = init,
    returnvars     = (μ = KeepLast(), τ = KeepLast()),
    iterations     = 10,
    free_energy    = true,
    showprogress   = true
)</code></pre><pre><code class="nohighlight hljs">Inference results:
  Posteriors       | available for (μ, τ)
  Free Energy:     | Real[14763.3, 3275.4, 673.815, 634.536, 634.536, 634.5
36, 634.536, 634.536, 634.536, 634.536]</code></pre><pre><code class="language-julia hljs">println(&quot;μ: mean = &quot;, mean(result.posteriors[:μ]), &quot;, std = &quot;, std(result.posteriors[:μ]))</code></pre><pre><code class="nohighlight hljs">μ: mean = -2.9841460075463533, std = 0.014321701044149137</code></pre><pre><code class="language-julia hljs">println(&quot;τ: mean = &quot;, mean(result.posteriors[:τ]), &quot;, std = &quot;, std(result.posteriors[:τ]))</code></pre><pre><code class="nohighlight hljs">τ: mean = 4.875396053603982, std = 0.21781663202936855</code></pre><h3 id="Form-constraints"><a class="docs-heading-anchor" href="#Form-constraints">Form constraints</a><a id="Form-constraints-1"></a><a class="docs-heading-anchor-permalink" href="#Form-constraints" title="Permalink"></a></h3><p>In order to support form constraints, the <code>@constraints</code> macro supports additional type specifications for posterior marginals.  For example, here how we can perform the EM algorithm with <code>PointMass</code> form constraint.</p><p><img src="../../../assets/examples/pics/posterior.png" alt/></p><pre><code class="language-julia hljs">@model function test_model7(y)
    τ ~ Gamma(shape = 1.0, rate = 1.0) 
    μ ~ Normal(mean = 0.0, variance = 100.0)
    for i in eachindex(y)
        y[i] ~ Normal(mean = μ, precision = τ)
    end
end</code></pre><p>As in the previous example we can use <code>@constraints</code> macro to achieve the same goal with a nicer syntax:</p><pre><code class="language-julia hljs">constraints7 = @constraints begin 
    q(μ) :: PointMassFormConstraint()
    
    q(μ, τ) = q(μ)q(τ) # Mean-Field over `μ` and `τ`
end</code></pre><pre><code class="nohighlight hljs">Constraints: 
  q(μ, τ) = q(μ)q(τ)
  q(μ) :: PointMassFormConstraint()</code></pre><pre><code class="language-julia hljs">dataset = rand(Normal(-3.0, inv(sqrt(5.0))), 1000);
result = infer(
    model          = test_model7(),
    data           = (y = dataset, ),
    constraints    = constraints7, 
    initialization = init,
    returnvars     = (μ = KeepLast(), τ = KeepLast()),
    iterations     = 10,
    free_energy    = true,
    showprogress   = true
)</code></pre><pre><code class="nohighlight hljs">Inference results:
  Posteriors       | available for (μ, τ)
  Free Energy:     | Real[14766.5, 2046.76, 649.261, 649.261, 649.261, 649.
261, 649.261, 649.261, 649.261, 649.261]</code></pre><pre><code class="language-julia hljs">println(&quot;μ: mean = &quot;, mean(result.posteriors[:μ]), &quot;, std = &quot;, std(result.posteriors[:μ]))</code></pre><pre><code class="nohighlight hljs">μ: mean = -2.997720059823328, std = 0.0</code></pre><pre><code class="language-julia hljs">println(&quot;τ: mean = &quot;, mean(result.posteriors[:τ]), &quot;, std = &quot;, std(result.posteriors[:τ]))</code></pre><pre><code class="nohighlight hljs">τ: mean = 4.7075524431232685, std = 0.2103179325307846</code></pre><h3 id="Meta-data-specification"><a class="docs-heading-anchor" href="#Meta-data-specification">Meta data specification</a><a id="Meta-data-specification-1"></a><a class="docs-heading-anchor-permalink" href="#Meta-data-specification" title="Permalink"></a></h3><p>During model specification some functional dependencies may accept an optional <code>meta</code> object in the <code>where { ... }</code> clause. The purpose of the <code>meta</code> object is to adjust, modify or supply some extra information to the inference backend during the computations of the messages. The <code>meta</code> object for example may contain an approximation method that needs to be used during various approximations or it may specify the tradeoff between accuracy and performance:</p><pre><code class="language-julia hljs"># In this example the `meta` object for the autoregressive `AR` node specifies the variate type of 
# the autoregressive process and its order. In addition it specifies that the message computation rules should
# respect accuracy over speed with the `ARsafe()` strategy. In contrast, `ARunsafe()` strategy tries to speedup computations
# by cost of possible numerical instabilities during an inference procedure
s[i] ~ AR(s[i - 1], θ, γ) where { meta = ARMeta(Multivariate, order, ARsafe()) }
...
s[i] ~ AR(s[i - 1], θ, γ) where { meta = ARMeta(Univariate, order, ARunsafe()) }</code></pre><p>Another example with <code>GaussianControlledVariance</code>, or simply <code>GCV</code> [see Hierarchical Gaussian Filter], node:</p><pre><code class="language-julia hljs"># In this example we specify structured factorisation and flag meta with `GaussHermiteCubature` 
# method with `21` sigma points for approximation of non-lineariety between hierarchy layers
xt ~ GCV(xt_min, zt, real_k, real_w) where { meta = GCVMetadata(GaussHermiteCubature(21)) }</code></pre><p>The Meta object is useful to pass any extra information to a node that is not a random variable or constant model variable. It may include extra approximation methods, differentiation methods, optional non-linear functions, extra inference parameters etc.</p><h3 id="GraphPPL.jl-@meta-macro"><a class="docs-heading-anchor" href="#GraphPPL.jl-@meta-macro">GraphPPL.jl <code>@meta</code> macro</a><a id="GraphPPL.jl-@meta-macro-1"></a><a class="docs-heading-anchor-permalink" href="#GraphPPL.jl-@meta-macro" title="Permalink"></a></h3><p>Users can use <code>@meta</code> macro from the <code>GraphPPL.jl</code> package to achieve the same goal. Read more about <code>@meta</code> macro in the corresponding documentation section. Here is a simple example of the same meta specification:</p><pre><code class="language-julia hljs">@meta begin 
     AR(s, θ, γ) -&gt; ARMeta(Multivariate, 5, ARsafe())
end</code></pre><pre><code class="nohighlight hljs">Meta: 
  AR(s, θ, γ) -&gt; ARMeta{Multivariate, ARsafe}(5, ARsafe())</code></pre><h2 id="Creating-custom-nodes-and-message-computation-rules"><a class="docs-heading-anchor" href="#Creating-custom-nodes-and-message-computation-rules">Creating custom nodes and message computation rules</a><a id="Creating-custom-nodes-and-message-computation-rules-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-custom-nodes-and-message-computation-rules" title="Permalink"></a></h2><h3 id="Custom-nodes"><a class="docs-heading-anchor" href="#Custom-nodes">Custom nodes</a><a id="Custom-nodes-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-nodes" title="Permalink"></a></h3><p>To create a custom functional form and to make it available during model specification the <code>ReactiveMP</code> inference engine exports the <code>@node</code> macro:</p><pre><code class="language-julia hljs"># `@node` macro accepts a name of the functional form, its type, either `Stochastic` or `Deterministic` and an array of interfaces:
@node NormalMeanVariance Stochastic [ out, μ, v ]

# Interfaces may have aliases for their names that might be convenient for factorisation constraints specification
@node NormalMeanVariance Stochastic [ out, (μ, aliases = [ mean ]), (v, aliases = [ var ]) ]

# `NormalMeanVariance` structure declaration must exist, otherwise `@node` macro will throw an error
struct NormalMeanVariance end 

@node NormalMeanVariance Stochastic [ out, μ, v ]

# It is also possible to use function objects as a node functional form
function dot end

# Syntax for functions is a bit differet, as it is necesssary to use `typeof(...)` function for them 
# out = dot(x, a)
@node typeof(dot) Deterministic [ out, x, a ]</code></pre><p>After that it is possible to use the newly created node during model specification:</p><pre><code class="language-julia hljs">@model function test_model()
    ...
    y ~ dot(x, a)
    ...
end</code></pre><h3 id="Custom-messages-computation-rules"><a class="docs-heading-anchor" href="#Custom-messages-computation-rules">Custom messages computation rules</a><a id="Custom-messages-computation-rules-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-messages-computation-rules" title="Permalink"></a></h3><p><code>RxInfer.jl</code> exports the <code>@rule</code> macro to create custom message computation rules. For example let us create a simple <code>+</code> node to be available for usage in the model specification usage. We refer to <em>A Factor Graph Approach to Signal Modelling , System Identification and Filtering</em> [ Sascha Korl, 2005, page 32 ] for a rigorous explanation of the <code>+</code> node in factor graphs. According to Korl, assuming that inputs are Gaussian Sum-Product message computation rule for <code>+</code> node is the following:</p><p class="math-container">\[\begin{aligned}
\mu_z = \mu_x + \mu_y\\
V_z = V_x + V_y
\end{aligned}\]</p><p>To specify this in <code>RxInfer.jl</code> we use the <code>@node</code> and <code>@rule</code> macros:</p><pre><code class="language-julia hljs">@node typeof(+) Deterministic  [ z, x, y ]

@rule typeof(+)(:z, Marginalisation) (m_x::UnivariateNormalDistributionsFamily, m_y::UnivariateNormalDistributionsFamily) = begin
    x_mean, x_var = mean_var(m_x)
    y_mean, y_var = mean_var(m_y)
    return NormalMeanVariance(x_mean + y_mean, x_var + y_var)
end</code></pre><p>In this example, for the <code>@rule</code> macro, we specify a type of our functional form: <code>typeof(+)</code>. Next, we specify an edge we are going to compute an outbound message for. <code>Marginalisation</code> indicates that the corresponding message respects the marginalisation constraint for posterior over corresponding edge:</p><p class="math-container">\[\begin{aligned}
q(z) = \int q(z, x, y) \mathrm{d}x\mathrm{d}y
\end{aligned}\]</p><p>If we look on difference between sum-product rules and variational rules with mean-field assumption we notice that they require different local information to compute an outgoing message:</p><p><img src="../../../assets/examples/pics/sp.png" alt/> <img src="../../../assets/examples/pics/vmp.png" alt/></p><p class="math-container">\[\begin{aligned}
\mu(z) = \int f(x, y, z)\mu(x)\mu(y)\mathrm{d}x\mathrm{d}y
\end{aligned}\]</p><p class="math-container">\[\begin{aligned}
\nu(z) = \exp{ \int \log f(x, y, z)q(x)q(y)\mathrm{d}x\mathrm{d}y }
\end{aligned}\]</p><p>The <code>@rule</code> macro supports both cases with special prefixes during rule specification:</p><ul><li><code>m_</code> prefix corresponds to the incoming message on a specific edge</li><li><code>q_</code> prefix corresponds to the posterior marginal of a specific edge</li></ul><p>Example of a Sum-Product rule with <code>m_</code> messages used:</p><pre><code class="language-julia hljs">@rule NormalMeanPrecision(:μ, Marginalisation) (m_out::UnivariateNormalDistributionsFamily, m_τ::PointMass) = begin 
    m_out_mean, m_out_cov = mean_cov(m_out)
    return NormalMeanPrecision(m_out_mean, inv(m_out_cov + inv(mean(m_τ))))
end</code></pre><p>Example of a Variational rule with Mean-Field assumption with <code>q_</code> posteriors used:</p><pre><code class="language-julia hljs">@rule NormalMeanPrecision(:μ, Marginalisation) (q_out::Any, q_τ::Any) = begin 
    return NormalMeanPrecision(mean(q_out), mean(q_τ))
end</code></pre><p><code>RxInfer.jl</code> also supports structured rules. It is possible to obtain joint marginal over a set of edges:</p><pre><code class="language-julia hljs">@rule NormalMeanPrecision(:τ, Marginalisation) (q_out_μ::Any, ) = begin
    m, V = mean_cov(q_out_μ)
    θ = 2 / (V[1,1] - V[1,2] - V[2,1] + V[2,2] + abs2(m[1] - m[2]))
    α = convert(typeof(θ), 1.5)
    return Gamma(α, θ)
end</code></pre><p><strong>NOTE</strong>: In the <code>@rule</code> specification the messages or marginals arguments <strong>must</strong> be in order with interfaces specification from <code>@node</code> macro:</p><pre><code class="language-julia hljs"># Inference backend expects arguments in `@rule` macro to be in the same order
@node NormalMeanPrecision Stochastic [ out, μ, τ ]</code></pre><p>Any rule always has access to the meta information with hidden the <code>meta::Any</code> variable:</p><pre><code class="language-julia hljs">@rule MyCustomNode(:out, Marginalisation) (m_in1::Any, m_in2::Any) = begin 
    ...
    println(meta)
    ...
end</code></pre><p>It is also possible to dispatch on a specific type of a meta object:</p><pre><code class="language-julia hljs">@rule MyCustomNode(:out, Marginalisation) (m_in1::Any, m_in2::Any, meta::LaplaceApproximation) = begin 
    ...
end</code></pre><p>or</p><pre><code class="language-julia hljs">@rule MyCustomNode(:out, Marginalisation) (m_in1::Any, m_in2::Any, meta::GaussHermiteCubature) = begin 
    ...
end</code></pre><h3 id="Customizing-messages-computational-pipeline"><a class="docs-heading-anchor" href="#Customizing-messages-computational-pipeline">Customizing messages computational pipeline</a><a id="Customizing-messages-computational-pipeline-1"></a><a class="docs-heading-anchor-permalink" href="#Customizing-messages-computational-pipeline" title="Permalink"></a></h3><p>In certain situations it might be convenient to customize the default message computational pipeline. <code>RxInfer.jl</code> supports the <code>pipeline</code> keyword in the <code>where { ... }</code> clause to add some extra steps after a message has been computed. A use case might be an extra approximation method to preserve conjugacy in the model, debugging or simple printing.</p><p>&lt;img style=&quot;display: block;   margin-left: auto;   margin-right: auto;   width: 30%;&quot; src=&quot;./pics/pipeline.png&quot; width=&quot;20%&quot; /&gt;</p><pre><code class="language-julia hljs"># Logs all outbound messages
y[i] ~ Normal(mean = x[i], precision = 1.0) where { pipeline = LoggerPipelineStage() }
# In principle, it is possible to approximate outbound messages with Laplace Approximation (this is not an implemented feature, but a concept)
y[i] ~ Normal(mean = x[i], precision = 1.0) where { pipeline = LaplaceApproximation() }</code></pre><p>Let us return to the coin toss model, but this time we want to print flowing messages:</p><pre><code class="language-julia hljs">@model function coin_toss_model_log(y)
    θ ~ Beta(2.0, 7.0) where { pipeline = LoggerPipelineStage(&quot;θ&quot;) }
    for i in eachindex(y)
        y[i] ~ Bernoulli(θ)  where { pipeline = LoggerPipelineStage(&quot;y[$i]&quot;) }
    end
end</code></pre><pre><code class="language-julia hljs">dataset = float.(rand(Bernoulli(p), 5));
result = infer(
    model = coin_toss_model_log(),
    data  = (y = dataset, )
)</code></pre><pre><code class="nohighlight hljs">[θ][Beta][out]: DeferredMessage([ use `as_message` to compute the message ]
)
[y[1]][Bernoulli][p]: DeferredMessage([ use `as_message` to compute the mes
sage ])
[y[2]][Bernoulli][p]: DeferredMessage([ use `as_message` to compute the mes
sage ])
[y[3]][Bernoulli][p]: DeferredMessage([ use `as_message` to compute the mes
sage ])
[y[4]][Bernoulli][p]: DeferredMessage([ use `as_message` to compute the mes
sage ])
[y[5]][Bernoulli][p]: DeferredMessage([ use `as_message` to compute the mes
sage ])
Inference results:
  Posteriors       | available for (θ)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../Active Inference Mountain car/">« Active Inference Mountain car</a><a class="docs-footer-nextpage" href="../Assessing People Skills/">Assessing People’s Skills »</a><div class="flexbox-break"></div><p class="footer-message">Created in <a href="https://biaslab.github.io/">BIASlab</a>, maintained by <a href="https://github.com/ReactiveBayes">ReactiveBayes</a>, powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Sunday 8 December 2024 15:09">Sunday 8 December 2024</span>. Using Julia version 1.11.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

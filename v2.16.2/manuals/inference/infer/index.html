<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Static vs Streamline inference · RxInfer.jl</title><meta name="title" content="Static vs Streamline inference · RxInfer.jl"/><meta property="og:title" content="Static vs Streamline inference · RxInfer.jl"/><meta property="twitter:title" content="Static vs Streamline inference · RxInfer.jl"/><meta name="description" content="Documentation for RxInfer.jl."/><meta property="og:description" content="Documentation for RxInfer.jl."/><meta property="twitter:description" content="Documentation for RxInfer.jl."/><meta property="og:url" content="https://reactivebayes.github.io/RxInfer.jl/manuals/inference/infer/"/><meta property="twitter:url" content="https://reactivebayes.github.io/RxInfer.jl/manuals/inference/infer/"/><link rel="canonical" href="https://reactivebayes.github.io/RxInfer.jl/manuals/inference/infer/"/><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/theme.css" rel="stylesheet" type="text/css"/><link href="../../../assets/header.css" rel="stylesheet" type="text/css"/><script src="../../../assets/header.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img class="docs-light-only" src="../../../assets/logo.svg" alt="RxInfer.jl logo"/><img class="docs-dark-only" src="../../../assets/logo-dark.svg" alt="RxInfer.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">RxInfer.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><span class="tocitem">User guide</span><ul><li><a class="tocitem" href="../../getting-started/">Getting started</a></li><li><a class="tocitem" href="../../comparison/">RxInfer.jl vs. Others</a></li><li><a class="tocitem" href="../../model-specification/">Model specification</a></li><li><a class="tocitem" href="../../constraints-specification/">Constraints specification</a></li><li><a class="tocitem" href="../../meta-specification/">Meta specification</a></li><li><input class="collapse-toggle" id="menuitem-2-6" type="checkbox" checked/><label class="tocitem" for="menuitem-2-6"><span class="docs-label">Inference specification</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../overview/">Overview</a></li><li class="is-active"><a class="tocitem" href>Static vs Streamline inference</a></li><li><a class="tocitem" href="../postprocess/">Inference results postprocessing</a></li><li><a class="tocitem" href="../manual/">Manual inference specification</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-7" type="checkbox"/><label class="tocitem" for="menuitem-2-7"><span class="docs-label">Inference customization</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../custom-node/">Defining a custom node and rules</a></li></ul></li><li><a class="tocitem" href="../../understanding-why-to-initialize-messages/">Messages initialization</a></li><li><a class="tocitem" href="../../debugging/">Debugging</a></li><li><a class="tocitem" href="../../delta-node/">Delta node</a></li></ul></li><li><span class="tocitem">Library</span><ul><li><a class="tocitem" href="../../../library/functional-forms/">Built-in functional form constraints</a></li><li><a class="tocitem" href="../../../library/model-specification/">Model specification</a></li><li><a class="tocitem" href="../../../library/bethe-free-energy/">Bethe Free Energy</a></li><li><a class="tocitem" href="../../../library/exported-methods/">Exported methods</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../../examples/overview/">Overview</a></li><li><input class="collapse-toggle" id="menuitem-4-2" type="checkbox"/><label class="tocitem" for="menuitem-4-2"><span class="docs-label">Basic examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../examples/basic_examples/overview/">Overview</a></li><li><a class="tocitem" href="../../../examples/basic_examples/Coin Toss Model/">Coin toss model (Beta-Bernoulli)</a></li><li><a class="tocitem" href="../../../examples/basic_examples/Bayesian Linear Regression Tutorial/">Bayesian Linear Regression Tutorial</a></li><li><a class="tocitem" href="../../../examples/basic_examples/Kalman filtering and smoothing/">Kalman filtering and smoothing</a></li><li><a class="tocitem" href="../../../examples/basic_examples/Predicting Bike Rental Demand/">Predicting Bike Rental Demand</a></li><li><a class="tocitem" href="../../../examples/basic_examples/Hidden Markov Model/">How to train your Hidden Markov Model</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Advanced examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../examples/advanced_examples/overview/">Overview</a></li><li><a class="tocitem" href="../../../examples/advanced_examples/Active Inference Mountain car/">Active Inference Mountain car</a></li><li><a class="tocitem" href="../../../examples/advanced_examples/Advanced Tutorial/">Advanced Tutorial</a></li><li><a class="tocitem" href="../../../examples/advanced_examples/Assessing People Skills/">Assessing People’s Skills</a></li><li><a class="tocitem" href="../../../examples/advanced_examples/Chance Constraints/">Chance-Constrained Active Inference</a></li><li><a class="tocitem" href="../../../examples/advanced_examples/Conjugate-Computational Variational Message Passing/">Conjugate-Computational Variational Message Passing (CVI)</a></li><li><a class="tocitem" href="../../../examples/advanced_examples/Global Parameter Optimisation/">Global Parameter Optimisation</a></li><li><a class="tocitem" href="../../../examples/advanced_examples/GP Regression by SSM/">Solve GP regression by SDE</a></li><li><a class="tocitem" href="../../../examples/advanced_examples/Infinite Data Stream/">Infinite Data Stream</a></li><li><a class="tocitem" href="../../../examples/advanced_examples/Nonlinear Sensor Fusion/">Nonlinear Sensor Fusion</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Problem specific</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../examples/problem_specific/overview/">Overview</a></li><li><a class="tocitem" href="../../../examples/problem_specific/Autoregressive Models/">Autoregressive Models</a></li><li><a class="tocitem" href="../../../examples/problem_specific/Gamma Mixture/">Gamma Mixture Model</a></li><li><a class="tocitem" href="../../../examples/problem_specific/Gaussian Mixture/">Gaussian Mixture</a></li><li><a class="tocitem" href="../../../examples/problem_specific/Hierarchical Gaussian Filter/">Hierarchical Gaussian Filter</a></li><li><a class="tocitem" href="../../../examples/problem_specific/Invertible Neural Network Tutorial/">Invertible neural networks: a tutorial</a></li><li><a class="tocitem" href="../../../examples/problem_specific/Probit Model (EP)/">Probit Model (EP)</a></li><li><a class="tocitem" href="../../../examples/problem_specific/RTS vs BIFM Smoothing/">RTS vs BIFM Smoothing</a></li><li><a class="tocitem" href="../../../examples/problem_specific/Simple Nonlinear Node/">Simple Nonlinear Node</a></li><li><a class="tocitem" href="../../../examples/problem_specific/Universal Mixtures/">Universal Mixtures</a></li></ul></li></ul></li><li><span class="tocitem">Contributing</span><ul><li><a class="tocitem" href="../../../contributing/overview/">Overview</a></li><li><a class="tocitem" href="../../../contributing/new-documentation/">Contributing to the documentation</a></li><li><a class="tocitem" href="../../../contributing/new-package/">Contributing to the dependencies</a></li><li><a class="tocitem" href="../../../contributing/new-example/">Contributing to the examples</a></li><li><a class="tocitem" href="../../../contributing/new-release/">Publishing a new release</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">User guide</a></li><li><a class="is-disabled">Inference specification</a></li><li class="is-active"><a href>Static vs Streamline inference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Static vs Streamline inference</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ReactiveBayes/RxInfer.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/ReactiveBayes/RxInfer.jl/blob/main/docs/src/manuals/inference/infer.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="user-guide-inference"><a class="docs-heading-anchor" href="#user-guide-inference">Automatic Inference Specification</a><a id="user-guide-inference-1"></a><a class="docs-heading-anchor-permalink" href="#user-guide-inference" title="Permalink"></a></h1><p><code>RxInfer</code> provides the <code>infer</code> function for quickly running and testing your model with both static and streaming datasets. To enable streaming behavior, the <code>infer</code> function accepts an <code>autoupdates</code> argument, which specifies how to update your priors for future states based on newly updated posteriors. </p><p>It&#39;s important to note that while this function covers most capabilities of the inference engine, advanced use cases may require resorting to the <a href="../overview/#user-guide-inference-execution-manual-specification">Manual Inference Specification</a>.</p><p>For details on manual inference specification, see the <a href="../manual/#user-guide-manual-inference">Manual Inference</a> section.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RxInfer.infer" href="#RxInfer.infer"><code>RxInfer.infer</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">infer(
    model; 
    data = nothing,
    datastream = nothing,
    autoupdates = nothing,
    initmarginals = nothing,
    initmessages = nothing,
    constraints = nothing,
    meta = nothing,
    options = nothing,
    returnvars = nothing, 
    predictvars = nothing, 
    historyvars = nothing,
    keephistory = nothing,
    iterations = nothing,
    free_energy = false,
    free_energy_diagnostics = BetheFreeEnergyDefaultChecks,
    showprogress = false,
    callbacks = nothing,
    addons = nothing,
    postprocess = DefaultPostprocess(),
    warn = true,
    events = nothing,
    uselock = false,
    autostart = true,
    catch_exception = false
)</code></pre><p>This function provides a generic way to perform probabilistic inference for batch/static and streamline/online scenarios. Returns an <code>InferenceResult</code> (batch setting) or <code>RxInferenceEngine</code> (streamline setting) based on the parameters used.</p><p><strong>Arguments</strong></p><p>For more information about some of the arguments, please check below. </p><ul><li><code>model</code>: specifies a model generator, required</li><li><code>data</code>: <code>NamedTuple</code> or <code>Dict</code> with data, required (or <code>datastream</code> or <code>predictvars</code>)</li><li><code>datastream</code>: A stream of <code>NamedTuple</code> with data, required (or <code>data</code>)</li><li><code>autoupdates = nothing</code>: auto-updates specification, required for streamline inference, see <code>@autoupdates</code></li><li><code>initmarginals = nothing</code>: <code>NamedTuple</code> or <code>Dict</code> with initial marginals, optional</li><li><code>initmessages = nothing</code>: <code>NamedTuple</code> or <code>Dict</code> with initial messages, optional</li><li><code>constraints = nothing</code>: constraints specification object, optional, see <code>@constraints</code></li><li><code>meta  = nothing</code>: meta specification object, optional, may be required for some models, see <code>@meta</code></li><li><code>options = nothing</code>: model creation options, optional, see <code>ModelInferenceOptions</code></li><li><code>returnvars = nothing</code>: return structure info, optional, defaults to return everything at each iteration, see below for more information</li><li><code>predictvars = nothing</code>: return structure info, optional, see below for more information (exclusive for batch inference)</li><li><code>historyvars = nothing</code>: history structure info, optional, defaults to no history, see below for more information (exclusive for streamline inference)</li><li><code>keephistory = nothing</code>: history buffer size, defaults to empty buffer, see below for more information (exclusive for streamline inference)</li><li><code>iterations = nothing</code>: number of iterations, optional, defaults to <code>nothing</code>, the inference engine does not distinguish between variational message passing or Loopy belief propagation or expectation propagation iterations, see below for more information</li><li><code>free_energy = false</code>: compute the Bethe free energy, optional, defaults to false. Can be passed a floating point type, e.g. <code>Float64</code>, for better efficiency, but disables automatic differentiation packages, such as ForwardDiff.jl</li><li><code>free_energy_diagnostics = BetheFreeEnergyDefaultChecks</code>: free energy diagnostic checks, optional, by default checks for possible <code>NaN</code>s and <code>Inf</code>s. <code>nothing</code> disables all checks.</li><li><code>showprogress = false</code>: show progress module, optional, defaults to false (exclusive for batch inference)</li><li><code>catch_exception</code>  specifies whether exceptions during the inference procedure should be caught, optional, defaults to false (exclusive for batch inference)</li><li><code>callbacks = nothing</code>: inference cycle callbacks, optional, see below for more info</li><li><code>addons = nothing</code>: inject and send extra computation information along messages, see below for more info</li><li><code>postprocess = DefaultPostprocess()</code>: inference results postprocessing step, optional, see below for more info</li><li><code>events = nothing</code>: inference cycle events, optional, see below for more info (exclusive for streamline inference)</li><li><code>uselock = false</code>: specifies either to use the lock structure for the inference or not, if set to true uses <code>Base.Threads.SpinLock</code>. Accepts custom <code>AbstractLock</code>. (exclusive for streamline inference)</li><li><code>autostart = true</code>: specifies whether to call <code>RxInfer.start</code> on the created engine automatically or not (exclusive for streamline inference)</li><li><code>warn = true</code>: enables/disables warnings</li></ul><p><strong>Note on NamedTuples</strong></p><p>When passing <code>NamedTuple</code> as a value for some argument, make sure you use a trailing comma for <code>NamedTuple</code>s with a single entry. The reason is that Julia treats <code>returnvars = (x = KeepLast())</code> and <code>returnvars = (x = KeepLast(), )</code> expressions differently. This first expression creates (or <strong>overwrites!</strong>) new local/global variable named <code>x</code> with contents <code>KeepLast()</code>. The second expression (note trailing comma) creates <code>NamedTuple</code> with <code>x</code> as a key and <code>KeepLast()</code> as a value assigned for this key.</p><p>The <code>model</code> argument accepts a <code>ModelGenerator</code> as its input. The easiest way to create the <code>ModelGenerator</code> is to use the <code>@model</code> macro.  For example:</p><pre><code class="language-julia hljs">@model function coin_toss(some_argument, some_keyword_argument = 3)
    ...
end

result = infer(
    model = coin_toss(some_argument; some_keyword_argument = 3)
)</code></pre><p><strong>Note</strong>: The <code>model</code> keyword argument does not accept a <code>FactorGraphModel</code> instance as a value, as it needs to inject <code>constraints</code> and <code>meta</code> during the inference procedure.</p><ul><li><strong><code>data</code></strong></li></ul><p>Either <code>data</code> or <code>datastream</code> or <code>predictvars</code> keyword argument is required. Specifying both <code>data</code> and <code>datastream</code> is not supported and will result in an error. Specifying both <code>datastream</code> and <code>predictvars</code> is not supported and will result in an error.</p><p><strong>Note</strong>: The behavior of the <code>data</code> keyword argument depends on the inference setting (batch or streamline).</p><p>The <code>data</code> keyword argument must be a <code>NamedTuple</code> (or <code>Dict</code>) where keys (of <code>Symbol</code> type) correspond to all <code>datavar</code>s defined in the model specification. For example, if a model defines <code>x = datavar(Float64)</code> the  <code>data</code> field must have an <code>:x</code> key (of <code>Symbol</code> type) which holds a value of type <code>Float64</code>. The values in the <code>data</code> must have the exact same shape as the <code>datavar</code> container. In other words, if a model defines <code>x = datavar(Float64, n)</code> then  <code>data[:x]</code> must provide a container with length <code>n</code> and with elements of type <code>Float64</code>.</p><ul><li><strong><code>streamline</code> setting</strong></li></ul><p>All entries in the <code>data</code> argument are zipped together with the <code>Base.zip</code> function to form one slice of the data chunck. This means all containers in the <code>data</code> argument must be of the same size (<code>zip</code> iterator finished as soon as one container has no remaining values). In order to use a fixed value for some specific <code>datavar</code> it is not necessary to create a container with that fixed value, but rather more efficient to use <code>Iterators.repeated</code> to create an infinite iterator.</p><ul><li><strong><code>datastream</code></strong></li></ul><p>The <code>datastream</code> keyword argument must be an observable that supports <code>subscribe!</code> and <code>unsubscribe!</code> functions (streams from the <code>Rocket.jl</code> package are also supported). The elements of the observable must be of type <code>NamedTuple</code> where keys (of <code>Symbol</code> type) correspond to all <code>datavar</code>s defined in the model specification, except for those which are listed in the <code>autoupdates</code> specification.  For example, if a model defines <code>x = datavar(Float64)</code> (which is not part of the <code>autoupdates</code> specification) the named tuple from the observable must have an <code>:x</code> key (of <code>Symbol</code> type) which holds a value of type <code>Float64</code>. The values in the named tuple must have the exact same shape as the <code>datavar</code> container. In other words, if a model defines <code>x = datavar(Float64, n)</code> then  <code>namedtuple[:x]</code> must provide a container with length <code>n</code> and with elements of type <code>Float64</code>.</p><p><strong>Note</strong>: The behavior of the individual named tuples from the <code>datastream</code> observable is similar to that which is used in the batch setting. In fact, you can see the streamline inference as an efficient version of the batch inference, which automatically updates some <code>datavar</code>s with the <code>autoupdates</code> specification and listens to the <code>datastream</code> to update the rest of the <code>datavar</code>s.</p><p>For specific types of inference algorithms, such as variational message passing, it might be required to initialize (some of) the marginals before running the inference procedure in order to break the dependency loop. If this is not done, the inference algorithm will not be executed due to the lack of information and message and/or marginals will not be updated. In order to specify these initial marginals, you can use the <code>initmarginals</code> argument, such as</p><pre><code class="language-julia hljs">infer(...
    initmarginals = (
        # initialize the marginal distribution of x as a vague Normal distribution
        # if x is a vector, then it simply uses the same value for all elements
        # However, it is also possible to provide a vector of distributions to set each element individually 
        x = vague(NormalMeanPrecision),  
    ),
)

This argument needs to be a named tuple, i.e. `initmarginals = (a = ..., )`, or dictionary.

- ### `initmessages`

For specific types of inference algorithms, such as loopy belief propagation or expectation propagation, it might be required to initialize (some of) the messages before running the inference procedure in order to break the dependency loop. If this is not done, the inference algorithm will not be executed due to the lack of information and message and/or marginals will not be updated. In order to specify these initial messages, you can use the `initmessages` argument, such as</code></pre><p>julia infer(...     initmessages = (         # initialize the messages distribution of x as a vague Normal distribution         # if x is a vector, then it simply uses the same value for all elements         # However, it is also possible to provide a vector of distributions to set each element individually          x = vague(NormalMeanPrecision),       ), )</p><ul><li><p><strong><code>options</code></strong></p></li><li><p><code>limit_stack_depth</code>: limits the stack depth for computing messages, helps with <code>StackOverflowError</code> for some huge models, but reduces the performance of inference backend. Accepts integer as an argument that specifies the maximum number of recursive depth. Lower is better for stack overflow error, but worse for performance.</p></li><li><p><code>pipeline</code>: changes the default pipeline for each factor node in the graph</p></li><li><p><code>global_reactive_scheduler</code>: changes the scheduler of reactive streams, see Rocket.jl for more info, defaults to no scheduler</p></li><li><p><strong><code>returnvars</code></strong></p></li></ul><p><code>returnvars</code> specifies latent variables of interest and their posterior updates. Its behavior depends on the inference type: streamline or batch.</p><p><strong>Batch inference:</strong></p><ul><li>Accepts a <code>NamedTuple</code> or <code>Dict</code> of return variable specifications.</li><li>Two specifications available: <code>KeepLast</code> (saves the last update) and <code>KeepEach</code> (saves all updates).</li><li>When <code>iterations</code> is set, returns every update for each iteration (equivalent to <code>KeepEach()</code>); if <code>nothing</code>, saves the last update (equivalent to <code>KeepLast()</code>).</li><li>Use <code>iterations = 1</code> to force <code>KeepEach()</code> for a single iteration or set <code>returnvars = KeepEach()</code> manually.</li></ul><p>Example:</p><pre><code class="language-julia hljs">result = infer(
    ...,
    returnvars = (
        x = KeepLast(),
        τ = KeepEach()
    )
)</code></pre><p>Shortcut for setting the same option for all variables:</p><pre><code class="language-julia hljs">result = infer(
    ...,
    returnvars = KeepLast()  # or KeepEach()
)</code></pre><p><strong>Streamline inference:</strong></p><ul><li>For each symbol in <code>returnvars</code>, <code>infer</code> creates an observable stream of posterior updates.</li><li>Agents can subscribe to these updates using the <code>Rocket.jl</code> package.</li></ul><p>Example:</p><pre><code class="language-julia hljs">engine = infer(
    ...,
    autoupdates = my_autoupdates,
    returnvars = (:x, :τ),
    autostart  = false
)</code></pre><ul><li><strong><code>predictvars</code></strong></li></ul><p><code>predictvars</code> specifies the variables which should be predicted. In the model definition these variables are specified as datavars, although they should not be passed inside data argument.</p><p>Similar to <code>returnvars</code>, <code>predictvars</code> accepts a <code>NamedTuple</code> or <code>Dict</code>. There are two specifications:</p><ul><li><code>KeepLast</code>: saves the last update for a variable, ignoring any intermediate results during iterations</li><li><code>KeepEach</code>: saves all updates for a variable for all iterations</li></ul><p>Example: </p><pre><code class="language-julia hljs">result = infer(
    ...,
    predictvars = (
        o = KeepLast(),
        τ = KeepEach()
    )
)</code></pre><p><strong>Note</strong>: The <code>predictvars</code> argument is exclusive for batch setting.</p><ul><li><strong><code>historyvars</code></strong></li></ul><p><code>historyvars</code> specifies the variables of interests and the amount of information to keep in history about the posterior updates when performing streamline inference. The specification is similar to the <code>returnvars</code> when applied in batch setting. The <code>historyvars</code> requires <code>keephistory</code> to be greater than zero.</p><p><code>historyvars</code> accepts a <code>NamedTuple</code> or <code>Dict</code> or return var specification. There are two specifications:</p><ul><li><code>KeepLast</code>: saves the last update for a variable, ignoring any intermediate results during iterations</li><li><code>KeepEach</code>: saves all updates for a variable for all iterations</li></ul><p>Example: </p><pre><code class="language-julia hljs">result = infer(
    ...,
    autoupdates = my_autoupdates,
    historyvars = (
        x = KeepLast(),
        τ = KeepEach()
    ),
    keephistory = 10
)</code></pre><p>It is also possible to set either <code>historyvars = KeepLast()</code> or <code>historyvars = KeepEach()</code> that acts as an alias and sets the given option for <strong>all</strong> random variables in the model.</p><p><strong>Example:</strong></p><pre><code class="language-julia hljs">result = infer(
    ...,
    autoupdates = my_autoupdates,
    historyvars = KeepLast(),
    keephistory = 10
)</code></pre><ul><li><strong><code>keep_history</code></strong></li></ul><p>Specifies the buffer size for the updates history both for the <code>historyvars</code> and the <code>free_energy</code> buffers in streamline inference.</p><ul><li><strong><code>iterations</code></strong></li></ul><p>Specifies the number of variational (or loopy belief propagation) iterations. By default set to <code>nothing</code>, which is equivalent of doing 1 iteration. </p><ul><li><strong><code>free_energy</code></strong></li></ul><p><strong>Streamline inference:</strong></p><p>Specifies if the <code>infer</code> function should create an observable stream of Bethe Free Energy (BFE) values, computed at each VMP iteration.</p><ul><li>When <code>free_energy = true</code> and <code>keephistory &gt; 0</code>, additional fields are exposed in the engine for accessing the history of BFE updates.<ul><li><code>engine.free_energy_history</code>: Averaged BFE history over VMP iterations.</li><li><code>engine.free_energy_final_only_history</code>: BFE history of values computed in the last VMP iterations for each observation.</li><li><code>engine.free_energy_raw_history</code>: Raw BFE history.</li></ul></li></ul><p><strong>Batch inference:</strong></p><p>Specifies if the <code>infer</code> function should return Bethe Free Energy (BFE) values.</p><ul><li><p>Optionally accepts a floating-point type (e.g., <code>Float64</code>) for improved BFE computation performance, but restricts the use of automatic differentiation packages.</p></li><li><p><strong><code>free_energy_diagnostics</code></strong></p></li></ul><p>This settings specifies either a single or a tuple of diagnostic checks for Bethe Free Energy values stream. By default checks for <code>NaN</code>s and <code>Inf</code>s. See also <a href="../../../library/bethe-free-energy/#RxInfer.BetheFreeEnergyCheckNaNs"><code>BetheFreeEnergyCheckNaNs</code></a> and <a href="../../../library/bethe-free-energy/#RxInfer.BetheFreeEnergyCheckInfs"><code>BetheFreeEnergyCheckInfs</code></a>. Pass <code>nothing</code> to disable any checks.</p><ul><li><strong><code>catch_exception</code></strong></li></ul><p>The <code>catch_exception</code> keyword argument specifies whether exceptions during the batch inference procedure should be caught in the <code>error</code> field of the  result. By default, if exception occurs during the inference procedure the result will be lost. Set <code>catch_exception = true</code> to obtain partial result  for the inference in case if an exception occurs. Use <code>RxInfer.issuccess</code> and <code>RxInfer.iserror</code> function to check if the inference completed successfully or failed. If an error occurs, the <code>error</code> field will store a tuple, where first element is the exception itself and the second element is the caught <code>backtrace</code>. Use the <code>stacktrace</code> function  with the <code>backtrace</code> as an argument to recover the stacktrace of the error. Use <code>Base.showerror</code> function to display the error.</p><ul><li><strong><code>callbacks</code></strong></li></ul><p>The inference function has its own lifecycle. The user is free to provide some (or none) of the callbacks to inject some extra logging or other procedures in the inference function, e.g.</p><pre><code class="language-julia hljs">result = infer(
    ...,
    callbacks = (
        on_marginal_update = (model, name, update) -&gt; println(&quot;$(name) has been updated: $(update)&quot;),
        after_inference    = (args...) -&gt; println(&quot;Inference has been completed&quot;)
    )
)</code></pre><p>The <code>callbacks</code> keyword argument accepts a named-tuple of &#39;name = callback&#39; pairs.  The list of all possible callbacks for different inference setting (batch or streamline) and their arguments is present below:</p><ul><li><code>on_marginal_update</code>:    args: (model::FactorGraphModel, name::Symbol, update) (exlusive for batch inference)</li><li><code>before_model_creation</code>: args: ()</li><li><code>after_model_creation</code>:  args: (model::FactorGraphModel, returnval)</li><li><code>before_inference</code>:      args: (model::FactorGraphModel) (exlusive for batch inference)</li><li><code>before_iteration</code>:      args: (model::FactorGraphModel, iteration::Int)::Bool (exlusive for batch inference)</li><li><code>before_data_update</code>:    args: (model::FactorGraphModel, data) (exlusive for batch inference)</li><li><code>after_data_update</code>:     args: (model::FactorGraphModel, data) (exlusive for batch inference)</li><li><code>after_iteration</code>:       args: (model::FactorGraphModel, iteration::Int)::Bool (exlusive for batch inference)</li><li><code>after_inference</code>:       args: (model::FactorGraphModel) (exlusive for batch inference)</li><li><code>before_autostart</code>:      args: (engine::RxInferenceEngine) (exlusive for streamline inference)</li><li><code>after_autostart</code>:       args: (engine::RxInferenceEngine) (exlusive for streamline inference)</li></ul><p><code>before_iteration</code> and <code>after_iteration</code> callbacks are allowed to return <code>true/false</code> value. <code>true</code> indicates that iterations must be halted and no further inference should be made.</p><ul><li><strong><code>addons</code></strong></li></ul><p>The <code>addons</code> field extends the default message computation rules with some extra information, e.g. computing log-scaling factors of messages or saving debug-information. Accepts a single addon or a tuple of addons. If set, replaces the corresponding setting in the <code>options</code>. Automatically changes the default value of the <code>postprocess</code> argument to <code>NoopPostprocess</code>.</p><ul><li><strong><code>postprocess</code></strong></li></ul><p>The <code>postprocess</code> keyword argument controls whether the inference results must be modified in some way before exiting the <code>inference</code> function. By default, the inference function uses the <code>DefaultPostprocess</code> strategy, which by default removes the <code>Marginal</code> wrapper type from the results. Change this setting to <code>NoopPostprocess</code> if you would like to keep the <code>Marginal</code> wrapper type, which might be useful in the combination with the <code>addons</code> argument. If the <code>addons</code> argument has been used, automatically changes the default strategy value to <code>NoopPostprocess</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/RxInfer.jl/blob/23f95bbaa753c56d83127dea0d0be14fdf937b1e/src/inference.jl#L1442-L1765">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RxInfer.InferenceResult" href="#RxInfer.InferenceResult"><code>RxInfer.InferenceResult</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">InferenceResult</code></pre><p>This structure is used as a return value from the <a href="#RxInfer.infer"><code>infer</code></a> function. </p><p><strong>Public Fields</strong></p><ul><li><code>posteriors</code>: <code>Dict</code> or <code>NamedTuple</code> of &#39;random variable&#39; - &#39;posterior&#39; pairs. See the <code>returnvars</code> argument for <a href="#RxInfer.infer"><code>infer</code></a>.</li><li><code>free_energy</code>: (optional) An array of Bethe Free Energy values per VMP iteration. See the <code>free_energy</code> argument for <a href="#RxInfer.infer"><code>infer</code></a>.</li><li><code>model</code>: <code>FactorGraphModel</code> object reference.</li><li><code>returnval</code>: Return value from executed <code>@model</code>.</li><li><code>error</code>: (optional) A reference to an exception, that might have occurred during the inference. See the <code>catch_exception</code> argument for <a href="#RxInfer.infer"><code>infer</code></a>.</li></ul><p>See also: <a href="#RxInfer.infer"><code>infer</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/RxInfer.jl/blob/23f95bbaa753c56d83127dea0d0be14fdf937b1e/src/inference.jl#L183-L197">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RxInfer.start" href="#RxInfer.start"><code>RxInfer.start</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">start(engine::RxInferenceEngine)</code></pre><p>Starts the <code>RxInferenceEngine</code> by subscribing to the data source, instantiating free energy (if enabled) and starting the event loop. Use <a href="#RxInfer.stop"><code>RxInfer.stop</code></a> to stop the <code>RxInferenceEngine</code>. Note that it is not always possible to stop/restart the engine and this depends on the data source type.</p><p>See also: <a href="#RxInfer.stop"><code>RxInfer.stop</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/RxInfer.jl/blob/23f95bbaa753c56d83127dea0d0be14fdf937b1e/src/inference.jl#L889-L896">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RxInfer.stop" href="#RxInfer.stop"><code>RxInfer.stop</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">stop(engine::RxInferenceEngine)</code></pre><p>Stops the <code>RxInferenceEngine</code> by unsubscribing to the data source, free energy (if enabled) and stopping the event loop. Use <a href="#RxInfer.start"><code>RxInfer.start</code></a> to start the <code>RxInferenceEngine</code> again. Note that it is not always possible to stop/restart the engine and this depends on the data source type.</p><p>See also: <a href="#RxInfer.start"><code>RxInfer.start</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/RxInfer.jl/blob/23f95bbaa753c56d83127dea0d0be14fdf937b1e/src/inference.jl#L945-L952">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RxInfer.@autoupdates" href="#RxInfer.@autoupdates"><code>RxInfer.@autoupdates</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">@autoupdates</code></pre><p>Creates the auto-updates specification for the <code>rxinference</code> function. In the online-streaming Bayesian inference procedure it is important to update your priors for the future  states based on the new updated posteriors. The <code>@autoupdates</code> structure simplify such a specification. It accepts a single block of code where each line defines how to update  the <code>datavar</code>&#39;s in the probabilistic model specification. </p><p>Each line of code in the auto-update specification defines <code>datavar</code>s, which need to be updated, on the left hand side of the equality expression and the update function on the right hand side of the expression. The update function operates on posterior marginals in the form of the <code>q(symbol)</code> expression.</p><p>For example:</p><pre><code class="language-julia hljs">@autoupdates begin 
    x = f(q(z))
end</code></pre><p>This structure specifies to automatically update <code>x = datavar(...)</code> as soon as the inference engine computes new posterior over <code>z</code> variable. It then applies the <code>f</code> function to the new posterior and calls <code>update!(x, ...)</code> automatically. </p><p>As an example consider the following model and auto-update specification:</p><pre><code class="language-julia hljs">@model function kalman_filter()
    x_current_mean = datavar(Float64)
    x_current_var  = datavar(Float64)

    x_current ~ Normal(mean = x_current_mean, var = x_current_var)

    x_next ~ Normal(mean = x_current, var = 1.0)

    y = datavar(Float64)
    y ~ Normal(mean = x_next, var = 1.0)
end</code></pre><p>This model has two <code>datavar</code>s that represent our prior knowledge of the <code>x_current</code> state of the system. The <code>x_next</code> random variable represent the next state of the system that  is connected to the observed variable <code>y</code>. The auto-update specification could look like:</p><pre><code class="language-julia hljs">autoupdates = @autoupdates begin
    x_current_mean, x_current_var = mean_cov(q(x_next))
end</code></pre><p>This structure specifies to update our prior as soon as we have a new posterior <code>q(x_next)</code>. It then applies the <code>mean_cov</code> function on the updated posteriors and updates  <code>datavar</code>s <code>x_current_mean</code> and <code>x_current_var</code> automatically.</p><p>See also: <a href="#RxInfer.infer"><code>infer</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/RxInfer.jl/blob/23f95bbaa753c56d83127dea0d0be14fdf937b1e/src/inference.jl#L612-L662">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RxInfer.RxInferenceEngine" href="#RxInfer.RxInferenceEngine"><code>RxInfer.RxInferenceEngine</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RxInferenceEngine</code></pre><p>The return value of the <code>rxinference</code> function. </p><p><strong>Public fields</strong></p><ul><li><code>posteriors</code>: <code>Dict</code> or <code>NamedTuple</code> of &#39;random variable&#39; - &#39;posterior stream&#39; pairs. See the <code>returnvars</code> argument for the <a href="#RxInfer.infer"><code>infer</code></a>.</li><li><code>free_energy</code>: (optional) A stream of Bethe Free Energy values per VMP iteration. See the <code>free_energy</code> argument for the <a href="#RxInfer.infer"><code>infer</code></a>.</li><li><code>history</code>: (optional) Saves history of previous marginal updates. See the <code>historyvars</code> and <code>keephistory</code> arguments for the <a href="#RxInfer.infer"><code>infer</code></a>.</li><li><code>free_energy_history</code>: (optional) Free energy history, average over variational iterations </li><li><code>free_energy_raw_history</code>: (optional) Free energy history, returns returns computed values of all variational iterations for each data event (if available)</li><li><code>free_energy_final_only_history</code>: (optional) Free energy history, returns computed values of final variational iteration for each data event (if available)</li><li><code>events</code>: (optional) A stream of events send by the inference engine. See the <code>events</code> argument for the <a href="#RxInfer.infer"><code>infer</code></a>.</li><li><code>model</code>: <code>FactorGraphModel</code> object reference.</li><li><code>returnval</code>: Return value from executed <code>@model</code>.</li></ul><p>Use the <code>RxInfer.start(engine)</code> function to subscribe on the <code>data</code> source and start the inference procedure. Use <code>RxInfer.stop(engine)</code> to unsubscribe from the <code>data</code> source and stop the inference procedure.  Note, that it is not always possible to start/stop the inference procedure.</p><p>See also: <a href="#RxInfer.infer"><code>infer</code></a>, <a href="#RxInfer.RxInferenceEvent"><code>RxInferenceEvent</code></a>, <a href="#RxInfer.start"><code>RxInfer.start</code></a>, <a href="#RxInfer.stop"><code>RxInfer.stop</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/RxInfer.jl/blob/23f95bbaa753c56d83127dea0d0be14fdf937b1e/src/inference.jl#L717-L737">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RxInfer.RxInferenceEvent" href="#RxInfer.RxInferenceEvent"><code>RxInfer.RxInferenceEvent</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RxInferenceEvent{T, D}</code></pre><p>The <code>RxInferenceEngine</code> sends events in a form of the <code>RxInferenceEvent</code> structure. <code>T</code> represents the type of an event, <code>D</code> represents the type of a data associated with the event. The type of data depends on the type of an event, but usually represents a tuple, which can be unrolled automatically with the Julia&#39;s splitting syntax, e.g. <code>model, iteration = event</code>.  See the documentation of the <code>rxinference</code> function for possible event types and their associated data types.</p><p>The events system itself uses the <code>Rocket.jl</code> library API. For example, one may create a custom event listener in the following way:</p><pre><code class="language-julia hljs">using Rocket

struct MyEventListener &lt;: Rocket.Actor{RxInferenceEvent}
    # ... extra fields
end

function Rocket.on_next!(listener::MyEventListener, event::RxInferenceEvent{ :after_iteration })
    model, iteration = event
    println(&quot;Iteration $(iteration) has been finished.&quot;)
end

function Rocket.on_error!(listener::MyEventListener, err)
    # ...
end

function Rocket.on_complete!(listener::MyEventListener)
    # ...
end
</code></pre><p>and later on:</p><pre><code class="language-julia hljs">engine = infer(events = Val((:after_iteration, )), ...)

subscription = subscribe!(engine.events, MyEventListener(...))</code></pre><p>See also: <a href="#RxInfer.infer"><code>infer</code></a>, <a href="#RxInfer.RxInferenceEngine"><code>RxInferenceEngine</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ReactiveBayes/RxInfer.jl/blob/23f95bbaa753c56d83127dea0d0be14fdf937b1e/src/inference.jl#L1106-L1147">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../overview/">« Overview</a><a class="docs-footer-nextpage" href="../postprocess/">Inference results postprocessing »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Thursday 22 February 2024 13:41">Thursday 22 February 2024</span>. Using Julia version 1.10.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

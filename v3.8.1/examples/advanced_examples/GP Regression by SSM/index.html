<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Solve GP regression by SDE · RxInfer.jl</title><meta name="title" content="Solve GP regression by SDE · RxInfer.jl"/><meta property="og:title" content="Solve GP regression by SDE · RxInfer.jl"/><meta property="twitter:title" content="Solve GP regression by SDE · RxInfer.jl"/><meta name="description" content="Julia package for automated Bayesian inference on a factor graph with reactive message passing"/><meta property="og:description" content="Julia package for automated Bayesian inference on a factor graph with reactive message passing"/><meta property="twitter:description" content="Julia package for automated Bayesian inference on a factor graph with reactive message passing"/><meta property="og:url" content="https://reactivebayes.github.io/RxInfer.jl/examples/advanced_examples/GP Regression by SSM/"/><meta property="twitter:url" content="https://reactivebayes.github.io/RxInfer.jl/examples/advanced_examples/GP Regression by SSM/"/><link rel="canonical" href="https://reactivebayes.github.io/RxInfer.jl/examples/advanced_examples/GP Regression by SSM/"/><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/theme.css" rel="stylesheet" type="text/css"/><link href="../../../assets/header.css" rel="stylesheet" type="text/css"/><script src="../../../assets/header.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img class="docs-light-only" src="../../../assets/logo.svg" alt="RxInfer.jl logo"/><img class="docs-dark-only" src="../../../assets/logo-dark.svg" alt="RxInfer.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">RxInfer.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><span class="tocitem">User guide</span><ul><li><a class="tocitem" href="../../../manuals/getting-started/">Getting started</a></li><li><a class="tocitem" href="../../../manuals/comparison/">RxInfer.jl vs. Others</a></li><li><a class="tocitem" href="../../../manuals/model-specification/">Model specification</a></li><li><a class="tocitem" href="../../../manuals/constraints-specification/">Constraints specification</a></li><li><a class="tocitem" href="../../../manuals/meta-specification/">Meta specification</a></li><li><input class="collapse-toggle" id="menuitem-2-6" type="checkbox"/><label class="tocitem" for="menuitem-2-6"><span class="docs-label">Inference specification</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../manuals/inference/overview/">Overview</a></li><li><a class="tocitem" href="../../../manuals/inference/static/">Static inference</a></li><li><a class="tocitem" href="../../../manuals/inference/streamlined/">Streamline inference</a></li><li><a class="tocitem" href="../../../manuals/inference/initialization/">Initialization</a></li><li><a class="tocitem" href="../../../manuals/inference/autoupdates/">Auto-updates</a></li><li><a class="tocitem" href="../../../manuals/inference/delta-node/">Deterministic nodes</a></li><li><a class="tocitem" href="../../../manuals/inference/nonconjugate/">Non-conjugate inference</a></li><li><a class="tocitem" href="../../../manuals/inference/undefinedrules/">Undefined message update rules</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-7" type="checkbox"/><label class="tocitem" for="menuitem-2-7"><span class="docs-label">Inference customization</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../manuals/customization/custom-node/">Defining a custom node and rules</a></li><li><a class="tocitem" href="../../../manuals/customization/postprocess/">Inference results postprocessing</a></li></ul></li><li><a class="tocitem" href="../../../manuals/debugging/">Debugging</a></li><li><a class="tocitem" href="../../../manuals/migration-guide-v2-v3/">Migration from v2 to v3</a></li></ul></li><li><span class="tocitem">Library</span><ul><li><a class="tocitem" href="../../../library/model-construction/">Model construction</a></li><li><a class="tocitem" href="../../../library/bethe-free-energy/">Bethe Free Energy</a></li><li><a class="tocitem" href="../../../library/functional-forms/">Functional form constraints</a></li><li><a class="tocitem" href="../../../library/exported-methods/">Exported methods</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../overview/">Overview</a></li><li><input class="collapse-toggle" id="menuitem-4-2" type="checkbox"/><label class="tocitem" for="menuitem-4-2"><span class="docs-label">Basic examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../basic_examples/overview/">Overview</a></li><li><a class="tocitem" href="../../basic_examples/Coin Toss Model/">Coin toss model (Beta-Bernoulli)</a></li><li><a class="tocitem" href="../../basic_examples/Bayesian Linear Regression Tutorial/">Bayesian Linear Regression Tutorial</a></li><li><a class="tocitem" href="../../basic_examples/Kalman filtering and smoothing/">Kalman filtering and smoothing</a></li><li><a class="tocitem" href="../../basic_examples/Predicting Bike Rental Demand/">Predicting Bike Rental Demand</a></li><li><a class="tocitem" href="../../basic_examples/Hidden Markov Model/">How to train your Hidden Markov Model</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox" checked/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Advanced examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../overview/">Overview</a></li><li><a class="tocitem" href="../Active Inference Mountain car/">Active Inference Mountain car</a></li><li><a class="tocitem" href="../Advanced Tutorial/">Advanced Tutorial</a></li><li><a class="tocitem" href="../Assessing People Skills/">Assessing People’s Skills</a></li><li><a class="tocitem" href="../Chance Constraints/">Chance-Constrained Active Inference</a></li><li><a class="tocitem" href="../Conjugate-Computational Variational Message Passing/">Conjugate-Computational Variational Message Passing (CVI)</a></li><li><a class="tocitem" href="../Global Parameter Optimisation/">Global Parameter Optimisation</a></li><li class="is-active"><a class="tocitem" href>Solve GP regression by SDE</a><ul class="internal"><li><a class="tocitem" href="#Create-state-space-model-for-GP-regression"><span>Create state space model for GP regression</span></a></li><li><a class="tocitem" href="#Generate-data"><span>Generate data</span></a></li><li><a class="tocitem" href="#Covariance-function:-Matern-3/2"><span>Covariance function: Matern-3/2</span></a></li><li><a class="tocitem" href="#Covariance-function:-Matern-5/2"><span>Covariance function: Matern-5/2</span></a></li><li><a class="tocitem" href="#Result"><span>Result</span></a></li></ul></li><li><a class="tocitem" href="../Infinite Data Stream/">Infinite Data Stream</a></li><li><a class="tocitem" href="../Nonlinear Sensor Fusion/">Nonlinear Sensor Fusion</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Problem specific</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../problem_specific/overview/">Overview</a></li><li><a class="tocitem" href="../../problem_specific/Autoregressive Models/">Autoregressive Models</a></li><li><a class="tocitem" href="../../problem_specific/Gamma Mixture/">Gamma Mixture Model</a></li><li><a class="tocitem" href="../../problem_specific/Gaussian Mixture/">Gaussian Mixture</a></li><li><a class="tocitem" href="../../problem_specific/Hierarchical Gaussian Filter/">Hierarchical Gaussian Filter</a></li><li><a class="tocitem" href="../../problem_specific/Invertible Neural Network Tutorial/">Invertible neural networks: a tutorial</a></li><li><a class="tocitem" href="../../problem_specific/Probit Model (EP)/">Probit Model (EP)</a></li><li><a class="tocitem" href="../../problem_specific/RTS vs BIFM Smoothing/">RTS vs BIFM Smoothing</a></li><li><a class="tocitem" href="../../problem_specific/Simple Nonlinear Node/">Simple Nonlinear Node</a></li><li><a class="tocitem" href="../../problem_specific/Universal Mixtures/">Universal Mixtures</a></li><li><a class="tocitem" href="../../problem_specific/Litter Model/">Litter Model</a></li></ul></li><li><a class="tocitem" href="../../../contributing/examples/">Contribute with examples</a></li></ul></li><li><span class="tocitem">Contributing</span><ul><li><a class="tocitem" href="../../../contributing/guide/">Contribution guide</a></li><li><a class="tocitem" href="../../../contributing/guidelines/">Contribution guidelines</a></li><li><a class="tocitem" href="../../../contributing/new-documentation/">Contributing to the documentation</a></li><li><a class="tocitem" href="../../../contributing/new-example/">Contributing to the examples</a></li><li><a class="tocitem" href="../../../contributing/new-release/">Publishing a new release</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li><a class="is-disabled">Advanced examples</a></li><li class="is-active"><a href>Solve GP regression by SDE</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Solve GP regression by SDE</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ReactiveBayes/RxInfer.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/ReactiveBayes/RxInfer.jl/blob/main/docs/src/examples/advanced_examples/GP Regression by SSM.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><p>This example has been auto-generated from the <a href="https://github.com/reactivebayes/RxInfer.jl/tree/main/examples"><code>examples/</code></a> folder at GitHub repository.</p><h1 id="examples-solve-gp-regression-by-sde"><a class="docs-heading-anchor" href="#examples-solve-gp-regression-by-sde">Solve GP regression by SDE</a><a id="examples-solve-gp-regression-by-sde-1"></a><a class="docs-heading-anchor-permalink" href="#examples-solve-gp-regression-by-sde" title="Permalink"></a></h1><pre><code class="language-julia hljs"># Activate local environment, see `Project.toml`
import Pkg; Pkg.activate(&quot;..&quot;); Pkg.instantiate();</code></pre><p>In this notebook, we solve a GP regression problem by using &quot;Stochastic Differential Equation&quot; (SDE). This method is well described in the dissertation &quot;Stochastic differential equation methods for spatio-temporal Gaussian process regression.&quot; by Arno Solin and &quot;Sequential Inference for Latent Temporal Gaussian Process Models&quot; by Jouni Hartikainen. The idea of the method is as follows.</p><p>Suppose a function <span>$f(x)$</span> follows a zero-mean Gaussian Process <span>$\begin{aligned} f(x) \sim \mathcal{GP}(0, k(x,x&#39;)). \end{aligned}$</span></p><p>When the dimensionality of <span>$x$</span> is 1, we can consider <span>$f(x)$</span> as a stochastic process over time, i.e. <span>$f(t)$</span>. For a certain classses of covariance functions, <span>$f(t)$</span> is a solution to an <span>$m$</span>-th order linear stochastic differential equation (SDE) <span>$\begin{aligned} a_0 f(t) + a_1 \frac{d f(t)}{dt} + \dots + a_m \frac{d^m f(t)}{dt^m} = w(t)  \end{aligned}$</span></p><p>where <span>$w(t)$</span> is a zero-mean white noise process with spectral density <span>$Q_c$</span>. If we define a vector-valued function <span>$\mathbf{f}(t) = (f(t),\, d/dt f(t),\dots,\, d^{m-1}/dt^{m-1}f(t))$</span>, then we can rewrite the above SDE under the companion form</p><p class="math-container">\[\begin{aligned}
\frac{d \mathbf{f}(t)}{dt} = \mathbf{F}\, \mathbf{f}(t) + \mathbf{L} w(t) \quad (1)
\end{aligned}\]</p><p>where <span>$\mathbf{F}$</span> and <span>$\mathbf{L}$</span> are defined based on the choice of covariance functions.  From (1), we have the following state-space model: <span>$\begin{aligned} \mathbf{f}_k = \mathbf{A}_{k-1} \, \mathbf{f}_{k-1} + \mathbf{q}_{k-1}, \quad \mathbf{q}_{k-1} \sim \mathcal{N}(\mathbf{0}, \mathbf{Q}_{k-1}) \quad(2a) \\
y_k = \mathbf{H} \, \mathbf{f}(t_k) + \epsilon_k , \quad \epsilon_k \sim \mathcal{N}(0, \sigma^2_{noise}) \quad(2b). \\
\end{aligned}$</span></p><p>where <span>$\mathbf{A}_k = \exp{(\mathbf{F}\,\Delta t_k)}$</span>, with <span>$\Delta t_k = t_{k+1} - t_k$</span>, is called the discrete-time state transition matrix, and <span>$\mathbf{Q}_k$</span> the process noise covariance matrix. For the computation of <span>$\mathbf{Q}_k$</span>, we will come back later. According to Arno Solin and Jouni Hartikainen&#39;s dissertation, the GP regression problem amounts to the inference problem of the above state-space model, and this can be solved by RTS-smoothing. The state-space model starts from  the initial state <span>$f_0 \sim \mathcal{N}(\mathbf{0},\, \mathbf{P}_0)$</span>. For stationary covariance function, the SDE has a stationary state <span>$f_\infty \sim \mathcal{N}(\mathbf{0},\, \mathbf{P}_\infty)$</span>, where <span>$\mathbf{P}_\infty$</span> is the solution to <span>$\begin{aligned} \frac{d\mathbf{P}_\infty}{dt} = \mathbf{F} \mathbf{P}_\infty + \mathbf{P}_\infty \mathbf{F}^T + \mathbf{L} \mathbf{Q}_c \mathbf{L}^T = 0 \quad (\mathrm{Lyapunov \, equation}). \end{aligned}$</span></p><p>With this stationary condition, the process noise covariance <span>$\mathbf{Q}_k$</span> is computed as follows <span>$\begin{aligned} \mathbf{Q}_k = \mathbf{P}_\infty - \mathbf{A}_k \mathbf{P}_\infty \mathbf{A}_k^T  \end{aligned}$</span></p><p>For one-dimensional problem the SDE representation of the GP is defined by the matrices <span>$\mathbf{F}, \, \mathbf{L}, \, \mathbf{Q}_c, \, \mathbf{P}_0$</span> and <span>$\mathbf{H}$</span>. Once we obtain all the matrices, we can do GP regression by implementing RTS-smoothing on the state-space model (2). In this notebook we will particularly use the Matern class of covariance functions for Gaussian Process.</p><pre><code class="language-julia hljs">using RxInfer, Random, Distributions, LinearAlgebra, Plots</code></pre><h2 id="Create-state-space-model-for-GP-regression"><a class="docs-heading-anchor" href="#Create-state-space-model-for-GP-regression">Create state space model for GP regression</a><a id="Create-state-space-model-for-GP-regression-1"></a><a class="docs-heading-anchor-permalink" href="#Create-state-space-model-for-GP-regression" title="Permalink"></a></h2><p>Here we create a state-space model <span>$\begin{aligned} \mathbf{f}_k = \mathbf{A}_{k-1} \, \mathbf{f}_{k-1} + \mathbf{q}_{k-1}, \quad \mathbf{q}_{k-1} \sim \mathcal{N}(\mathbf{0}, \mathbf{Q}_{k-1}) \\
y_k = \mathbf{H} \, \mathbf{f}(t_k) + \epsilon_k , \quad \epsilon_k \sim \mathcal{N}(0, \sigma^2_{noise}), \\
\end{aligned}$</span> where <span>$y_k$</span> is the noisy observation of the function <span>$f$</span> at time <span>$t_k$</span>, and <span>$\sigma^2_{noise}$</span> is the noise variance and assumed to be known.</p><pre><code class="language-julia hljs">@model function gp_regression(y, P, A, Q, H, var_noise)
    f_prev ~ MvNormal(μ = zeros(length(H)), Σ = P) #initial state
    for i in eachindex(y)
        f[i] ~ MvNormal(μ = A[i] * f_prev,Σ = Q[i])
        y[i] ~ Normal(μ = dot(H , f[i]), var = var_noise)
        f_prev = f[i]
    end
end</code></pre><h2 id="Generate-data"><a class="docs-heading-anchor" href="#Generate-data">Generate data</a><a id="Generate-data-1"></a><a class="docs-heading-anchor-permalink" href="#Generate-data" title="Permalink"></a></h2><pre><code class="language-julia hljs">Random.seed!(10)
n = 100
σ²_noise = 0.04;
t = collect(range(-2, 2, length=n)); #timeline
f_true = sinc.(t); # true process
f_noisy = f_true + sqrt(σ²_noise)*randn(n); #noisy process

pos = sort(randperm(75)[1:2:75]); 
t_obser = t[pos]; # time where we observe data

y_data = Array{Union{Float64,Missing}}(missing, n)
for i in pos 
    y_data[i] = f_noisy[i]
end

θ = [1., 1.]; # store [l, σ²]
Δt = [t[1]]; # time difference
append!(Δt, t[2:end] - t[1:end-1]);</code></pre><h3 id="Let&#39;s-visualize-our-data"><a class="docs-heading-anchor" href="#Let&#39;s-visualize-our-data">Let&#39;s visualize our data</a><a id="Let&#39;s-visualize-our-data-1"></a><a class="docs-heading-anchor-permalink" href="#Let&#39;s-visualize-our-data" title="Permalink"></a></h3><pre><code class="language-julia hljs">plot(t, f_true, label=&quot;True process f(t)&quot;)
scatter!(t_obser, y_data[pos], label = &quot;Noisy observations&quot;)
xlabel!(&quot;t&quot;)
ylabel!(&quot;f(t)&quot;)</code></pre><p><img src="../../../assets/examples/GP Regression by SSM_5_1.png" alt/></p><h2 id="Covariance-function:-Matern-3/2"><a class="docs-heading-anchor" href="#Covariance-function:-Matern-3/2">Covariance function: Matern-3/2</a><a id="Covariance-function:-Matern-3/2-1"></a><a class="docs-heading-anchor-permalink" href="#Covariance-function:-Matern-3/2" title="Permalink"></a></h2><p>The Matern is a stationary covariance function and defined as follows <span>$\begin{aligned} k(\tau) = \sigma^2 \frac{2^{1-\nu}}{\Gamma(\nu)} \left(\frac{\sqrt{2\nu}\tau}{l} \right)^\nu K_\nu\left(\frac{\sqrt{2\nu}\tau}{l} \right) \end{aligned}$</span> where  <span>$\begin{aligned} \sigma^2: \text{the magnitude scale hyperparameter}\\
l: \text{the characteristic length-scale}\\
\nu: \text{the smoothness hyperparameter}\\
K_\nu(.): \text{the modified Bessel function of the second kind}. \end{aligned}$</span> When we say the Matern-3/2, we mean <span>$\nu=3/2$</span>. The matrices for the state space model are computed as follows <span>$\begin{aligned} \mathbf{F} = \begin{pmatrix} 0 &amp; 1\\
-\lambda^2 &amp; -2\lambda \end{pmatrix} ,\quad \quad \mathbf{L} = \begin{pmatrix} 0 \\ 1 \end{pmatrix}, \quad \quad \mathbf{P}_\infty = \begin{pmatrix} \sigma^2 &amp; 0 \\ 0 &amp; \lambda^2\sigma^2 \end{pmatrix} ,\quad \quad \mathbf{H} = \begin{pmatrix} 1 &amp; 0 \end{pmatrix}, \quad \quad Q_c = 4\lambda^3\sigma^2 \end{aligned}$</span>  where <span>$\lambda = \frac{\sqrt{3}}{l} $. From these matrices, we can define $\mathbf{A}_k$</span> and <span>$\mathbf{Q}_k$</span>.</p><pre><code class="language-julia hljs">λ = sqrt(3)/θ[1];
#### compute matrices for the state-space model ######
L = [0., 1.];
H = [1., 0.];
F = [0. 1.; -λ^2 -2λ]
P∞ = [θ[2] 0.; 0. (λ^2*θ[2]) ]
A = [exp(F * i) for i in Δt]; 
Q = [P∞ - i*P∞*i&#39; for i in A];</code></pre><pre><code class="language-julia hljs">result_32 = infer(
    model = gp_regression(P = P∞, A = A, Q = Q, H = H, var_noise = σ²_noise),
    data = (y = y_data,)
)</code></pre><pre><code class="nohighlight hljs">Inference results:
  Posteriors       | available for (f, f_prev)
  Predictions      | available for (y)</code></pre><h2 id="Covariance-function:-Matern-5/2"><a class="docs-heading-anchor" href="#Covariance-function:-Matern-5/2">Covariance function: Matern-5/2</a><a id="Covariance-function:-Matern-5/2-1"></a><a class="docs-heading-anchor-permalink" href="#Covariance-function:-Matern-5/2" title="Permalink"></a></h2><p>Now let&#39;s try the Matern-5/2 kernel. The matrices for the SDE representation of the Matern-5/2 are:</p><p class="math-container">\[\begin{aligned}
\mathbf{F} = \begin{pmatrix}
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 1 \\
-\lambda^3 &amp; -3\lambda^2 &amp; -3\lambda
\end{pmatrix} ,\quad \quad \mathbf{L} = \begin{pmatrix}
0 \\ 0 \\ 1
\end{pmatrix}, \quad \quad \mathbf{H} = \begin{pmatrix}
1 &amp; 0 &amp; 0
\end{pmatrix}, \quad \quad Q_c = \frac{16}{3} \sigma^2 \lambda^5, 
\end{aligned}\]</p><p>where <span>$\lambda = \sqrt{5} / l$</span>. To find <span>$\mathbf{P}_\infty$</span>, we solve the Lyapunov equation</p><p class="math-container">\[\begin{aligned}
\frac{d\mathbf{P}_\infty}{dt} = \mathbf{F} \mathbf{P}_\infty + \mathbf{P}_\infty \mathbf{F}^T + \mathbf{L} \mathbf{Q}_c \mathbf{L}^T = 0,
\end{aligned}\]</p><p>of which the solution is</p><p class="math-container">\[\begin{aligned}
vec(\mathbf{P}_\infty) = (\mathbf{I} \otimes \mathbf{F} + \mathbf{F}\otimes\mathbf{I})^{-1}\, vec(-\mathbf{L}Q_c\mathbf{L}^T)
\end{aligned}\]</p><p>where <span>$vec(.)$</span> is the vectorization operator and <span>$\otimes$</span> denotes the Kronecker product. Now we can find <span>$\mathbf{A}_k$</span> and <span>$\mathbf{Q}_k$</span> </p><p class="math-container">\[\begin{aligned}
\mathbf{A}_k = \exp{(\mathbf{F}\Delta t_k)} 
\end{aligned}\]</p><p class="math-container">\[\begin{aligned}
\mathbf{Q}_k = \mathbf{P}_\infty - \mathbf{A}_k \mathbf{P}_\infty \mathbf{A}_k^T  
\end{aligned}\]</p><pre><code class="language-julia hljs">λ = sqrt(5)/θ[1];
#### compute matrices for the state-space model ######
L = [0., 0., 1.];
H = [1., 0., 0.];
F = [0. 1. 0.; 0. 0. 1.;-λ^3 -3λ^2 -3λ]
Qc = 16/3 * θ[2] * λ^5;

I = diageye(3) ; 
vec_P = inv(kron(I,F) + kron(F,I)) * vec(-L * Qc * L&#39;); 
P∞ = reshape(vec_P,3,3);
A = [exp(F * i) for i in Δt]; 
Q = [P∞ - i*P∞*i&#39; for i in A];</code></pre><pre><code class="language-julia hljs">result_52 = infer(
    model = gp_regression(P = P∞, A = A, Q = Q, H = H, var_noise = σ²_noise),
    data = (y = y_data,)
)</code></pre><pre><code class="nohighlight hljs">Inference results:
  Posteriors       | available for (f, f_prev)
  Predictions      | available for (y)</code></pre><h2 id="Result"><a class="docs-heading-anchor" href="#Result">Result</a><a id="Result-1"></a><a class="docs-heading-anchor-permalink" href="#Result" title="Permalink"></a></h2><pre><code class="language-julia hljs">slicedim(dim) = (a) -&gt; map(e -&gt; e[dim], a)

plot(t, mean.(result_32.posteriors[:f]) |&gt; slicedim(1), ribbon = var.(result_32.posteriors[:f]) |&gt; slicedim(1) .|&gt; sqrt, label =&quot;Approx. process_M32&quot;, title = &quot;Matern-3/2&quot;, legend =false, lw = 2)
plot!(t, mean.(result_52.posteriors[:f]) |&gt; slicedim(1), ribbon = var.(result_52.posteriors[:f]) |&gt; slicedim(1) .|&gt; sqrt, label =&quot;Approx. process_M52&quot;,legend = :bottomleft, title = &quot;GPRegression by SSM&quot;, lw = 2)
plot!(t, f_true,label=&quot;true process&quot;, lw = 2)
scatter!(t_obser, f_noisy[pos], label=&quot;Observations&quot;)
xlabel!(&quot;t&quot;)
ylabel!(&quot;f(t)&quot;)</code></pre><p><img src="../../../assets/examples/GP Regression by SSM_10_1.png" alt/></p><p>As we can see from the plot, both cases of Matern kernel provide good approximations (small variance) to the true process at the area with dense observations (namely from t = 0 to around 3.5), and when we move far away from this region the approximated processes become less accurate (larger variance). This result makes sense because GP regression exploits the correlation between observations to predict unobserved points, and the choice of covariance functions as well as their hyperparameters might not be optimal. We can increase the accuracy of the approximated processes by simply adding more observations. This way of improvement does not trouble the state-space method much but it might cause computational problem for naive GP regression, because with N observations the complexity of naive GP regression scales with <span>$N^3$</span> while the state-space method scales linearly with N.     </p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../Global Parameter Optimisation/">« Global Parameter Optimisation</a><a class="docs-footer-nextpage" href="../Infinite Data Stream/">Infinite Data Stream »</a><div class="flexbox-break"></div><p class="footer-message">Created in <a href="https://biaslab.github.io/">BIASlab</a>, maintained by <a href="https://github.com/ReactiveBayes">ReactiveBayes</a>, powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Monday 23 December 2024 17:17">Monday 23 December 2024</span>. Using Julia version 1.10.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Nonlinear Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate local environment, see `Project.toml`\n",
    "import Pkg; Pkg.activate(\"..\"); Pkg.instantiate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RxInfer, Random, StableRNGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of creating custom node with nonlinear function approximation with samplelist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom node creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct NonlinearNode end # Dummy structure just to make Julia happy\n",
    "\n",
    "struct NonlinearMeta{R, F}\n",
    "    rng      :: R\n",
    "    fn       :: F   # Nonlinear function, we assume 1 float input - 1 float output\n",
    "    nsamples :: Int # Number of samples used in approximation\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@node NonlinearNode Deterministic [ out, in ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define two Sum-product message computation rules for our new custom node\n",
    "- Rule for outbound message on `out` edge given inbound message on `in` edge\n",
    "- Rule for outbound message on `in` edge given inbound message on `out` edge\n",
    "- Both rules accept optional meta object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule for outbound message on `out` edge given inbound message on `in` edge\n",
    "@rule NonlinearNode(:out, Marginalisation) (m_in::NormalMeanVariance, meta::NonlinearMeta) = begin \n",
    "    samples = rand(meta.rng, m_in, meta.nsamples)\n",
    "    return SampleList(map(meta.fn, samples))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule for outbound message on `in` edge given inbound message on `out` edge\n",
    "@rule NonlinearNode(:in, Marginalisation) (m_out::Gamma, meta::NonlinearMeta) = begin     \n",
    "    return ContinuousUnivariateLogPdf((x) -> logpdf(m_out, meta.fn(x)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model specification\n",
    "\n",
    "After we have defined our custom node with custom rules we may proceed with a model specification:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "p(\\theta) &= \\mathcal{N}(\\theta|\\mu_{\\theta}, \\sigma_{\\theta}),\\\\\n",
    "p(m) &= \\mathcal{N}(\\theta|\\mu_{m}, \\sigma_{m}),\\\\\n",
    "p(w) &= f(\\theta),\\\\\n",
    "p(y_i|m, w) &= \\mathcal{N}(y_i|m, w),\n",
    "\\end{aligned}$$\n",
    "\n",
    "Given this IID model, we aim to estimate the precision of a Gaussian distribution. We pass a random variable $\\theta$ through a non-linear transformation $f$ to make it positive and suitable for a precision parameter of a Gaussian distribution. We, later on, will estimate the posterior of $\\theta$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function nonlinear_estimation(y, θ_μ, m_μ, θ_σ, m_σ)\n",
    "    \n",
    "    # define a distribution for the two variables\n",
    "    θ ~ Normal(mean = θ_μ, variance = θ_σ)\n",
    "    m ~ Normal(mean = m_μ, variance = m_σ)\n",
    "\n",
    "    # define a nonlinear node\n",
    "    w ~ NonlinearNode(θ)\n",
    "\n",
    "    # We consider the outcome to be normally distributed\n",
    "    for i in eachindex(y)\n",
    "        y[i] ~ Normal(mean = m, precision = w)\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@constraints function nconstsraints(nsamples)\n",
    "    q(θ) :: SampleListFormConstraint(nsamples, LeftProposal())\n",
    "    q(w) :: SampleListFormConstraint(nsamples, RightProposal())\n",
    "    \n",
    "    q(θ, w, m) = q(θ)q(m)q(w)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@meta function nmeta(fn, nsamples)\n",
    "    NonlinearNode(θ, w) -> NonlinearMeta(StableRNG(123), fn, nsamples)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@initialization function ninit()\n",
    "    q(m) = vague(NormalMeanPrecision)\n",
    "    q(w) = vague(Gamma)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinear_fn(x) = abs(exp(x) * sin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "rng  = StableRNG(seed)\n",
    "\n",
    "niters   = 15 # Number of VMP iterations\n",
    "nsamples = 5_000 # Number of samples in approximation\n",
    "\n",
    "n = 500 # Number of IID samples\n",
    "μ = -10.0\n",
    "θ = -1.0\n",
    "w = nonlinear_fn(θ)\n",
    "\n",
    "data = rand(rng, NormalMeanPrecision(μ, w), n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now that synthetic data/constriants/model is defined, lets infer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = infer(\n",
    "    model = nonlinear_estimation(θ_μ = 0.0, m_μ = 0.0, θ_σ=100.0, m_σ=1.0),\n",
    "    meta =  nmeta(nonlinear_fn, nsamples),\n",
    "    constraints = nconstsraints(nsamples),\n",
    "    data = (y = data, ), \n",
    "    initialization = ninit(),\n",
    "    returnvars = (θ = KeepLast(), ),\n",
    "    iterations = niters,  \n",
    "    showprogress = true\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can check the posterior now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "θposterior = result.posteriors[:θ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's us visualise the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, StatsPlots\n",
    "\n",
    "estimated = Normal(mean_std(θposterior)...)\n",
    "\n",
    "plot(estimated, title=\"Posterior for θ\", label = \"Estimated\", legend = :bottomright, fill = true, fillopacity = 0.2, xlim = (-3, 3), ylim = (0, 2))\n",
    "vline!([ θ ], label = \"Real value of θ\")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/.julia/dev/RxInfer.jl/examples`\n"
     ]
    }
   ],
   "source": [
    "# Activate local environment, see `Project.toml`\n",
    "import Pkg; Pkg.activate(\"..\"); Pkg.instantiate(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RxInfer, Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers the fundamentals and advanced usage of the `RxInfer.jl` package.\n",
    "\n",
    "This tutorial is also available in the [documentation](https://reactivebayes.github.io/RxInfer.jl/stable/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General model specification syntax\n",
    "\n",
    "We use the `@model` macro from the `GraphPPL.jl` package to create a probabilistic model $p(s, y)$ and we also specify extra constraints on the variational family of distributions $\\mathcal{Q}$, used for approximating intractable posterior distributions.\n",
    "Below there is a simple example of the general syntax for model specification. In this tutorial we do not cover all possible ways to create models or advanced features of `GraphPPL.jl`.  Instead we refer the interested reader to the documentation for a more rigorous explanation and illustrative examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the `@model` macro accepts a regular Julia function\n",
    "@model function test_model1(s_mean, s_precision, y)\n",
    "    \n",
    "    # the `tilde` operator creates a functional dependency\n",
    "    # between variables in our model and can be read as \n",
    "    # `sampled from` or `is modeled by`\n",
    "    s ~ Normal(mean = s_mean, precision = s_precision)\n",
    "    y ~ Normal(mean = s, precision = 1.0)\n",
    "    \n",
    "    # It is possible to return something from the model specification (including variables and nodes)\n",
    "    return \"Hello world\"\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `@model` macro creates a function with the same name and with the same set of input arguments as the original function (`test_model1(s_mean, s_precision, y)` in this example).\n",
    "The arguments are however converted to the keyword arguments. The `@model` macro does not support positional arguments."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use control flow statements such as `if` or `for` blocks in the model specification function. In general, any valid snippet of Julia code can be used inside the `@model` block. As an example consider the following (valid!) model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function test_model2(y)\n",
    "    \n",
    "    if length(y) <= 1\n",
    "        error(\"The `length` of `y` argument must be greater than one.\")\n",
    "    end\n",
    "    \n",
    "    s[1] ~ Normal(mean = 0.0, precision = 0.1)\n",
    "    y[1] ~ Normal(mean = s[1], precision = 1.0)\n",
    "    \n",
    "    for i in eachindex(y)\n",
    "        s[i] ~ Normal(mean = s[i - 1], precision = 1.0)\n",
    "        y[i] ~ Normal(mean = s[i], precision = 1.0)\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use complex expressions inside the functional dependency expressions\n",
    "\n",
    "```julia\n",
    "y ~ Normal(mean = 2.0 * (s + 1.0), precision = 1.0)\n",
    "```\n",
    "\n",
    "The `~` operator automatically creates a random variable if none was created before with the same name and throws an error if this name already exists\n",
    "\n",
    "```julia\n",
    "# `~` creates random variables automatically\n",
    "s ~ Normal(mean = 0.0, precision1.0)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic inference in RxInfer.jl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RxInfer.jl` uses the `Rocket.jl` package API for inference routines. `Rocket.jl` is a reactive programming extension for Julia that is higly inspired by `RxJS` and similar libraries from the `Rx` ecosystem. It consists of **observables**, **actors**, **subscriptions** and **operators**. For more information and rigorous examples see [Rocket.jl github page](https://github.com/biaslab/Rocket.jl)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observables\n",
    "Observables are lazy push-based collections and they deliver their values over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimerObservable(300, 300)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Timer that emits a new value every second and has an initial one second delay \n",
    "observable = timer(300, 300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A subscription allows us to subscribe on future values of some observable, and actors specify what to do with these new values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimerSubscription()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "actor = (value) -> println(value)\n",
    "subscription1 = subscribe!(observable, actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We always need to unsubscribe from some observables\n",
    "unsubscribe!(subscription1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProxyObservable(Int64, MapProxy(Int64))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can modify our observables\n",
    "modified = observable |> filter(d -> rem(d, 2) === 1) |> map(Int, d -> d ^ 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimerSubscription()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subscription2 = subscribe!(modified, (value) -> println(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsubscribe!(subscription2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coin Toss Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function coin_toss_model(y)\n",
    "    # We endow θ parameter of our model with some prior\n",
    "    θ  ~ Beta(2.0, 7.0)\n",
    "    # We assume that the outcome of each coin flip \n",
    "    # is modeled by a Bernoulli distribution\n",
    "    y .~ Bernoulli(θ)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call the `infer` function to run inference in such model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred bias is 0.7445972495088409 with standard deviation is 0.019310272869626444\n"
     ]
    }
   ],
   "source": [
    "p = 0.75 # Bias of a coin\n",
    "\n",
    "dataset = float.(rand(Bernoulli(p), 500));\n",
    "\n",
    "result = infer(\n",
    "    model = coin_toss_model(),\n",
    "    data  = (y = dataset, )\n",
    ")\n",
    "\n",
    "println(\"Inferred bias is \", mean(result.posteriors[:θ]), \" with standard deviation is \", std(result.posteriors[:θ]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the inferred bias is quite close to the actual value we used in the dataset generation with a low standard deviation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reactive Online Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RxInfer.jl naturally supports reactive streams of data and it is possible to run reactive inference with some external datasource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function online_coin_toss_model(θ_a, θ_b, y)\n",
    "    θ ~ Beta(θ_a, θ_b)\n",
    "    y ~ Bernoulli(θ)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(θ_a,θ_b = params(q(θ)),)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "autoupdates = @autoupdates begin \n",
    "    θ_a, θ_b = params(q(θ))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxresult = infer(\n",
    "    model = online_coin_toss_model(),\n",
    "    data  = (y = dataset, ),\n",
    "    autoupdates = autoupdates,\n",
    "    historyvars = (θ = KeepLast(), ),\n",
    "    keephistory = length(dataset),\n",
    "    initmarginals = (\n",
    "        θ = vague(Beta),\n",
    "    ),\n",
    "    autostart = true\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = @animate for i in 1:length(dataset)\n",
    "    plot(mean.(rxresult.history[:θ][1:i]), ribbon = std.(rxresult.history[:θ][1:i]), title = \"Online coin bias inference\", label = \"Inferred bias\", legend = :bottomright)\n",
    "    hline!([ p ], label = \"Real bias\", size = (600, 200))\n",
    "end\n",
    "\n",
    "gif(animation, \"../pics/online-coin-bias-inference.gif\", fps = 24, show_msg = false);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../pics/online-coin-bias-inference.gif)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we used static dataset and the `history` field of the reactive inference result, but the `rxinference` function also supports any real-time reactive stream and can run indefinitely."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was an example of exact Bayesian inference with Sum-Product (or Belief Propagation) algorithm. However, `RxInfer` is not limited to only the sum-product algorithm but it also supports variational message passing with [Constrained Bethe Free Energy Minimisation](https://www.mdpi.com/1099-4300/23/7/807)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a very high-level, `RxInfer` is aimed to solve the Constrained Bethe Free Energy minimisation problem. For this task we approximate our exact posterior marginal distribution by some family of distributions $q \\in \\mathcal{Q}$. Often this involves assuming some factorization over $q$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function test_model6(y)\n",
    "    τ ~ Gamma(shape = 1.0, rate = 1.0) \n",
    "    μ ~ Normal(mean = 0.0, variance = 100.0)\n",
    "    for i in eachindex(y)\n",
    "        y[i] ~ Normal(mean = μ, precision = τ)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we want to specify extra constraints for $q_a$ for Bethe factorisation:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{aligned}\n",
    "q(s) = \\prod_{a \\in \\mathcal{V}} q_a(s_a) \\prod_{i \\in \\mathcal{E}} q_i^{-1}(s_i)\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RxInfer.jl` package exports `@constraints` macro to simplify factorisation and form constraints specification. Read more about `@constraints` macro in the corresponding documentation section, here we show a simple example of the same factorisation constraints specification, but with `@constraints` macro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Constraints: \n",
       "    q(μ, τ) = q(μ)q(τ)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "constraints6 = @constraints begin\n",
    "     q(μ, τ) = q(μ)q(τ) # Mean-Field over `μ` and `τ`\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run inference in this model we again need to create a synthetic dataset and call the `infer` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\u001b[K\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inference results:\n",
       "  Posteriors       | available for (μ, τ)\n",
       "  Free Energy:     | Real[14763.3, 3276.07, 668.946, 628.904, 628.904, 628.904, 628.904, 628.904, 628.904, 628.904]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = rand(Normal(-3.0, inv(sqrt(5.0))), 1000);\n",
    "result = infer(\n",
    "    model         = test_model6(),\n",
    "    data          = (y = dataset, ),\n",
    "    constraints   = constraints6, \n",
    "    initmarginals = (μ = vague(NormalMeanPrecision), τ = vague(GammaShapeRate)),\n",
    "    returnvars    = (μ = KeepLast(), τ = KeepLast()),\n",
    "    iterations    = 10,\n",
    "    free_energy   = true,\n",
    "    showprogress  = true\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "μ: mean = -3.009380043564933, std = 0.014241334363642019\n"
     ]
    }
   ],
   "source": [
    "println(\"μ: mean = \", mean(result.posteriors[:μ]), \", std = \", std(result.posteriors[:μ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "τ: mean = 4.930577085136045, std = 0.22028193870559956\n"
     ]
    }
   ],
   "source": [
    "println(\"τ: mean = \", mean(result.posteriors[:τ]), \", std = \", std(result.posteriors[:τ]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form constraints\n",
    "\n",
    "In order to support form constraints, the `@constraints` macro supports additional type specifications for posterior marginals. \n",
    "For example, here how we can perform the EM algorithm with `PointMass` form constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../pics/posterior.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function test_model7(y)\n",
    "    τ ~ Gamma(shape = 1.0, rate = 1.0) \n",
    "    μ ~ Normal(mean = 0.0, variance = 100.0)\n",
    "    for i in eachindex(y)\n",
    "        y[i] ~ Normal(mean = μ, precision = τ)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous example we can use `@constraints` macro to achieve the same goal with a nicer syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Constraints: \n",
       "    q(μ, τ) = q(μ)q(τ)\n",
       "    q(μ) :: PointMassFormConstraint()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "constraints7 = @constraints begin \n",
    "    q(μ) :: PointMassFormConstraint()\n",
    "    \n",
    "    q(μ, τ) = q(μ)q(τ) # Mean-Field over `μ` and `τ`\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference results:\n",
       "  Posteriors       | available for (μ, τ)\n",
       "  Free Energy:     | Real[14766.5, 2054.95, 657.106, 657.106, 657.106, 657.106, 657.106, 657.106, 657.106, 657.106]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = rand(Normal(-3.0, inv(sqrt(5.0))), 1000);\n",
    "result = infer(\n",
    "    model         = test_model7(),\n",
    "    data          = (y = dataset, ),\n",
    "    constraints   = constraints7, \n",
    "    initmarginals = (μ = vague(NormalMeanPrecision), τ = vague(GammaShapeRate)),\n",
    "    returnvars    = (μ = KeepLast(), τ = KeepLast()),\n",
    "    iterations    = 10,\n",
    "    free_energy   = true,\n",
    "    showprogress  = true\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "μ: mean = -3.022357739818599, std = 0.0\n"
     ]
    }
   ],
   "source": [
    "println(\"μ: mean = \", mean(result.posteriors[:μ]), \", std = \", std(result.posteriors[:μ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "τ: mean = 4.634417532698216, std = 0.2070505057007574\n"
     ]
    }
   ],
   "source": [
    "println(\"τ: mean = \", mean(result.posteriors[:τ]), \", std = \", std(result.posteriors[:τ]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta data specification\n",
    "\n",
    "During model specification some functional dependencies may accept an optional `meta` object in the `where { ... }` clause. The purpose of the `meta` object is to adjust, modify or supply some extra information to the inference backend during the computations of the messages. The `meta` object for example may contain an approximation method that needs to be used during various approximations or it may specify the tradeoff between accuracy and performance:\n",
    "\n",
    "```julia\n",
    "# In this example the `meta` object for the autoregressive `AR` node specifies the variate type of \n",
    "# the autoregressive process and its order. In addition it specifies that the message computation rules should\n",
    "# respect accuracy over speed with the `ARsafe()` strategy. In contrast, `ARunsafe()` strategy tries to speedup computations\n",
    "# by cost of possible numerical instabilities during an inference procedure\n",
    "s[i] ~ AR(s[i - 1], θ, γ) where { meta = ARMeta(Multivariate, order, ARsafe()) }\n",
    "...\n",
    "s[i] ~ AR(s[i - 1], θ, γ) where { meta = ARMeta(Univariate, order, ARunsafe()) }\n",
    "```\n",
    "\n",
    "Another example with `GaussianControlledVariance`, or simply `GCV` [see Hierarchical Gaussian Filter], node:\n",
    "\n",
    "```julia\n",
    "# In this example we specify structured factorisation and flag meta with `GaussHermiteCubature` \n",
    "# method with `21` sigma points for approximation of non-lineariety between hierarchy layers\n",
    "xt ~ GCV(xt_min, zt, real_k, real_w) where { meta = GCVMetadata(GaussHermiteCubature(21)) }\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Meta object is useful to pass any extra information to a node that is not a random variable or constant model variable. It may include extra approximation methods, differentiation methods, optional non-linear functions, extra inference parameters etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphPPL.jl `@meta` macro\n",
    "\n",
    "Users can use `@meta` macro from the `GraphPPL.jl` package to achieve the same goal. Read more about `@meta` macro in the corresponding documentation section. Here is a simple example of the same meta specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphPPL.MetaSpecification(GraphPPL.MetaObject[AR(s, θ, γ) -> ARMeta{Multivariate, ARsafe}(5, ARsafe())], Union{GraphPPL.GeneralSubModelMeta, GraphPPL.SpecificSubModelMeta}[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@meta begin \n",
    "     AR(s, θ, γ) -> ARMeta(Multivariate, 5, ARsafe())\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating custom nodes and message computation rules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom nodes\n",
    "\n",
    "To create a custom functional form and to make it available during model specification the `ReactiveMP` inference engine exports the `@node` macro:\n",
    "\n",
    "```julia\n",
    "# `@node` macro accepts a name of the functional form, its type, either `Stochastic` or `Deterministic` and an array of interfaces:\n",
    "@node NormalMeanVariance Stochastic [ out, μ, v ]\n",
    "\n",
    "# Interfaces may have aliases for their names that might be convenient for factorisation constraints specification\n",
    "@node NormalMeanVariance Stochastic [ out, (μ, aliases = [ mean ]), (v, aliases = [ var ]) ]\n",
    "\n",
    "# `NormalMeanVariance` structure declaration must exist, otherwise `@node` macro will throw an error\n",
    "struct NormalMeanVariance end \n",
    "\n",
    "@node NormalMeanVariance Stochastic [ out, μ, v ]\n",
    "\n",
    "# It is also possible to use function objects as a node functional form\n",
    "function dot end\n",
    "\n",
    "# Syntax for functions is a bit differet, as it is necesssary to use `typeof(...)` function for them \n",
    "# out = dot(x, a)\n",
    "@node typeof(dot) Deterministic [ out, x, a ]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that it is possible to use the newly created node during model specification:\n",
    "\n",
    "```julia\n",
    "@model function test_model()\n",
    "    ...\n",
    "    y ~ dot(x, a)\n",
    "    ...\n",
    "end\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom messages computation rules\n",
    "\n",
    "`RxInfer.jl` exports the `@rule` macro to create custom message computation rules. For example let us create a simple `+` node to be available for usage in the model specification usage. We refer to *A Factor Graph Approach to Signal Modelling , System Identification and Filtering* [ Sascha Korl, 2005, page 32 ] for a rigorous explanation of the `+` node in factor graphs. According to Korl, assuming that inputs are Gaussian Sum-Product message computation rule for `+` node is the following:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\mu_z = \\mu_x + \\mu_y\\\\\n",
    "V_z = V_x + V_y\n",
    "\\end{aligned}$$\n",
    "\n",
    "To specify this in `RxInfer.jl` we use the `@node` and `@rule` macros:\n",
    " \n",
    "```julia\n",
    "@node typeof(+) Deterministic  [ z, x, y ]\n",
    "\n",
    "@rule typeof(+)(:z, Marginalisation) (m_x::UnivariateNormalDistributionsFamily, m_y::UnivariateNormalDistributionsFamily) = begin\n",
    "    x_mean, x_var = mean_var(m_x)\n",
    "    y_mean, y_var = mean_var(m_y)\n",
    "    return NormalMeanVariance(x_mean + y_mean, x_var + y_var)\n",
    "end\n",
    "```\n",
    "\n",
    "In this example, for the `@rule` macro, we specify a type of our functional form: `typeof(+)`. Next, we specify an edge we are going to compute an outbound message for. `Marginalisation` indicates that the corresponding message respects the marginalisation constraint for posterior over corresponding edge:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "q(z) = \\int q(z, x, y) \\mathrm{d}x\\mathrm{d}y\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look on difference between sum-product rules and variational rules with mean-field assumption we notice that they require different local information to compute an outgoing message:\n",
    "\n",
    "![](../pics/sp.png)\n",
    "![](../pics/vmp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{aligned}\n",
    "\\mu(z) = \\int f(x, y, z)\\mu(x)\\mu(y)\\mathrm{d}x\\mathrm{d}y\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{aligned}\n",
    "\\nu(z) = \\exp{ \\int \\log f(x, y, z)q(x)q(y)\\mathrm{d}x\\mathrm{d}y }\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `@rule` macro supports both cases with special prefixes during rule specification:\n",
    "- `m_` prefix corresponds to the incoming message on a specific edge\n",
    "- `q_` prefix corresponds to the posterior marginal of a specific edge"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a Sum-Product rule with `m_` messages used:\n",
    "\n",
    "```julia\n",
    "@rule NormalMeanPrecision(:μ, Marginalisation) (m_out::UnivariateNormalDistributionsFamily, m_τ::PointMass) = begin \n",
    "    m_out_mean, m_out_cov = mean_cov(m_out)\n",
    "    return NormalMeanPrecision(m_out_mean, inv(m_out_cov + inv(mean(m_τ))))\n",
    "end\n",
    "```\n",
    "\n",
    "Example of a Variational rule with Mean-Field assumption with `q_` posteriors used:\n",
    "\n",
    "```julia\n",
    "@rule NormalMeanPrecision(:μ, Marginalisation) (q_out::Any, q_τ::Any) = begin \n",
    "    return NormalMeanPrecision(mean(q_out), mean(q_τ))\n",
    "end\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RxInfer.jl` also supports structured rules. It is possible to obtain joint marginal over a set of edges:\n",
    "\n",
    "```julia\n",
    "@rule NormalMeanPrecision(:τ, Marginalisation) (q_out_μ::Any, ) = begin\n",
    "    m, V = mean_cov(q_out_μ)\n",
    "    θ = 2 / (V[1,1] - V[1,2] - V[2,1] + V[2,2] + abs2(m[1] - m[2]))\n",
    "    α = convert(typeof(θ), 1.5)\n",
    "    return Gamma(α, θ)\n",
    "end\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: In the `@rule` specification the messages or marginals arguments **must** be in order with interfaces specification from `@node` macro:\n",
    "\n",
    "```julia\n",
    "# Inference backend expects arguments in `@rule` macro to be in the same order\n",
    "@node NormalMeanPrecision Stochastic [ out, μ, τ ]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any rule always has access to the meta information with hidden the `meta::Any` variable:\n",
    "\n",
    "```julia\n",
    "@rule MyCustomNode(:out, Marginalisation) (m_in1::Any, m_in2::Any) = begin \n",
    "    ...\n",
    "    println(meta)\n",
    "    ...\n",
    "end\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to dispatch on a specific type of a meta object:\n",
    "\n",
    "```julia\n",
    "@rule MyCustomNode(:out, Marginalisation) (m_in1::Any, m_in2::Any, meta::LaplaceApproximation) = begin \n",
    "    ...\n",
    "end\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```julia\n",
    "@rule MyCustomNode(:out, Marginalisation) (m_in1::Any, m_in2::Any, meta::GaussHermiteCubature) = begin \n",
    "    ...\n",
    "end\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing messages computational pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In certain situations it might be convenient to customize the default message computational pipeline. `RxInfer.jl` supports the `pipeline` keyword in the `where { ... }` clause to add some extra steps after a message has been computed. A use case might be an extra approximation method to preserve conjugacy in the model, debugging or simple printing.\n",
    "\n",
    "<img style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 30%;\" src=\"./pics/pipeline.png\" width=\"20%\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```julia\n",
    "# Logs all outbound messages\n",
    "y[i] ~ Normal(mean = x[i], precision = 1.0) where { pipeline = LoggerPipelineStage() }\n",
    "# In principle, it is possible to approximate outbound messages with Laplace Approximation (this is not an implemented feature, but a concept)\n",
    "y[i] ~ Normal(mean = x[i], precision = 1.0) where { pipeline = LaplaceApproximation() }\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us return to the coin toss model, but this time we want to print flowing messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function coin_toss_model_log(y)\n",
    "    θ ~ Beta(2.0, 7.0) where { pipeline = LoggerPipelineStage(\"θ\") }\n",
    "    for i in eachindex(y)\n",
    "        y[i] ~ Bernoulli(θ)  where { pipeline = LoggerPipelineStage(\"y[$i]\") }\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[θ][Beta][out]: DeferredMessage([ use `as_message` to compute the message ])\n",
      "[y[1]][Bernoulli][p]: DeferredMessage([ use `as_message` to compute the message ])\n",
      "[y[2]][Bernoulli][p]: DeferredMessage([ use `as_message` to compute the message ])\n",
      "[y[3]][Bernoulli][p]: DeferredMessage([ use `as_message` to compute the message ])\n",
      "[y[4]][Bernoulli][p]: DeferredMessage([ use `as_message` to compute the message ])\n",
      "[y[5]][Bernoulli][p]: DeferredMessage([ use `as_message` to compute the message ])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inference results:\n",
       "  Posteriors       | available for (θ)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = float.(rand(Bernoulli(p), 5));\n",
    "result = infer(\n",
    "    model = coin_toss_model_log(),\n",
    "    data  = (y = dataset, )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
